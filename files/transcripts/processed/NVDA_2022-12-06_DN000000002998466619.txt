okay thanks much hi everyone brett simpson pleasure welcome ian buck know run data center division nvidia one key growth engine business think particularly interesting time connect ian simona heading new product cycle hopper looking back nvidia launched ampere think back early 2020 business 1 billion quarterly revenue back looking today almost 4 billion quarterly revenue really strong period business well done many know ian inventor cuda going try touch sort software opportunity nvidia see ahead presentation ian thanks much joining u today thanks thank also simona jankowski line know vp ir nvidia going pas simona read safe harbor simona q brett simpson ian buck q brett simpson ian buckthank brett hosting u quick reminder comment today may contain statement investor advised read report filed sec information related risk uncertainty facing business back question answer thanks simona maybe start ian maybe recap 2022 period looking division market opportunity see ahead maybe touch sort customer reaction new product think happening bleeding edge ai see evolving 2023 yeah mean whirlwind probably hit u back obviously 2020 launched ampere feel like lifetime ago back 2020 throughout covid launched ampere following year announced grace cpu work year course announced hopper nvidia new clip investment importance computing across industry innovation allow u continue invent new gpus new architecture new algorithm serve growing market ai computing data center general biannual clip point making new gpu architecture every two year committed new cpu architecture also every two year exciting launch hopper year hopper gpu specifically designed advance ai well hpc specialization model foundational model used today large language model generative ai applied pretty much every domain computer want see listen learn generate back excited hopper introduction production pc ai ph system coming available oems cloud hyperscalers hopper bringing market great maybe given environment run moment think lot investor trying understand whether environment right made think different opportunity see ahead look next sort six 12 month got lot product rollouts et cetera enterprise engagement still demand signal still strong thinking six 12 month ago yeah foundation engage grown last two year remained consistent increasing activity motion start certainly big hyperscalers work best work microsoft partnering openai meta google even others taking advantage gpus software solution layering top order develop ai technology capability moonshot foundational model lot work software hardware fact nvidia software developer hardware developer example lot work framework like pytorch tensorflow also develop large language model supercomputer share rest world help move ball forward give u experience continuously improve platform along taking input every major hyperscalers well experience build supercomputer try test advance state art certainly big hyperscale side activation cloud continued grow certainly every enterprise strategy kind bringing technology workﬂows way business cloud result public cloud activation platform certainly grown saw a100 continue see grow h100 enterprise side certainly upward trend challenge enterprise side meeting enterprise developer talent pool necessary google amazon meta may see opportunity ai could changing advancing business role help move forward provide platform big part nvidia ai enterprise platform help provide stable supported platform enterprise rely getting best best performance support need directly nvidia working together inaudible cloud partner also helping activate right kind software take advantage natively ai framework targeted service support come working lot great activity happening course community providing service enterprise share data get result back without build software scratch seeing also course cloud provider providing service lot developed deployed nvidia gpus along growing broader isv category well even traditional isvs may area numerical simulation trying deploy ai surrogate model first principle physic simulation product development sort thing finally nvidia trying move ball forward well area see opportunity move market forward invest done particularly healthcare space clara platform applying ai thing like medical imaging proteomics also speech ai q brett simpson ian bucksort provided foundational support riva platform help enterprise take advantage speech ai offer really cool ability customization train new model new voice additional thing like recently last gdc announced nemo large language model service build service enterprise customize large model provide open model variety different gpt size done 530 billion parameter model called megatron make available service enterprise take existing train model model super smart tune basically technical prompting couple example hundred example 500 model learns answer question way customer looking ph answered asking question broader internet customer support already given hundred example customer support call answer look like inaudible answer appropriately context business enterprise side beginning still beginning ai adoption seeing lot interest nvidia standpoint company engage different level certainly consuming sort offering decided invest also isvs well course platform holistically big part strategy open move ball forward helping company customer developer user get benefit ai want come back service model around megatron gpt broadly little bit later wanted mean guess go back model coming a100 around time much upgrade cycle could see playing nvidia last couple year talk little bit today bleeding edge worked lab see mean conference year ago ian talked model size growing like 10x year still happening mean must well trillion parameter model size trillion guess parameter go next couple year hopper cycle type workload hopper ideally positioned deliver yeah certainly natural nlp large language model llm community slowed one bit see many major player well taking advantage model large tend well previous model may focus thing like computer vision understanding picture picture stop sign capability think first principle sort q brett simpson ian buckunderstanding perspective fairly straightforward fact nature see animal bug thing basic vision capability like identify object call language different language unique encompasses understand language need know word saying right mean order make context anything useful mean sort model encompass understand corpus human understanding result trained entire internet literally data set basically big scrape internet cleaned tuned trained tend obviously much bigger 530 billion parameter model talked already certainly new work new model coming already trillion parameter still short like brain scale question 150 trillion parameter inaudible trillion right 2025 2026 yeah get moore law model capability growing model basically large language model today obviously provide convincing chat dialogue back forth used sentiment analysis sort thing understand human knowledge next step obviously seeing right remains true model large certainly train single gpu even single server tend train across pod collection trained megatron model 4,000 gpus final training run took little month course lot r get point develop model way certainly trained tuned different use case tuning step actually much approachable requires le infrastructure going train entire model point people developing new foundational model used different use case lot interesting research development biggest player infrastructure one goal hopper bring cost large language model training make applicable done hopper run trick ph train 6 time 9 time faster ampere requiring 6 time 9 time le infrastructure depending model really designed transformer layer talked take advantage reduced precision mixed precision stack still maintain accuracy easy offer bit ph ﬂoating point hard make work work well fact use selene supercomputer train different heuristic q brett simpson ph baked software/hardware hopper make successful part hopper made nlp applicable dramatically improved inference performance performance take run model production train deploy hopper 30 time faster ampere allows people take largest possible model still run reasonable amount infrastructure single system deliver reasonable performance running model going dramatically broaden applicability nlp model lot people run use case probably saw previously bespoke offering large model goal definitely seeing lot interest deploying hopper course next step else generate else large language model produce kind response chat box response customer service response sentiment response starting see hit mixed modality space generative ai work done stable diffusion folk like stability ai midjourney runway others showing take large language model connect image generation output picture rather text super exciting example another place large language model underlying generative portion ai understanding corpus image mean multiple speaker another great example project farther future imagine ai generating sort thing generating potential chemical compound therapeutic material property generation manufacturing material science came back supercomputing conference dallas texas talk town building foundational using supercomputer build foundational model science hpc use case across science community sort opportunity going get u access platform technology researcher user company take advantage deploy different use case make part job fun help get maybe focus little bit training guess seen last 12 month mean meta quite public built massive cluster 16,000 a100s think earnings report talked microsoft rolling ten thousand gpus think oracle also pretty active building large training cluster large exaﬂop supercomputer heading phase amount people keep building massive training cluster going consolidate handful player see hundred potential training cluster like getting developed trying get sense see training evolving ian buckand guess part also want come back service opportunity license model going lot enterprise get involved ai rather train everything ground license something pay service fee rather necessarily buying big hardware cluster well one thing sort bet ai still tapped different application ai fundamentally ai statistical trick algorithm take data write code case microsoft literally helping write code program application ai seem balanced everything computing enterprise revolves around data collect customer data business generates operates teach u communication customer ﬂow business also generates massive amount data interpreted understood taking advantage ai improve make better continued grow result access infrastructure developing ai either first principle foundational level taking existing foundational model applying growing definitely interest others major isvs big company explore explore building new foundational capability need infrastructure interesting cloud starting provide infrastructure building ai supercomputer bespoke supercomputer certainly microsoft led way announcement providing independent interconnected gpu cluster cloud people rent kind infrastructure seeing oracle many others company like meta building infrastructure one many either going build able consume rented cloud seeing growth ai infrastructure particularly infrastructure available cloud important note rent designed fractionalized way one note everything single focused around single node capability many gpus fit single server usually maxing eight 16 infrastructure cloud scalable thinking data renting entire data center row ph pod collection half rack various work developing foundational model going serve different industry broad largest largest model one tend get excitement press certain capability designing model new kind model different kind workload foundation level requires level infrastructure scale q brett simpson ian buckthen second part course applying taking foundation model applying different use case business certainly see thing like speech ai foundational model trained english even ph want certain accident certain voice thing need retrained scratch take foundational model deploy business figuring take advantage service sort different provider go consume causing growth gpus across cloud still think ebb ﬂow term versus enterprise platform choice try activate channel coming think ai squirreling away corner people afford certainly interest exploring outer limit ai large infrastructure continue believe seeing diversification different use case developing foundational model sort different scale different kind player ability consume get cloud well finally breadth different service like mentioned take advantage trained learned ph service yeah interesting interesting thinking mean mentioned still early phase building workload compute requirement go guess look hyperscalers bleeding edge today making big investment public cloud serving instance thousand enterprise guess break today see guy maybe spending multiple billion year nvidia break overall revenue see sort stage large investment made hyperscalers see scaling looking inevitable hyperscalers spending 10 billion plus point soon think fortune 500 sizing investment opportunity see fortune 500 company spending 1 billion infrastructure really differentiate ai think year development opportunity nvidia specifically yeah mean think still early stage think diﬃcult project dollar obviously exciting continue exciting definitely see growth moving forward one way look logical case every server inside hyperscale data center accelerated level operating data either ﬂowing data center within data center every bit data logically interpreted understood ai make insight improve function operation data center trying impact outcome result today probably le around le 10 hyperscale data center accelerated preventing cause growth people identifying capability ai could impact improve part workﬂow part user story part capability part data center particularly time data center space precious certainly seen growth data center pop overnight take year plan year build accelerated computing offer great way optimizing data center space moving stuff service consume lot using ai reduce amount infrastructure preserve space norm ph grow data center space important metric foundation grow accelerating computing allows le data center space likewise power energy eﬃciency operation scale much lower total energy cost cpu infrastructure may able lot interest identifying workload shifting accelerated portion data center order thing optimize data center usage improve throughput workﬂow consuming le data center space eﬃcient power order naturally grow think application course may happen inside data center diﬃcult folk outside see first people hyperscalers seeing service building also make service publicly visible projection get translated inside operational line inside business enterprise side activation different enterprise isvs major enterprise service company seeing seeing go look success story talked jensen talked gdc keynote look oracle world joined stage safra talked enterprise adopting question still fairly small percentage total enterprise software stack inaudible ai lot valid reason something going changing fairly quickly becoming point order competitive enterprise software world need deploying offering capability giving cio cfo consumer isv software fortune 500 need ph strategy imagine asking isvs leveraging ai make business run better service incorporated service already already stage lot baseline functionality capability obviously operation enterprise served major enterprise isvs trying hard right others activating ai foundational enterprise software stack q brett simpson ian buckand grow get faster eﬃcient see adoption gpus across cloud data center well offering company run workload eﬃciently low possible latency order deliver need service think interesting thing track think looking isvs deploying ai major fortune 500 deploying place think look sector well interesting thing happening retail talking think mcdonald publicly talked pilot speech ai sort talking looking different way providing different kind service obviously exciting see retail community take advantage ai certainly look segment vertical vertical segment one two player go see opportunity turn around excited take advantage lot investment activity happening across enterprise role obviously working isvs provide foundational layer company fortune 500 owner need get direct support nvidia back kind nvidia ai enterprise offering market yeah yeah make sense maybe wanted talk little bit mean guess look 2023 big architecture change compute generally dpu going start become thing think obviously removed grace cpu side hopper big architecture change interconnect sits around would describe transition seeing much approach compute complex becoming platform sale nvidia rather selling sort discrete card content guess looking content today within server see dramatic increase ramp bluefield grace switching infrastructure developing yeah think couple thing one obviously existing business people interested getting access great infrastructure computing continue today x86 gpus either sort standard server accelerator look like pcie card quite large one similar may seen geforce product go standard server eight 16 graphic connector optimized computing also come smaller size inference use case tend much smaller edge like accelerator go go way embedded space measured watt deployed edge kind use case even conference room telco kind application robotics go way server explicitly designed computing scale see hgx dgx solution moving forward think interesting trend toward data center unit compute people looking server component chip order advancement computing ai think looking entire data center optimize entire data center compute many year ago data center hyperscalers basically ph kind data center driven i/o compute would deliberately choose smaller cpu focus interconnect scale along storage compute king looking entire data center improve compute utility entire data center optimize unit total unit computing look way want look capability data center accelerator obviously cpu connected network integrated together far scale across data center see nvidia investing three done obviously continued path accelerator building dpus bluefield 2 announced bluefield 3 got strong road map well going way bluefield 4 connecting interconnect data center together intelligently allow thing like computing operation done line speed network provide security isolation also networking people demonstrated eﬃcient providing kind service particularly use case important well needing performant seeing cloud provider provide infiniband infrastructure alongside ethernet good market depending different use case serve certainly demand ethernet infiniband growing quite bit want inaudible intelligently applying dpu rolling across seeing traction cpu side one interesting thing cpu traditionally connected gpu via pcie express standard bus continue support support long shall live basically opportunity another capability provide perhaps bespoke capability putting grace next hopper gpu tightly integrate two fact done grace hopper product announced year put two chip next built speed interconnect nvlink interconnect offer 900 gigabyte second bandwidth wo fully coherent big uplift get pcie maybe 100 gigabyte second 50 100 getting 900 grace hopper fully coherent gpu operate entire data contained entire server cpu inaudible gpu memory really make allow u work largest model like talked basically operating different scale seeing interest q brett simpson q jim fontanelli ian buckgrace hopper recommenders deploying nlp rest market going obviously well optimized run everything gpu continue exist quite time seeing interesting opportunity grace hopper sort push limit go training inference able deploy large model minimal infrastructure provides sort latency performance may spread model across multiple gpus able execute single gpu combined grace memory deliver large language model real time excited another interest hpc supercomputing community well really like coherence cpu gpu really love arm architecture ecosystem come long way term arm see everyone investing arm well across different vertical excited see take shape bringing grace market next year great interesting well think conscious time think good segue perhaps open q got colleague jim line jim relay question picked investor far yeah sure first question think quite straightforward quickly take hopper majority data center shipment yeah every transition little like little different see gaming side tends bit switchover data center operating enterprise use case people qualified deployed scale ampere a100 gpu obviously quite successful still quite diﬃcult get cloud try ask instance still show sold lot place expect continue trend usually transition happen period quarter different hopper becomes available different market first ph come market coming market pcie product get major oems hgx nvlink connected baseboard product coming market q1 next year cloud well h1 going transition differently also different region nature work work hard work take qualify server hyperscale entire hyperscale data center deploy scale fire forget data center massive way execute scale make sure best possible quality test work scale happen throughout 2023 expecting a100 continue 2024 well slowly blend saw a100 see q brett simpson ian buck q brett simpson q jim fontanelli ian buckcourse everything inﬂuenced economics market condition trend ai certainly lot largest customer large inaudible interested getting access hopper quickly looking forward seeing announcement reference ian long take a100 cross 100 sense benchmark yeah saw believe six eight quarter worth continued voltaire ph point largely tailed least think six eight quarter transition lot go obviously kind saw last time jim maybe got time one ... yeah maybe question might good place wrap question industry often look transition decade cycle think estimate around 3 4 server accelerated globally think market tam adoption curve regard server get accelerated go decade certainly picking mean one reason investing accelerated roadmap new gpus every two year new cpu every two year dpus every two year simply demand interest like cpu wait process technology transition memory technology transition dialed tuned manufacturing process ship often a01 silicon production product like ampere allows people get access technology even sooner opportunity acceleration become richer sooner unlike perhaps era moore law waited next technology transition get faster people want get faster faster main limiter think one main limiter number company isvs fortune 500 get building talent pool figure adopt technology use case nvidia provide platform case vertical platform like clara merlin recommender system maxine teleconference communication product solution way provide foundational layer allows enterprise meet inaudible gap q brett simpson ian buck q brett simpson simona jankowski ian buckthat player enter space get access technology affordably especially hopper reducing cost access perform ai infrastructure even perform ai infrastructure say ramp driver broader adoption platform across enterprise expecting like said still beginning little curve 3 4 expect isvs adopt company invest service get launched everyone number start continue curve even certainly era compute paramount access infrastructure key yet bit data center crunch perhaps importance running thing eﬃciently greener capability better usage power access compounding factor driving growth think going exciting exciting hopper transition yet another turn crank 2023 bring even happy keep coming back guy telling next thing roll ph yeah definitely take ian hopper anything good result saw ampere going interesting couple year good luck new product introduction next year thank simona thanks much time great discussion could gone couple page question guess read another time right well thanks much joining u guy really appreciate end session thanks much thank thank