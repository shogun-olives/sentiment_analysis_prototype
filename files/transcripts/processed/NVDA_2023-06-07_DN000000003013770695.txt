good morning good afternoon everybody thank joining u nvidia fireside get started simona jankowski going read u disclosure jump simona yes good morning thank much hosting u wanted quickly remind audience comment today may contain statement investor advised read report filed sec information relates risk uncertainty facing business back simona thanks well delighted ian buck couple year could talk last year conﬂicts ian veteran run everything accelerated computing nvidia interest level day relates ai includes hardware software enablement marketing activity ian known basically call father cuda led formidable moat around nvidia business term compiler technology acceleration library framework optimization could better person think talk happening world ai nvidia playing part ian buck q han mosesmann ian buck q han mosesmannso ian welcome pretty busy imagine yeah amazing journey amazing last year since talked actually last actually last six month even exciting definitely riding exponential cooking yeah question answer okay great start nvidia 20 year almost 20 year gotten even intense term going state ai today know lot discussion chatgpt generative ai brieﬂy state ai term nvidia view guy participating question think started go yeah like said journey far accelerated computing whole started making gpus programmable launching cuda 2006 investing ecosystem since internally within nvidia building software foundation platform accelerated computing well working everybody ecosystem everybody ecosystem enable gpus computing platform course broad goal certain market computing simulation others adopted first broadening since course since 2012 ai invent ai ph ai found u activation making everywhere putting gpu researcher canada able find realize thing working neural network inaudible others turn math pretty good fit cuda took couple inﬂection point along way ai first one basically initial work inaudible canada back 2012 initially enriching competition starting point really ai basic image recognition picture beach ball stop sign birthday party image recognition expanded form statement would image sentiment taking view web page tweet understanding positive negative sentiment understanding content described initial concept ai use ai initial production ramp saw probably remember jeff dean talking finding cat video example ian buckall right obviously hyperscalers cloud provider social medium internet needed understand content first place really turn data use ai understand people posting review product et cetera shift next shift ai became capable along way ai shifted recognition problem generative one able understand content text speech video whatever able generate meaningful content create content create product description would want user click link started small really hit fact set actually bert remember original bert model first model ability understand textbook produce simple text statement general text fact nvidia one bert day remember fact got noticed even market identify idea new kind neural network called transformer could understand text prior application ai basically looking neighborhood information building understanding localized data make sense image recognition recognize face first recognize individual shape certain position certain place face two circle nose line mouth build notion face localized language different language sort interaction speaking right filled pronounce context known part text speech far away saying right understand transformer based around idea attention figuring distant relationship incorporating neural network started bert mentioned google took offer gpt gpt transformer accessing idea nvidia obviously swarming convolution image recognition cnns focus still still growing important one transformer taken including video understand relationship primary use case speech human understanding speech language hard problem think computer vision like dog cat even bug basic computer vision brain perspective find highly tune reasonable job really human gift language built upon deep understanding knowledge first next inﬂection point transformer sort understanding knowledge able connect knowledge language mean understanding little bit generation q han mosesmann ian bucktoday era generative ai started two area two area kick one obviously image generation able describe like picture teddy bear swimming inaudible generates picture generative ai chatgpt able conversation understanding saying repeating back extracting information database back one large neural network generative ai make moved era recognition recognition important pick data understand content make decision based informed ai informing ai provide content provide review provide mid text engage customer generally help artist optimize business build new application build new kind service interesting also though unlike revelation like pc space mobile space guy seen new kind application new kind platform new kind software one generative ai actually making old stuff interesting look oﬃce 365 think could probably like saying stuff listening excel interesting word interesting generative ai wow way interesting yeah revolution seeing generative ai opt create new startup new kind service also making old stuff super interesting fun double exponential think really cusp begin generative ai everyone see opportunity guy market vc community investor community see amazing startup created make real super fun right seeing different application new service old getting amplified changed ai hey ian compute think lot people industry observer talk ai parameter complexity doubling every three four five month much longer half compute implication nvidia industry currently use custom asics even fi ph yeah great question one get asked lot first generative ai ai knowledge like access knowledge certainly access knowledge like database something courier pro found provider important reason gpt big mega megatrend 530 billion model trained supercomputer large capture knowledge level and/or starting point generative model drive model size thing drive model size well first model size tends limit know bigger model want extreme fact ph people build model limit practical want wait one training job build model scale constantly iterating model data tuning parameter give converge level intelligence lot ai training drop complete informe inform next one actually take many month year build truly intelligent model final change potential convergence effort thing drive challenge tends training time nobody want train month two think go past productivity hard innovate waiting long size model tends factor much capacity put place productivity scale general rule like people deal researcher one really developing stuff start building foundation model really want train training job take month inpatient make faster gpus figure connect faster together infiniband build optimized infrastructure thing like grace hopper new dgx gh 200 productivity increase train roughly month model substantially must get bigger get intelligent say one thing though model size one metric model size measured parameter 175 billion typical gpt people trained 500 trillion perimeter model behind closed door starting get little secretive releasing huge model drive u opportunity massive intelligence thing driving model design layer continually tuning intelligence layer making optimized clever layer reduces complexity per layer noise capturing parameter layer bunch math calculation instead naive connection human brain way similar different kind neuron vision processing versus auditory versus memory specialize layer design happens ai one sequence like know guy noticed one play something like chatgpt get forget previous conversation drift function sequencing much information confrontation keep store memory conversation sequence length increase compute size significantly term also training inference load captioning billion parameter much memory much need processed order make informed conversation going forward diversification going q han mosesmann ian buckhave lot different model palm llama see different specialization happening expect moving forward model naturally want get bigger encapsulate intelligence believe definitely seeing happen seeing integrate deeply intelligence database applying ai database create information better database super interesting go talk forever tied directly large model ai working internal system well inform ph get specialization happening seeing multiple different model specialization different layer sequence like keep conversation intelligent keep ai working memory adapt also significantly increasing compute requirement chicken egg saw try help think driving every time launch new architecture new interconnect technology new innovative thing grace hopper dgx gh 200 expand scope researcher developer nvidia research order move large language model generative ai forward next chapter probably reasoning interesting seeing right generative ai talk reasoning future kind neither going even harder blue sky problem well okay look like going growth category time listening investor participant like ask question click question ask question button right screen come read ian talk new metric kind interesting talking contact silicon valley maybe six month ago price hopper dgx hopper starting come really really expensive people saying way going pay kind price kind system much expensive say peer yet probably hand amount better part year kind brings mind issue ai model training inference little upfront price le relevant really tco aspect eﬃciency aspect come play determine come market architect compute gpus yeah really appreciate question one get asked lot community entire community world see pricing see sticker shock way usually realize take build hyperscale data center cost go dollar investment new people building datacenters scale get work hyperscalers productivity utility compute incredibly important order improve service improve optimize business increase revenue compute critical add generation putting right content front keeping engagement score high keeping product want provide service nothing annoying getting use add getting one actually thing want information need lead revenue critical people see maybe see cost gpu create opportunity invest build service make turn ai opportunity provides based competing data specifically though talk generation generation think introducing new gpu new technology market gtu revolutionizing compute capability also tco analysis today existing product next hopper provides six time compute performance transformer level implementing transformer layer ampere six time end delivering training delivering three four time performance complete training job throughput front even infronts optimized course think think look cost individual one throughput entire data center going based today going able tomorrow save ton money save ton money transitioning one generation next opportunity performance economic tco hugely favor term throughput data center productivity data center one billion dollar investment billion take build data center around world story play enterprise well moving workload cpu previous generous gpus new gpus throughput system rack data center data center scale measured x factor often certainly model model including also look breadth different workload including model represented image recognition benchmark see inaudible example inaudible guy heard benchmark created google sort provide field clean clear benchmark representative training workload since meta also contributing workload provide honest benchmark change correct level accuracy q han mosesmann ian buck q han mosesmann ian buckconversions requirement use measure performance market based previous generation see hopper done compared ampere interesting point stop ship continuously invest software optimization suffer massive part started software engineer manager nvidia cuda hired thousand software engineer others across company one reason job importance software interface rest world people consuming technology partnering framework like pytorch jax ton ﬂow everything else rest ecosystem user community nvidia point software engineer power engineer good march first round benchmarking something like hopper continuously improve fact ampere life got believe two half three time faster okay yeah first time go look first time submitted inaudible benchmark public think recently stopped submitting shifted hopper see 2.5 time x ph improvement model use case mean kind user experience think loyal community user developer community well biggest customer continuously optimizing whole stack platform along improve tco great hey ian get question interesting one expand current issue scaling sequence length might solved seems push new architecture favorable scaling function would risk opportunity nvidia advantage transformer engine yeah good question let elaborate little bit want working customer user community take relatively small large model larger input sequence length provides context conversation moving forward mentioned starting hundred going thousand want push higher increase compute complexity inference job want tune training scalability really important also capacity important creates larger working memory larger model inaudible way address one scaling obviously throughput multiple way optimize first transforming mentioned hopper revolutionary impactful may need called fpa ph fiable fpa eight bit ﬂoating point presentation basically eight zero one represent ﬂoating point number lot information number character alphanumeric keyboard example time two every character type eight per character roughly double balance actually move bit ph make training work fpa incredibly fast obviously computing eight bit faster computing 16 bit also memory size half would 16 bit ﬂoating point everybody really ph transformer engine specifically designed ca put expect cut number information eightfold exponential eightfold order make training successfully transformering ph hopper actually combination hardware software make sure transformer model train convergence information corporate community ton work make actually consumed massive amount supercomputing capability meet work understand tune figure keep thing within range eight bit mentioned sequencing reduce size model size working set fit 96 94 80 gig gpu depending ﬂavor available hopper course keep response time fast respond question range usability scale scale need gpu computing order expand scale amd link technology called amd link allows hopper 900 gigabyte second lot roughly seven time think get like pcie try use standard pcie connect new device start system basically combine two gpus together one split model actually execute model parallel across two gpus need much bandwidth gpus order keep thing going keep thing make allow gpus operate one start model keep latency response time low need go two gpus nvl h100 nvl product actually two pcie carved bridge inaudible system go across eight beyond use trick use infiniband go way ranger dgx gh 200 256 gpus connected amd link announced computex two week ago thing size model bigger model even need latency smaller model longer sequence link could q han mosesmann ian buck q han mosesmann ian buckbe served single gpu single hopper term performance grace hopper grace hopper announced talking gtc seen gtc conference check grace hopper basically 600 gigabyte gpu combine gpu upwards 96 gigabyte hbm memory cpu gloom together linking gpu take advantage cpu memory operates upwards 500 gigabyte 600 gigabyte second effectively 600 gigabyte gpu also help larger sequence link lot way actually pitty community analysis becoming complex matrix model size latency requirement sequence length blanketed space creating see u creating many different brand different product hopper pca form factor hopper amd link dgx form factor two pcas bridge together grace hopper used deploy inference scale good answer yeah apologize every day making sure working hyperscalers startup everyone else dial create new product address look like blanketing market various type product counter different proprietary new architecture emerged composed kind like saying yeah others multiple one click anymore nvidia roadmap think kind used pascal gpu three year later volta later ampere inaudible nvidia working diversifying way add value instead bringing build cpu gpus bpus work technical diﬃculty infiniband ethernet make platform different path play optimize connect thing together build different product within even within one gpu traditionally generation meet demand wherever want go based guy going q han mosesmann ian buck simona jankowski q han mosesmann ian buckso agility really important ai thing invented nvidia sort one ai company work every ai company seeing product meeting different see different aspect believe able dial perhaps parallel partner trying meet demand meet optimize workload thing say also accelerated gpu roadmap used gpu 100 class gpus every three year two year case cycle jensen talked timeline addition time would grace next time quantum next interconnect accelerated able invest chief sure every two year 18 month kind look good know got bunch question come lot time tactical one sure answer maybe simona come please talk effort source supply second half year nvidia define significant mentioned latest conference call yeah simona comment little bit conference call detail follow sure happy hope guy hear okay commented earnings call going substantially higher supply half relative first half year essentially back extended demand visibility see stretching quarter well commented seen pretty steep increase demand quarter way leading current time working closely customer ensure supply also helped underpin strong guidance gave second quarter even higher baseline second quarter commented substantially higher level supply versus granular exact linearity q3 q4 give u bit time get closer back half year able provide guidance okay q han mosesmann ian buckno pretty much much add certainly biggest customer course playing u everyone swarming generative ai part able working course plan planning continue thing simona mentioned time okay another question along line maybe answer biggest bottleneck nvidia gpus broadly much time think take industry build suﬃcient inventory supply level know well going comment specific bottleneck supply standpoint think challenge bottleneck perhaps adoption really bottleneck going broadening seeing enterprise pick ai happen people provider ai including nvidia need meet enterprise ai expertise either acquisition hired brought working closely startup others adopt ai inﬂuence improve business see large language model startup example providing really like work ai example know making easier use older software ai click button check box instead existing software degree thing ph meeting need enterprise term perhaps service taking appropriate model something useful really thing enterprise need provide right kind data take convert appropriate model virtual assistant chat capability lot activity right helping adopt ai workﬂows product work email product example exactly checking provide hundred maybe thousand two example text text gpt model way 175 larger answer question format context instead asking generic chatgpt question continue generic answer generic human generic unit would answer answer like financial expert support call expert thing connecting ai information retrieval system ask question get answer may may right certainly ca make chatgpt lie write code actually look right something made actually get actual sourcing information see little bit work bing broadly generative ai useful generate answer tell source explore result q han mosesmann ian buckso democratization connecting gpus industry big push right starting see early mover space next next wave gpu usage also revenue service thing like dgx great effort well partner going moving needle last question got minute let see keep 10 minute conversation biggest client hyperscalers enterprise changed last earnings call seems hear real call many make serious investment ai question quickly changed since conference call basically week ago know changed conference call certainly changed chatgptmoment generative ai moment converse probably continues amplified activity seeing street opportunity generative ai every one service every one capability seeing nvidia supplier gpus supplier infrastructure partner many level always partner hyperscale effort development server design data center build something even capable optimized every one unique challenge capability technology contribute working nvidia make work well amazon efa elastic adapter tell lot work make sure work scale hyperscalers also use infiniband working scale infiniband going platform ph always partner data center partner amplified side ph grace grace hopper cpu land space exciting step software side capability software infrastructure integrating different framework core capability broadening across service developer researcher get access infrastructure meet amplified always partnering inaudible jax others certainly continued grown seeing service group seeing nvidia also partner optimize latest platform offer generative ai seeing opportunity work le moving workload even still cpu easing little bit ai simplified ai using much intelligent larger model improve quality service better interaction q han mosesmann ian buck q han mosesmann simona jankowskiwith device even talking hockey puck kitchen counter cloud also partner optimize model 2.5x 3x a100 u working back oﬃce optimization customer biggest customer giving u challenge side side working optimize workload get obviously reﬂected thing like benchmark elsewhere amplified certainly engagement service team deploying ai figuring run use hopper use hopper scale inference better eﬃciently move workload gpu structure plan growth moving forward big part definitely gone quite check well could imagine well ian thank much enlightening look like going hiring another thousand software engineer hopefully interview exciting time simona thank well look forward group session later afternoon great day thanks thank hope see person got thank