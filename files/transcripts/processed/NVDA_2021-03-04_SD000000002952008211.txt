technical diﬃculty also simona jankowski going pas simona read statement simona thanks brett reminder presentation contains statement investor advised read report filed sec information related risk uncertainty facing business back brett question answer thanks simona ian maybe wanted set maybe set scene market guess 2020 breakout year strategically commercially nvidia division specifically mean launched a100 finalize mellanox transaction launched dpu obviously proposed acquisition arm chinese entity list restriction deal mean surging sale obviously crazy year clear least clear investor giant kind innovation phase compute right maybe break see front running division see course 2021 2022 think recognize still really early adoption curve accelerated compute going define year crazy 2020 crazy 2020 certainly sitting nvidia launched whole new architecture ampere gpu a100 launch home fact jensen kitchen think company slowed struggle execute think thrive environment already virtual global company knew launched kitchen virtually a100 great success u continues fact market today really give enjoy benefit ampere business 20x improvement previous architecture kind innovation kind improvement make generation generation able achieve look whole stack perspective chip performance chip obviously chip critically important ampere added new technology like tensor float 32 whole new tensor core architecture gaming visualization side also added ray tracing new ray tracing capability amazing optimize software stack well seeing right course adoption a100 targeted first foremost course ai cloud market broader data center ability train world largest model done ampere a100 also course seeing success hpc scientific computing strategy build 1 gpu 1 platform highly leveraged point different vertical capability market library sdks take advantage 1 gpu architecture underneath see moving forward first ai continues obviously grow software writing software defining application going interact cloud use business insight thing totally new technology something world still learning use even first principal standpoint see business grew lot originally hyperscalers google facebooks amazon alibabas world people technology knowledge go invent build scratch starting see broadening cloud starting consume gpus rest world learning use technology either nvidia direct software software partner ai stack working finally training side sure also increasingly enterprise brett simpson ian buck brett simpsonthe bigger company maybe need understand apply business use ai technology thing like understanding data ingesting understanding product adoption understanding recommend give customer also changing interact customer particularly covid kind whole new world video chat good mean guess since largely nontechnical audience wanted spend bit time market strategic opportunity see next couple year maybe first seen lot research breakthrough ai last 12 month mean bert large model size going crazy algorithm mean still still look like applied research domain lot breakthrough think one colleague bryan catanzaro saying maybe view possible company could spending 1 billion compute time train single language model guess practical application going see breakthrough seeing model size yes people still figuring limit ai sure think one area started computer vision idea picture basic question think largely mature well starting point ai 6 seven year ago asked asking computer question think pretty good getting pretty good also identifying different part picture putting box around even identifying individual pixel consisted face background ai green screening starting see consumerization technology bryan talk huge model 1 billion parameter hear new area particularly natural language processing area going beyond understanding computer vision think bug cat dog every intelligent life force intelligence level computer vision brain pretty small language language understanding however much broader bigger challenge right need understand saying right also mean intent understand take action respond communicate back way communicating ian buckyes much much intelligent problem opportunity large right interact human going interact computer data interact business actually language understanding document thing like chat bot recommender system sentiment analysis understanding dialogue making decision call doctor oﬃce help request financial adviser understanding meaning intent technology like virtual assistant chat bot want kind understanding improve user experience end make better customer conversational ai big thrust right call general conversational ai market huge 500 million support call year 200 million meeting going 200 million smart speaker world obviously new world covid everything digital going digital medium area could ai agent call help transcribe understand summarize capture action see people talking thing big model area recommenders think recommenders think interact internet search really recommendation go amazon browsing website buy something recommending thing visit news feed deciding see see obviously implication model present something accurate something likely buy also moderate content time huge data problem amount data across think every user social medium every news post every product massive matrix model tend large certainly data trying capture large getting even bigger seeing significant growth challenge ai also people buying infrastructure go right obviously highly motivated often go right bottom line economics brett simpson ian buckone example guess conversational ai microsoft oﬃce know audience know turn grammar checking microsoft actually using ai model based bert famous ai model language understanding finding grammatical error highlighting blue model got complicated trying understand language move gpu today run nvidia gpu live oﬃce 365 beta actually highly accurate grammar correction running sentence gpu running ai inference yes yes interesting maybe switching gear little bit ian term adoption curve technology mean mentioned computer vision ago thing kind solved moving next thing guess go survey talking cio ai coming spending budget big item big item today guess technology still feel quite nascent outside maybe top 50 hyperscalers developing model recommenders laid many organization think actually using accelerated compute today real scale yes think adoption curve followed like mentioned people capability use think adoption curve getting consumed 2 part training part developing ai service model use case deployment part inference deploying ai live service infrastructure adoption curve follow people first needed people understood data science understood like machine learning ops ﬂow capability understand published ai community apply particular business pretty small fact started hyperscaler think fortune 500 5000 others still relatively small see traction actually going isv partner community actually quite rich area find right partner understands particular technology working apply particular business use case see huge majority use case outside big hyperscalers starting way brett simpson ian buckand think community probably see activity ai right make lot sense lot smart people great idea could applied many different possible business use case point develop service partner probably data scientist company need turn deploy growth come different growth vector one training developing model course scale number people number problem model set size kind multiply 3 together kind get size training opportunity side inference deployment data service running amount data coming opportunity ai optimize scale amount data size business opportunity want gpu front every one connection run operate execute ai latency required service whether interactively news feed click got hundred thousand inference millisecond voice conversation maintain inference latency keep number utterance least speed talk mean guess obviously going take time lack data scientist really understand well see lot guy prototyping today kicking tire cloud trying figure going technology see path sort path see corporates building industrial scale ai going sort cloud hyperscale play providing service library supporting view think lot start cloud obviously easy take first step cloud budgetary standpoint paying hour certainly nvidia standpoint make assure architecture available platform real everywhere work major cloud provider activate make sure latest a100 gpus cloud customer use inferencing t4 gpus time make sure major oems access technology offer base gpus time market consume however want choose remain open way brett simpson ian buckthe adoption tends start usually data data resides cloud tends start cloud need data center privacy security reason people start usually kicking point thing get started experiment cloud get real stake start data scale certainly people look cloud bill decide whether want cloud many case see also stratification people want manage risk want make sure work multiple different cloud provider use case capability well manage risk want run different service necessarily locked one particular cloud sort one particular hybrid think people going necessarily naturally want vary industry industry sure talking cloud role think really play silicon perspective one hand buying gpus guy like google aws developing chip software see sort internal chip effort developing obviously resource nvidia reach love get thought term internal silicon effort well sure think first great everyone coming conclusion need accelerated computing mean ai use case great one compute turn software turn business opportunity work one thing unique nvidia forefront lot technology full stack company remember releasing gpus everyone get access start using also releasing software stack top well work tightly friend google tensorflow facebook pytorch many stack actually ml ops stack well also released container optimized version make freely available ngc container registry download get latest certified tested validated ai software work whether cloud ai company working ai company including hyperscalers take learning knowledge engagement whether recommender system conversational one brett simpson ian buckdoing stuff ai video chat like conversation well informs u help customer make product better library sdks better make better incorporate back platform corporation improving making framework better optimized vertical stack optimize feedback get right back hardware team architecture benchmark tune test team also see improve architecture make new investment architecture whether compute caching memory define next generation someone stay middle see quickly happens nvidia result releasing new container every month different workﬂows different framework well new architecture every year continuously innovate super done area rapid innovation great company get train bandwagon ride wave programming interface high enough level nvidia come along next gpu next version software see 20x saw ampere story repeat everyone investing think make total sense ai platform compute could write software think stand know making platform available everywhere customer benefit benefit think mostly advance adoption ai inside broader enterprise pretty exciting yes yes guess cloud specifically seen cloud compute big concentration amongst big player listen aws talk got 10,000 customer machine learning today become contemplated service market dominated public cloud player see large opportunity sell pod system corporates build enterprise channel yes think couple thing one definitely see one way consume ai sure service going stand different ai capability different service stand serve capability fine tune one software program run model widely different use case different streaming latency requirement wildly different think see wide variety different service capability everyone compete naturally vertical capability market term hybrid course decision people want make term much want consume utilization first foremost data superpod standpoint pod audience ability actually put together multiple gpus system create ai infrastructure broad data science team think ai gain adoption people going want infrastructure internally first allows optimize infrastructure workload model size model train thousand gpus optimized running embedded use case maybe different size different scaling scaling parameter something need get today starting see cloud also offer lot diversity different architecture cloud hyperscalers make decision make investment obviously hyperscalers decided scale want deploy something seeing option cloud also exciting offer different place point customer choose end boil rent versus buy decision come economics different conversation think way cloud versus ai different except difference want necessarily configure machine certainly training term know want put together going way infiniband stack going providing storage solution tightly coupled compute usually important training scale one reason built superpod selene made available customer capability obviously basically supercomputer offer community also supercomputer offer community get head start cloud starting figure participate well seeing infiniband happen csps cloud provider exciting different storage option obviously different brett simpson ian buckchallenge deploy stuff scale across multiple region making available rent making economics work well think going see lot diversification kind instance type capability different cloud people get access different way technology connected together yes yes yes interesting maybe mentioned selene ian wanted touch little bit infrastructure investment nvidia making look capex budget nvidia going annualizing 1 billion today know investing new campus et cetera nvidia see opportunity offer ai service enterprise mean see geforce business model early stage opportunity wider strategy service business reason see u building selene building infrastructure first successful ai practitioner like understand technology intimately understand advance like said one chip one core problem people want today capability super exciting need think like data center whole ca think programming one chip model big fit single gpu going case single server think spread across entire rack row data center certainly train time reasonable 2 week really want go keep data science team also expensive busy need training scale training thinking entire data center ca paper order successful ai thinking problem scale engineering organization build make product better sure also create product vertical market chosen car one huge portion infrastructure seeing today used driving car initiative nvidia drive work driving car customer give turnkey solution partner nvidia deliver car capability brett simpsonand build whole pipeline data ingestion labeling training simulated environment run car simulation crash 100 time without ever hurting anyone seeing work work ever put car actually test real time build infrastructure result also learned product make better certainly also research team specializing different capability learning advancing field forward also teach u lot product term service work one market one use case right strategy make available ai platform every different hyperscaler oem enterprise consume develop capability remember phase new form computing people figuring deploy use different use case market choose go vertical advance forward done car also done conversational ai like mentioned software stack called jarvis come pretrained model help speech recognition language understanding also capability done recommender system published software stack baseline capability large recommender system scale informed engagement hyperscalers call stack merlin also video collaboration stack ucaas stack called maxine used improving experience right zoom helping apply ai technology thing like noise cancellation green screening super resolution et cetera choose really help advance ai field forward different usually go way turnkey solution usually go active enablement rest market take deploy technology see benefit maybe ask ian guess look back v100 cycle data center division bit lumpy good time slower time guess take time customer digest buying need next amount compute think going ian buck brett simpson ian buckthe behavior going see a100 think different type market time around getting faster every time think market maturing saw v100 remember three year ago wave ai requires time people absorb understand technology see next ramp think coming software matured way go market technology software matured going much faster u certainly see digestion sense product transition obviously people want refresh large ﬂeet like hyperscaler happen experienced v100 a100 much much happening much faster fact grew data center business many company think struggled saw downturn think rapid adoption ai observation 20x need go next platform really pulling product forward making sure get market quickly possible making available think transition happening faster always going transition manage certainly spent lot time focusing prime pump make sure everyone get platform ready make technology ready early people understand hit market everyone ready absorb backwards compatibility big part making sure framework ai software stack already ready go day 1 wait people test hardware try reporting ahead simulation early version hardware get ready launch stack ready go think improved significantly since v100 a100 yes excellent maybe competitive dynamic see ahead mean dominant franchise particularly training also getting accelerated compute come inference great look 2 three year sustainable think position market share position accelerated compute look like lot taken lot longer get market look 2 three year perspective market share lot change 2 three year mean think ai 2 three year ago today continues evolve grow model thing talking widely different used talk imagenet used talk resnet kind like table stake ca conversational ai natural language processing lot opportunity growth coming already place think one part think technology ai evolving really rapidly important practitioner ai order keep trend understand model actually art craft learn lot system engineering computer architecture interconnect storage system whole data center think look time frame really happening thinking data center computer really new data center designed designed train network scale give data science team throughput keep tool develop natural language conversational agent going right use case problem size trying solve huge every product every user every data point every news feed optimizing nvidia shifted company thinking data center unit compute includes gpus system networking increasing cpu fit together broader software stack kubernetes workﬂow manage enclave data scientist different service developing thing turning around ﬂipping infrastructure applying inference mentioned inference 3 four year ago vast majority inference done cpu today compute gpu compute inference compute cpu hyperscalers add ﬂops capability came a100 designed a100 started seeing trend model getting bigger capability want get smarter cpu could keep term executing model latency necessary nlp model conversational agent talked particularly recommenders newer model brett simpson ian buckresult workﬂow people started deploying gpus saw t4 gpu used hyperscalers today inference a100 made architecture excellent great training gpu also tensor core run operation necessary inference reduced precision stuff either inaudible fp16 also capability called mig gpu gpu actually inside split 7 separate gpus presented independently system people take gpu bought training turnaround serve inference use case 2 3 faster previous gpus one single slice seeing adoption need good training inference certainly workﬂow allows seamlessly go training inference really important able obviously run new model area conversation recommender super key maybe switching gear little bit ian maybe get update arm situation mean update arm acquisition would great also interested asset data center perspective mean see role nvidia see general purpose cpu arsenal long time develop server architecture based arm general purpose server architecture see arm opportunity data center well certainly data center new unit computing look advance nvidia advance data center certainly focus talk think arm standpoint creates premier computing company age ai combine latest nvidia leading ai computing platform arm cpu expertise help position arm nvidia arm customer entire ecosystem customer next wave computing age ai course ai also powering internet thing thousand item bigger internet people point make exciting certainly expand arm ip licensing opportunity allows u offer nvidia technology large end market including mobile pc turbocharger arm server cpu road map help investing road map advancing arm brett simpson ian buck brett simpson ian buck brett simpsonmove faster accelerate adoption data center edge ai course iot certainly expands nvidia computing platform reach today 2 million 15 million developer exciting customer excited think partner excited opportunity great ca succeed unless arm customer succeed guess see important step cpu capability data center house think particularly business scaling much cpu becomes fundamental solution going forward think always needed fast cpu fact amdahl law still much law unlike law make infinitely fast gpu accelerate entire workﬂow entire problem may accelerate 80 solution infinitely fast still 5x faster stuck 5x think ai accelerated computing general data center scale investing data center data center scale cpu dpu gpu component parallel serial i/o networking really get achieve 20x speed ups talked think entire canvas innovation canvas talking order achieve performance see ai continue advance continue allow breakthrough happen turn business opportunity world enterprise excellent interesting well think time ian say really appreciate time great great discussion could go lot longer many question really appreciate coming event today chatting u problem time thank next speaker starting minute samsung network evp woojune kim please click zoom session thanks much ian thanks time bye thank thanks simona