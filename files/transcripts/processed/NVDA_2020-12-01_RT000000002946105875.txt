perfect thank good afternoon good morning everybody wherever aaron rakers hardware semiconductor analyst well fargo think first time get host meeting well fargo nvidia extremely excited obviously company extremely successful looking forward conversation jump ian buck vice president general manager tesla data center business want hand real quickly simona jankowski kind go disclaimer thanks aaron reminder presentation contains statement investor advised read report filed sec information related risk uncertainty facing business perfect thank simona ian pleasure host discussion maybe kick audience familiar kind role maybe give real quick background responsibility nvidia jump right question yes sure hi vice president general manager data center gpu business focus gpus go server either cloud data center specifically focus hyperscale market ai well hpc scientific computing server ph computing result team focus product lineup bringing new product market gpus also lot software go making platform successful ai well generally accelerated computing q aaron rakers ian buckquestions answer question answer yes perfect mentioned started presentation watched supercomputing conference week two ago go ton detail ai kind strategy around wanted start discussion kind latter point brought software ecosystem importance think clearly visionary cuda importance cuda ecosystem see landscape evolving around importance software ecosystem stickiness cuda platform asked little bit context seen others really validated got intel moving oneapi got amd rocm xilinx vitis forth let start let talk stickiness see cuda importance yes mean started probably 15 year ago recognized new kind computing happening area started computer graphic really simulation light environment around u different kind computing focused back nvidia focused accelerating computer graphic literally writing encouraging developer giving platform write program determine color every pixel think processing graphic pixel level 10,000 1 million program run parallel generate image folk like others recognize computing horsepower could used thing video game back 2004 started cuda build platform accelerated computing taking portion application whether hpc anywhere accelerating inner loop important computational portion get new kind platform new kind architecture massive parallel processor long journey 15 year developing sort accelerated computing platform today probably complete advanced robust platform consists ten thousand engineering person year create 11th generation cuda way programming gpus point entire platform entire platform library call ranging signal processing numerics linear algebra course ai machine learning computer vision image processing well audio thing fact q aaron rakers ian buck q aaron rakers ian buckit expanding even vertical workload conversational ai technology like jarvis recommender system system like merlin video collaboration platform like maxine building platform made successful productive many people point think 18,000 1,800 application application catalog accelerated two million developer developing platform think talk productivity accelerated computing nvidia gpus cuda brought community take application make something never even thought possible computing horsepower gpus offer yes one common question gotten time time seems ebb ï¬‚ow stickiness hear around tensorflow pytorch hey write directly mean guess think answered question little bit prior answer much application layer write become verticalized library depth see anything competitively changing context cuda stickiness well one thing made really successful broadly adopted availability early decided critical decision pivotal decision make cuda enabled available every gpu video produced result think shipped 1 billion gpus recognized early even though make bespoke one platform one product line mean every product line innovation happening world research lab dorm room fact ai alex krizhevsky sort wrote literally first ai framework convnet student canada saw stuff hpc gaming geforce gpu ported think access availability platform literally able consume available every cloud every oem every data center every gaming laptop creates innovation make possible u accelerate many different workload people see opportunity figure apply either programming gpus directly using one library going vertical stack using ai framework yes yes q aaron rakers ian bucki think unmatched think something truly unique marketplace wide availability breadth innovation happened nvidia provides people player innovating top platform make successful say yes great point time tiptoeing towards another layer accelerated compute right thing nvidia driven others right around data processing units/smartnics guess maybe little bit lost people building similar kind software ecosystem stack top dpu strategy mellanox bluefield talk little bit doca importance doca envision role dpus evolving data center yes explain clearly trend happening data center general pivoting around use programmability see data center used programmed vm one cpu today data center redefined becoming programmable many different layer program entire helm chart concatenated many microservices together build data center cloud application running across many different node many different instance type addition program gpus cpu two kind computing platform inside system cpu obviously continues provide really important role environment additionally connecting gpu node together unique fast interesting way nic nic becoming critical part data center also programmable part look people oï¬ „ oading security operation virtualization stack moving closer network node connects rest data center oï¬ „ oad lot computation workload latency operation one thing recognize instead programming cpu entire data center becoming one programmable unit thing people program aspect whether connecting kubernetes container moving different part application accelerator accumulate cpu well oï¬ „ oading many operational system security virtualization task nic networking platform even going step starting see computation happening network way traï¬ƒc ï¬‚owing optimal place may switch example particularly popular hpc one thing recent acquisition mellanox accelerate networking stack able program programmable part entire data center solution doca data center chip provides programming platform accelerated networking adapter allows people kind program q aaron rakers ian buckand develop level oï¬ „ oad running security chip well offering virtualization oï¬ „ oad onto processor well take advantage many different accelerator inside bluefield interconnect nics ph accelerate data center operation see opportunity saw accelerated computing back started cuda doca programming data center scale optimizing data center communication data center application yes yes awesome let take little bit step back think data center business total think tam addressability nvidia opportunity right think laid 50 billion going 100 billion underpins think attach rate gpus think evolution dpus far attach rate evolving talking customer seeing happening front clearly nvidia data center business far outpunching server growth profile seen recently last quarter yes mean server data center market obviously gigantic market total actually fairly small part right think causing nonlinearity adoption application use case benefit gpus accelerated computing notably started hpc simulation smaller market important one recognized first saw end moore law many guy thought talking realized needed alternative path caused growth obviously recently adoption ai broadly machine learning benefit gpus break machine learning dramatic often 1,000 cpu server replaced single like system performance also cost huge tco saving 20x case processor gpu designed kind application serial processor fast execute one thread execution fast execute 10,000 different program operating entire data set ai work data ml work data designed kind processing continually optimizing along way since first started path ai kepler generation pascal volta turing ampere continue optimize architecture standpoint driving lot growth adoption technique different market obviously started hyperscalers talent invent technology ground folk like google amazon microsoft alibaba baidu facebook others obviously ai talent q aaron rakers ian buck q aaron rakers ian buckwhat seeing obviously take market continue see opportunity ai grow use case internally also rest cloud offer public cloud offering gpus seeing consumer internet company snapchats pinterests zoom zillows world consume benefit ai improve recommenders conversational ai agent data processing next wave think growth enterprise general bringing service solution enterprise take advantage ai necessarily ai brain trust google might ai maturing technology machine learning general see benefit gpus served either programming directly using understanding using tensorflow triton inference serving using managed service delivering capability yes mean thought around attach rate progression gpu attach rate think also dpu side mean jensen pretty clear like could evolving path almost every majority majority server actually incorporate form dpu smartnics yes think early dpu early dpu term today attach rate however believe every server dpu simply oï¬ „ oad virtualization security management task logically happening unnecessarily cpu could oï¬ „ oaded networking network rest system leaving rest cpu available end application user performance designed saw similar experience aws nitro moved infrastructure support separate processor let free cpu core cpu capability end customer manage infrastructure true vast majority market believe doca bluefield yes yes talk little bit system strategy mean seen nvidia selene show top 500 list supercomputer company clearly pushed deeper dgx think recently announcing dgx station a100 guess responsibility deep nvidia go path full system strategy business glad asked question lot people get confused nvidia also system provider think important recognize like said q aaron rakersthe data center reinvented business opportunity accelerated computing gotten large enough break traditional mold box design really think entire data center design envisioned canvas ph earlier breaking pcie form factor building custom baseboard solution better optimized allow gpus talk eï¬ƒciently exploring leaning gpus potentially node system well work infiniband data center scale interconnects innovation space huge requires lot investment lot invention diï¬ƒcult traditional oems invest kind money capability capability start 0 billion market cost take significant r think scale invent scale take burden two reason one user car initiative product drive platform research team finding different way apply innovate ai general product well research saturn v infrastructure used optimize first take design innovation package product bring market meet tip spear rest market dgx platform dgx superpods selene based provides blueprint template rest market follow clear way bring market completely customer want buy directly direct relationship nvidia configurable lighthouse juggernaut offering help pave way market take different component make available partner take baseboard inside dgx inside selene give hp give dell give inspur rest market give cloud provider baseboard available microsoft amazon dell hp software stack well optimized everyone get benefit people could consume technology however see fit goal make available everywhere whether cloud rent server buy way system business help lead market importantly accelerate innovation data center space yes one question got kind put mean oftentimes asked question around cloud hyperscale cloud internal development effort competitor realm ai seen ian buck q aaron rakersaws done annapurna asset forth see competitive landscape cloud customer evolve sure think ai general obviously revolution computing general think world able achieve ai far outpaced even science fiction 20 year ago make sense everyone obviously investing ai solution capability cloud compete going provide channel different option capability like seen also try attempt differentiate seen well think nvidia ai company work every ai company accelerate different workload different capability help improves advance platform able innovate rate unmatched think see specifically result mlperf benchmark created google help separate wheat chaff lot claim lot people saying flop capability proof pudding eating come form mlperf set standard guideline performance accuracy see result able outperform competitive hardware still show think important aspect everyone going try differentiate specialize way fine nvidia standpoint standpoint strategy change make sure continue work every ai company every ai customer give u opportunity visibility capability continue move platform forward going volta ampere delivered 20x performance ai three year come innovation engagement different customer serving different need well looking inward architecture importantly software continue advance ai everyone democratize everywhere keep u toe make job constantly learning new application ai make faster optimize hyperscalers well new emerging workload enterprise yes next question extent kind go detail share arm acquisition data center piece arm still early right arm truly competitor cpu side market think strategic merit owning arm whether kind better together hey building system stack strategy optimizing data movement across cpu gpu memory interconnects et cetera et cetera important arm data center side ian buck q aaron rakers ian buck well think arm mean think announcement today seeing people innovate arm across board nation investing arm supercomputer computing platform covid research cloud investing delivering arm capability think new way improve cost performance application performance provides rich innovation platform people innovate whether leverage arm ip design arm probably ubiquitous cpu platform world surrounded arm device right sure think combining nvidia leading ai technology platform yes better together advance ai cpu ecosystem dramatically platform already serf today well well new opportunity data center cloud computing broader sense data center three processor cpu dpu gpu bringing three one roof innovate new exciting way acquisition still ongoing going wait completes talk space opportunity see front u go broader innovation happening data center whole yes appreciate answering question helpful know probably better question maybe colette going ask answer way balance getting supply relative demand appears a100 ampere product cycle think nvidia currently thinking getting balance data center side point mean going take several month catch demand think exciting sort interest growth training inference delivered record number quarter t4 example every time introduce new architecture game changer right a100 20x better perf v100 come new wave demand interest product meeting demand always exciting time certainly help bring platform market whether hyperscalers bringing online oems launching product well rest market take several month catch demand always exciting time platform refreshes experienced get injection new hardware meantime continue improve software value proposition stop launch new gpu q aaron rakers ian buckin fact even release isas gpus coming software constantly updating team responsible delivering new container tensorflow pytorch base framework well inferencing stack triton jarvis merlin maxine pumping new version every month constantly moving platform make fun exciting customer course operationally meet demand four minute left hinted t4 record quarter inferencing side last quarter one thing a100 clearly emphasized convergence training inferencing outside t4 reaction harder u see inferencing versus training successful kind convergence mind yes going get little trickier may know tensor core tensor core core optimized ai operation started volta architecture focused training turing architecture add version inference ampere combine two actually added hpc well fp16 intense core ph capable ï¬‚oating point calculation hpc fp16 bï¬‚oat16 training well fp16 int8 inference ph tensor core seeing lot customer take advantage performance capability a100 training inference instance cloud hard u track people using a100s cloud live obviously vary used batch inference reframe model want rerun inference going use a100 pro forma platform also use live inference inference service developed technology like triton allow multiple user multiple model run ensemble one a100 gpu optimize infrastructure rolling exciting compare amount inference capability shipped cloud form gpus spanning volta t4 a100 huge boost inference capability total flop available cloud inference gpus available cpu first time think exciting tipping point a100 massively powerful inference gpu well training going little bit tricker sure people excited training capability expect first primary use case people adopt a100 inference see trend continue still expect t4 run certainly market edge kind server want accept one two q aaron rakers ian buck q aaron rakersgpus inference capability obviously work cpu well a100 particularly a100 mig capability may change game lot new customer learn consolidate optimize inference using le infrastructure save money get benefit a100 final question going ask kind secular thematical kind question around really kind got extremely excited data center opportunity proliferation complexity ai model right google bert ph nlg microsoft et cetera slow rate expansion parameter expansion whatever want however want think ai model see part slows ever right chicken egg developed model size infrastructure allows build customer willing buy single gpu instance single a100 design system superpod get bigger look thing like ph openai requires massive number gpus train exciting part time conversation ai advancement natural language processing computer vision recommender system particularly last two recommender system conversational ai true human intelligence something simple picture recognizing picture something conceptually human dog cat even insect recognize capability recognizing vision system see language processing able answer question understand word saying meant coming sensible answer help find product want internet conversation bot constructive helpful really intelligence intelligence far one seen endpoint number parameter solve problem even close number neuron brain continue grow foreseeable future somebody figure get point build infrastructure get lot innovation right combine gpus together data center electrically mechanically computer technology also algorithm numerics make work one really hard problem get work nvidia also get work partner microsoft openai others figure well ian buck q aaron rakersawesome ian ran time could continue go kind jump really appreciate thank much letting u host conversation appreciate sure right ph thanks thanks much