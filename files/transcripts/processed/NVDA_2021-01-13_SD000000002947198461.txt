good afternoon everyone thank joining u annual technology internet conference toshiya hari cover semiconductor semiconductor capital equipment space goldman sachs honored excited u today ian buck general manager vice president accelerated computing nvidia 40 minute list question ian webcast please feel free type question try get toward latter part session ian like get started first thank much carving time busy schedule sure pulled sort direction really appreciate question answer technology conference suspect investor audience know heard speak past level set audience hoping could talk little bit responsibility nvidia although pretty sure thing typical day curious spend time internal responsibility responsibility thing yes sure thank bother wonderful break thing get talk little bit thing done going toshiya hari ian buckmy name ian buck general manager accelerated computing nvidia long way saying responsible gpus go data center le graphic gaming forward compute ai focus csp market day filled talking like amazon microsoft facebook apple baidu tencent alibaba name hyperscalers obviously nvidia course special relationship given work also responsible work hpc traditionally background joined nvidia 2004 started cuda 2006 came built engineering side mostly focused computing hpc use case still today huge part business obviously grew encompasses hpc ai today time spent hyperscalers larger supercomputing project surprisingly conversation tend similar sometimes ... got great intro thank much wanted kick post introduction asking sort look back reï¬‚ect 2020 potentially look forward 2021 2020 clearly challenging year many u global economy time many secular trend technology space expected occur next 3 5 10 year seems accelerated pulled sit ian key highlight business 2020 top priority team 2021 yes go answer question want remind audience investor team reminds presentation conversation may include looking statement investor advised read full report filed sec information related risk uncertainty facing business way get question certainly think anyone could imagine kind year real test lot company market covid come switch oï¬ƒce environment meeting customer safe space traveling everyone home maintaining social distancing business inability travel event conference going virtual well engaging customer data center drive lot ai innovation come experimentation development ai course one world largest ai computer upgrade continue invest term achievement year certainly execution wise think everyone nvidia proud able took covid seriously early went home back february despite despite culture still able execute launched ampere generation gpus a100 gtc conference spring home run work pulling together launch finalizing product taking market getting hyperscalers oems activated product happened covid result result performance great 20x performance previous generation product faster anyone expected meantime upgraded data center ampere competed competition like mlperf virtually covid delivering leadership performance training inference challenge ai slowing research community slow either continue deliver faster better smarter neural network basically neural network accelerating doubling basically capability size term number parameter every 2 three month date back like 30,000x increase computational complexity neural network racing meet demand innovating whole stack course hardware a100 helped lot year big trend year finally saw inï¬‚ection inference side business got ampere gpus growth t4 cloud inference workload add ï¬‚ops gpus available inference cpu available inference actually tipped scale compute gpu inference cpu great thing driving recommender system people figuring apply ai ad placement content prioritization research one nlp natural language processing speech workload able transcription virtual chat bot kind workload order magnitude complex main use case past focused computer vision way like explain computer vision baseline capability sort think see understand seeing silicon dog cat even bug basic computer vision understanding toshiya hari ian buckthe recognize image good bad understanding language whole another level intelligence understand said rate speed say meant come answer human nowhere near superhuman level nlp yet trying get one thing openai demonstrated turning around useful service business company really well covid mean hard time sure story data center upgrade maintaining protocol even robot supervisor walking around observing people making sure wiring done right able pull result got market rewarded customer appreciated certainly time people care cloud deliver platform ian maybe top priority coming year certainly seeing growth continuing rollout ampere ampere product see mean definitely see emphasis vertical workload conversational ai software early still beta go widely also recommender system also seeing applying technology video collaboration platform maxim product obviously invented last year going come market activate conversational huge market 500 million support call 200 million meeting day huge area ai content opportunity add value recommender system challenge recommenders common looking looking one picture telling everything customer sale data web traï¬ƒc web content star like review much richer opportunity people figure different way apply technology see inference definitely growing conversational ai recommenders 2 big driver natural language processing general new neural network going stop people going continue build bigger impressive capable ai need infrastructure order deliver get done lot toshiya hari ian buckgoing happen year certainly ai front stuff pretty excited got definitely want come back thing talked term inference performance improvement a100 go wanted ask software analyst semiconductor background like tend spend little bit much time hardware side maybe little software side pretty clear based accomplished nvidia accomplished software critical component support growth business hoping could take u back working cuda guess early 2000s drove company overall create today critical platform support business explain u cuda evolved past 14 15 year contribute competitive moat guy data center accelerated computing early certainly roadshow asked lot people industry cared computing compute focused needed way people gpgpu graphic card using graphic apis couple thing came clear first want learn new language want easy access take programmer developer give way program system cuda based c extended fortran language make really easy developer grok ph gpu express kind parallelism without learn whole new language whole new platform think largely achieved teach developer cuda day long understand concept thread decent c fortran programming get hpc space model extended others one quickly evolved building platform ca program gpu people expect certain level library capability get work done software today developed entirely combination different library technology needed make median application work certainly compute space work quickly grown quickly grown building entire platform sdks library enable starting basic math library single processing linear algebra operation sparse algebra dnn library video codecs dali input output processing 80 sdks track different industry give way program gpu one step library capability already optimized gpus backward forward compatible use today go volta 100 ampere get 10x right like without customer platform get enjoy thing think platform grown substantially since first day program kernel program one piece code gpu providing different must hundred library mentioned 80 sdks make successful thing recognized big secret success fact full stack platform try like standardize define isa fact even release isas gpus decided tackle problem higher level meet programmer programming expressing problem different way want consume keep innovation space deep could innovate broader software stack underneath well hardware change hardware time result huge number software developer think actually software developer hardware developer nvidia building investing algorithm library write code optimize gpus meet developer algorithmic work meantime also give u ï¬‚exibility completely redesign architecture break isa compatibility day long fact order move needle forward learn engage customer think big part success look whole stack even people engage acquisition industry stay focused certain one know going add value optimize whole stack chip library compiler runtime vertical stack critical decision early worry isa compatibility meet provide whole innovation space really get 10 20x kind performance see number toshiya hari ian buckinnovating way programmer need u developed volta kepler fermi ride wave platform enjoyable many people got thank ian wanted shift gear little bit talk growth driver business sort touched earlier response hyperscale obviously important market sort business turbocharged growth overall data center business spoke thing like conversational ai recommender system important driver business year obviously going forward based conversation amazon google world thinking growth sort killer application hyperscale business yes hyperscalers tend tip spear serve market term renting inference sorry infrastructure well meeting customer often development team engineering team go invest build first adopter kind use case like saw ai beginning result obviously important customer learn lot engaging partner help take technology market whether conversational ai language processing next model recommender system learn lot engagement serve well enjoy developer enjoy platform time turn around turn service provide core infrastructure rest market rent engage take longer rest market catch google obviously brain trust google amazon alibaba happening fact vertical industry running half business hyperscale representing 50 data center revenue vertical industry represent another 50 catching learning technique part sdks library application framework build scratch industry ai prowess consume library service rather developing time think data center edge use case much larger hyperscale world industry consume footprint learn adopt toshiya hari ian buckthis technology obviously seeing applied everywhere end choice want consume whether cloud managed data center push edge based problem use case job basically activate 3 let customer figure choose amongst based use case certainly seeing early adoption vertical space certainly manufacturing transportation health care retail financial service certainly early adopter company like bmw ge walmart american express example figuring apply technology certainly get involved engage one fun part nvidia company ai company work every ai company able learn engage facebook time amex able bridge technology capability recommender system may used social medium site looking fraud credit card transaction different use case underlying system recommender system trying understand litany unstructured data right choice anomaly might system got sort next question ian traction seeing enterprise side mentioned business roughly today health care financial service manufacturing listed couple vertical seeing traction could shed light thinking enterprise market medium long term relative hyperscale probably hard put exact number think relative growth profile enterprise hyperscale think adoption cycle enterprise relative adoption cycle ph adoption technology couple 2 camp think always presence hpc side course oil gas industry need supercomputer seismic processing connect market well continue likewise simulation space imagine think ai adoption enterprise still fairly early early day expect grow significantly challenge consume adopt right product consume adopt making little bit easier ca give tensorflow hope train model toshiya hariin end focused vertical sdks solution stack one focus around jarvis conversational ai platform providing complete asr nlu tt pipeline pretrained data ï¬‚eet dgx system enterprise customer get something transcription box may training even provide framework tune generically trained model understand phone conversation augment information ordering prescription teach prescription name recognize already teaching someone already well understood even know speak english know conversation ai start beginning truly starting baby know nothing huge engineering test bring speed see model like bert offer capability train certain level intelligence specialization stack really exist starting exist focus driver stack provide conversational ai similarly merlin recommender system maxine ucaas kind conversation collaboration platform providing needed enterprise adopt vertical sdks need bought sold like product managed maintained little different little different engagement might see hyperscaler obviously developer developer done pretty well full confidence know certainly different market today lot quadro rendering business done way lot early ai adoption seen great success triton inference software building excited see come fruition year moving got ian wanted ask inference couple year ago one common reaction investor nvidia dominates training market plain inference mostly cpu based forth obviously ton success t4 a100 guess recently noted aggregate nvidia gpu compute capacity available inference cloud exceeded cpu sort secret sauce big driver term done well inference date ian buck start model complexity obviously training order magnitude complex inference train model inference back propagation lot competition obviously requires started many early ai model computer vision space others cpu infrastructure certainly suitable execute forward pas ai reasonable amount latency also people existing software simply call user framework kick inference capable changed model complexity model complexity model traditional use case new use case cv computer vision went nascar cnm ph got harder put bounding box around people thing object actually identify every pixel attempting real time high throughput became prohibitively expensive nlp driver bert model example also dlrm dlrm deep learning recommender model basically reference recommended model facebook submitted mlperf much harder execute latency requirement might recommender system language system conversation ca take second inference respond 100 millisecond take network traï¬ƒc load time slot actually inference quite small interaction use case recommender system even worse actually run recommender thousand product get click answer immediately driving growth see t4 record revenue t4 shipment q3 get t4 gpu priced differently different product focused inference hyperscalers see driving lot strength part software software problem gone away delivering best performance problem chip lot ï¬‚ops algorithm optimization software stack execute right precision maintain accuracy continue provide high throughput investing software called tensorrt sort deep learning inference compiler take model trained tensorflow pytorch whatever compiles reduce precision fp16 date run toshiya hari ian buckon top found challenge deploying inference made also easier kubernetes environment triton software like turnkey inference engine give throw fire triton across kubernetes home chart need send data give inference back lot customer trying optimize inference infrastructure triton super helpful help people deploy run cpu run gpus support different major ai framework even includes huge uplift help business make easier people deploy inference instead trying shoehorn existing application call software huge part training one job inference entirely different latency throughput accuracy quantization graph compiler fusion matter lot diversity got work kubernetes infrastructure prometheus monitoring system stuff work order get stuff production lot software investing couple year thrilled see finally take great use case amex fraud detection one walmart using inventory management even microsoft oï¬ƒce grammar correction right done cloud cloud azure checking grammar gpu yes ian term think growth model complexity feel like customer manage perfect thing like conversational ai recommender system pretty darn complex fair sort extrapolate current slope term rate model becoming complex future could even acceleration think male ph recommender system still open tapped curve slowing openai approved continue go right seen chart model complexity one shown end language neural network close human level neuron naive parameter neuron basis still clearly least one existence proof got another one 2 order magnitude go toshiya hariand way training scale get really complicated get net whole thing learn converge expect continue application nlu different use case specialization network simple people want extract language varies compared like image image recognition box bounding box much complicated language sentiment search want find data information structured data imagine take new york time read new york time come fully structured table information could used search cybersecurity another example like every network log able build extract structured data look intrusion detection application space go get really broad nlu exact story play recommender system even complicated data data tends unstructured well application use case widely different make ai super exciting application space keep becoming broader diverging result variety different neural network platform need run get complicated think one reason invest much different vertical use case get experience bring back core platform figure optimize think network complexity going slow people continue get human level language understanding intelligence interestingly think application use case applied use case continue expand diversity model cambrian explosion big bang ai going get exciting people apply variety different use case speech way creating human reliable human speech applied ai problem done many use case still turning good ai speech use case still developed fascinating stuff shifting gear little bit wanted ask road map mentioned earlier rate innovation gpu accelerated computing staggering think spoke 20x improvement a100 based working today visibility internally road map would characterize sustainability technology cadence outside 10 going 7 going 5 lever ian buckhave pull hardware side software side maintain cadence yes huge part full stack optimization going new node technology change parameter obviously good baseline go different new technology eï¬ƒciency performance particular power level increase also run processor different power level change shift time great give new option transistor performance huge product performance come though software algorithm improved volta performance day launched gtc day launched a100 three year later different gtc 4x came innovation algorithm compiler working community improve overall holistic platform running v100 gpu server result try crank software optimization fast publish new framework container every month whether tensorflow pytorch help improve accelerate training look bottleneck training pipeline see make faster make core ï¬‚ops faster matrix multiple layer lot i/o pipeline start show amdahl law expletive show lot place burn actually work optimize use case invented library called dali preprocessing image processing cropping angling preparing data trained gpu cpu could keep applies audio data processing nvtabular library processing structuring lot data used done cpu gpu put right next framework data optimized move quickly huge part make platform successful generation generation wait new hardware release constantly pumping technology come together holistically look top bottom software algorithm solution make thing lot faster course cuda compiler run time course work operating system optimize low level optimization toshiya hari ian buckthat course go gpu improved redesigned throughout old isa bring new one designed core sm architecture see trend shift hpc ai scale look data center constrain one gpu pcie card broke mold turned gpu side turned mezzanine product built hgx baseboard go dgx platform go hgx go hyperscalers oems take step look interconnect acquisition mellanox look building data center scale supercomputer work one throughout solve ai challenge help define future ai software stack data center scale optimization done generation generation kind need think way ai getting big one gpu one processor run layer fast apply technology develop ai workload science data science feeling constrained want push limit provide way training scale like demonstrated take advantage develop generation ai got mean touched mellanox little bit speak dpu opportunity see next couple year yes think super exciting acquisition mellanox look computing network data center scale networking space nvidia bluefield example taking networking building dpu programmable data center chip open another 10 billion tam nvidia dpus doca counterpart cuda platform help architect modern data center optimize data center scale networking area security network compute able make data center malleable turn supercomputer cloud resource capable insert programmable networking platform ensure security isolation right level oï¬ „ oad impact performance toshiya hari ian buckso problem trying solve early journey certainly worked worked mellanox little decade hpc space culture compatible engineering driven technical great see nvidia certainly getting bring platform strength capability talked full stack market really help revolutionize okay arm four month since announced acquisition early feedback customer broader ecosystem remind u arm fit overall data center strategy sure sure arm also exciting certainly spending lot time right lot interest arm talent strategy ai company standpoint think made clear create premier computing company age ai combine lot nvidia ai leading computing platform arm vast ecosystem help really move forward together help position next wave computing age ai happening data center happening desktop course happening edge world iot help expand arm ip licensing portfolio nvidia technology meet large market including mobile pc also given background data center server help advance turbocharge arm cpu adoption ph pace data center course lot interest work amazon graviton course consumer side see apple m1 great time arm certainly seeing everywhere customer feedback overall positive deal would affect way customer getting access arm technology like fully committed arm existing licensing model preserve arm customer neutrality regard general nvidia open company work every major cpu provider x86 lot work ibm power course arm even acquisition announced like said ai company work every ai company job activate technology place help get help ride accelerate tide ai toshiya hari ian buck toshiya hariwe high confidence deal close long term treat arm like citizen acquisition certainly already released software stack arm excited see come market ian ca believe time let go wanted ask realize probably spend much time finance community maybe extent view sort finance world missing prospect data center world broadly missing underestimating story well first hard comprehend growth ai think none u unless around original pc revolution kind experienced something like mean model doubling every 2 three month mean nvidia general different market people figure first going really make wave impact enterprise problem customer hard also think hard put number put spec sheet say got great product lived since ai since oscar dusky ph first work montreal worked core overriding ph work soon torch 7 started turning gpus really hard complexity software stack intense value full stack innovation think really important see different thing happening industry understand software expect take market huge part hard quantify amount constant optimization work move ball forward software stack underlying hardware capability said full stack innovation sort business model engineering approach enabled u keep super fun moving quickly underestimate cost energy take bring get stuff done keep fun get learn every different use case ai would wish job ian great place end ian thank precious time thank insight also big thank investor joined u afternoon ian buck toshiya hari ian buck thank good luck meanwhile everyone thank bye