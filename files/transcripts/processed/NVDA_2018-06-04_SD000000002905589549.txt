get started first know name chris mcnally cover global automotive supplier london really behalf entire global auto team c.j semi team really evercore want say thank welcome think going special event quickly evolution last couple year sort small autonomous bus tour c.j silicon valley arndt helped organize bunch southern germany countless trip israel keep really brief amazing lineup next two day almost 20 company really leader autonomous ai soon shared mobility space say leader really soon leader broad spectrum new startup hope great conference kick c.j great thanks chris know c.j muse covering semiconductor space well semi equipment perspective private public company servicing primarily ai autonomous got nvidia intel xilinx public side handful emerging asic company think quite interesting ian buckto kick start nvidia honored ian buck vice president accelerated computing kick thing think present roughly 10 15 minute little fireside chat open q audience guess bring ian stage thank well thank giving opportunity talk name ian buck general manager vice president accelerated computing nvidia background actually engineer started nvidia 15 year hired start programming project called cuda built cuda engineering five year ago jensen invited actually run data center business life day job working hpc ai whether supercomputing lab like oak ridge national lab others course ai player google amazon facebooks alibabas et cetera done slide serve context nvidia maybe kick discussion q taking question usual safe harbor conversation inaudible right inaudible advance slide thing working bring back please f5 inaudible closed presentation middle desktop maybe semiconductor guy could invest logitech improve product would appreciate hate thing go next slide please nvidia ai computing company really acceleration accelerator mean companion cpu first market accelerated course known obviously computer game graphic started way founding mission company really first workload accelerated think computer graphic computer graphic video game typically every pixel screen video game batman might 1,000 10,000 even 100,000 line program determining color 1 pixel batman face taking consideration different light source room surface property skin environmental effect lighting effect lens effect graphic artist game developer basically writes write program c compile run gpu gpus turn around run program every pixel screen 1 million pixel 10,000 line program 60th second throw result away camera moved nature 2 decade point computer graphic basically evolution still graphic become massively parallel computing problem running long program massive set data designing incredible speed throughput simulating life majority vast majority processor dedicated specialized core call tensor core accelerating kind kind computation massively parallel problem got 1,000,000,000 pixel screen put lot lot core latest volta gpus 5,000 core different cpu cpu core tend optimized running single program really fast one thread execution run outlook web browser operating system gpu lab accelerated computing lab typically want run thousand ten thousand really hundred thousand thread running parallel throw many core problem first market computer graphic gaming evolved programmable stimulating light expanded actually accelerated accelerating simulation computing world fastest supercomputer u.s. world fastest supercomputer europe built world fastest supercomputer japan accelerated nvidia gpus kind simulation example would room want simulate air ﬂow room divide room tiny little group belt simulate group belt parallel use group belt time various kind equation simulate air ﬂow room identify vent quality thing air ﬂow air ring combustion engine similar math kind problem course today ai found actually find ai ai found u third slide talking next next slide please let go back please first market really discovered nvidia general purpose specialized computing graphic actually performance computing community people building supercomputer look plan 5 10 year first notice trend end moore law basically moore law transistor law giving transistor process technology improves transistor put toward product also turned marketing law transistor meant performance decade industry worked got transistor company like intel fantastic turning transistor faster technology adding thing like predictive execution effective execution branch predictor enormous cache keep memory closer processor result industry could rely getting 2x performance roughly two year course started tail around 2010 even transistor started running idea passed cpu today starting add core try deliver performance basically trying go parallel gpu end different started actually parallel started different kind use case never tried run outlook run outlook system solve problem massively parallel result architecture designed throughput necessarily latency result able keep continuing taking transistor available u directly applying core also tend holistic way optimize release instruction drive processor ca download ca write assembly unlike inaudible actually expose software interface call cuda everything built top optimized give u much wider palette innovate improve performance actually change instruction set every major architecture generation actually optimize compile whole system software programming language course go higher software like linear outlook mass library way ai framework like tensorflow pytorch others basically giving u 10x 10 year kind speedup often see talked next slide transitioned era ai really feel like many technology transition experienced last 30 year first course pc revolution advent wintel mobile revolution advent android platform cloud revolution like amazon container today ai yet another new kind computing technology going pervasive think important talk ai computing technology necessarily market see ai showing every one market touch cloud service like okay google seeing affecting inﬂuencing simulation community people using ai better weather simulation better processing data data set anywhere enormous amount data make prediction improve service process scientific discovery ai deployed capability really computing technology effectively replacing traditional software traditional software write describe perhaps stop sign look like describe stop sign look like see hexagon red got letter write code ai basically give lot data lot picture stop sign learn see recognize stop sign image basically write software story play every one industry long data drive next slide history well could go long time history ai explain think ai found gpus early advent cuda decided make available gpus data center one even gpus anyone go fry best buy gamer also download cuda tool kit writing program see could benefit computing back 2012 guy named alex krizhevsky graduate student canada working thing called neural network deep neural network still ai winter happened geforce gtx graphic card also gamer dorm room pc realized math convolutional neural network studying geoffrey hinton kind math talking hpc time imported ai code gpu called beginning alexnet alex krizhevsky named went submitted network computer vision contest called imagenet predominant competition computer vision researcher given million image predict inside image computer vision researcher competing getting 70 accurate alex came nobody computer vision industry went 83 stuck 72 73 within overnight became 1 researcher computer vision without ever studying participating computer vision contest catalyst moment geoff alex geoff henson work course google alex krizhevsky seeing facebook whole industry going basically ai got gpus alex trained could take training took literally entire semester train neural network brought month making terrible way get ph .. could train month today train alexnet matter think 15 minute something like accelerate whole industry become practical seeing ai hit every one nvidia market certainly anywhere computing ai used tool improve prediction improve speech speech recognition seeing speech synthesis one reason okay google alexa sound good using ai generate speech figure inﬂections right say certain tense word seeing ad recommender system given web page likely click link course diﬃcult advertising seeing video inﬂection space city typically run 40 hd stream single gpu running neural network every frame look suspicious behavior catalog vehicle lot content filtering detecting hate speech thing ai today sort creative super resolution magical enhanced button take fuzzy image make crisp neural network trained image detect incomplete data make high resolution high quality data truly amazing stuff next slide please fast forward 2012 today nvidia core technology company try make product technology available every channel today modern gpus volta gpu kind look like son daughter gaming card anymore going data center google amazon supercomputer around world basically build fastest largest possible thing smc allow prioritized module run fast thirst computing ai extreme put perspective typically need around 10 million image train neural network accurate prediction rate path modern neural network like gigaﬂop enormous amount computing necessary train along data make available gpus like volta oems also make bespoked system highlight ai system lead market enable oem partner build server technology well help make technology available every cloud ramp volta dgx amazon microsoft google alibaba innovating software side stop hardware work numerical library level programming level team working tensorflow team pytorch team caffe2 palo palo china framework help training software course important software well running neural network production even make available consumer level developer level next alex guy fastest possible pc gpu ai research develop next workﬂow make available next slide please let go sort market talk market later keep going want drag long next slide please couple fun one ohio state neural network health care health care think literally 1 trillion market everyone need health care using ai radiology huge amount time energy money wasted throwaway scan mri come clean mri may missed early detection cancer guy actually training neural network enormous amount medical imaging data available u world everything archived electronic medical record take data train neural network tell radiologist `` hi look potential spot like inaudible therapy replace doctor think one want rely entirely computer diagnosis aid doctor identifying spot really early transportation kansa city wo think kansa city bastion innovation ai actually deploying neural network detect pothole form take traﬃc light data weather data street data pump neural network predict within think getting 90 accurate pothole going form intersection actually send truck ahead time target crack road pothole form actually think eliminate pothole kansa city using ai wish san jose live last one preventative maintenance ge good work actually taking data getting gas turbine predicting ahead time machine going start fail preventative maintenance early rather later take potentially interrupt service cost hell lot roughly saving 50 million year per plant preventative maintenance driven ton story go spare detail see ai general purpose computing tool taking data making good prediction applying sort opportunity ai developed need data scientist researcher ingest data understand build service need lot compute think last slide oh know guy want talk car later thought frame little bit vehicle example vertical industry nvidia invest many vertical industry one investing actually building car platform believe bulk computing leverage cloud much eﬃcient way running ai hockey puck kitchen connect cloud ai get horsepower cloud keep hockey puck 20 device think hockey puck always connected cloud ca rely bring ai supercomputer car typically run around 12 different neural network car one actually drive around get car hand touching close wheel leave building come around san tomas merge onto 101 drive around fine basically take data center gpus highest end level 5 system actually 2 gpus redundancy 2 tegra socs running neural network parallel task prediction lane detection collision avoidance actually multiple camera looking driver looking driver distracted also different use case area incredibly complicated problem lot challenge getting level 5 car challenging lot simulation well taking gpus use data center graphic capability simulating thing might able drive 1 million mile road test drive real car billion mile simulation big part q christopher james muse ian buck q christopher james musedata center business actually trying show automotive company buying rack data center gpus server simulation experience teach ai simulation ever hit road think last slide want thank happy start conversation take question question answer got whole laundry list question think 20 minute time start high level dave patterson google talked renaissance computer architecture end gpu tpu positing hypothesis inﬂect ai built business almost 3 billion run rate view kind ai cycle yes certainly agree dave sense accelerating ai tool becoming new way write software new way computation obviously market affecting huge health care car economy kind architecture need order accelerate ai different traditionally cpu fact latest volta gpu redesigned architectural inaudible call tensor core designed specifically designed tensor operation basic building block framework like tensorflow called tensor pytorch challenging part happening ai diversification one neural network rule started convolutional neural network image processing rnns lstms gans tqms sort parsed lstms one neural network different structure sort mathematical operation need invented last two year mean people swarm field going explode track 200 different neural network performance tuning alone expanding think reason mentioned programming really important place platform people program develop neural network evolve tend usurp replace critically important ai field evolving cranking new architecture well almost annually fast industry moving people want inaudible innovate many different level go top bottom time forefront evolving quickly ian buck q christopher james muse ian bucki think one major area focus competitive positioning kind guess start cuda talk ﬂexibility programmability nature think give competitive advantage versus sort emerging asics evolving well cpu yes started cuda 2004 launched wanted give developer something program gpu around term used basically ph d. computer graphic order use gpu invented new programming model based c later fortran allow anyone c c++ background program gpu easily function around gpu called function instead running like would cpu say many time run parallel really simple anyone understood c c++ course python java fortran could understand programming gpu second thing made available everywhere every gpu shipped 2006 support cuda massively pervasive available parallel computing architecture processor available world get country engaging developer base allowing thing like alex krizhevsky guy invented alexnet keep u aloft find opportunity diﬃcult decision make time clearly paid u long term ai evolving develop program move framework forward ai framework also inferencing software production software take advantage technology paramount people want learn new programming language want use language already know innovate top world migrates 3 4 ai framework sure case went world would obviate need program cuda guess share view think ai framework evolve time shrink migrate handful think proliferate proliferate beginning think bunch ai framework large trying thing saw course company bought merged consolidation overlapped capability starting see little bit diversification framework starting happen colby may heard colby 1 framework use speech specializing speech processing speech everything health care one called candle specializing genomics understanding cancer whole purpose ai used cancer understanding agct correlate agct dna sequence doctor electronic medical record database specialized kind processing think need different kind framework generic tensorflow always tensorflow always pytorch 2 company keep thing aﬂoat seeing ai space workﬂows eventually software q christopher james muse ian buckitself think vast majority ai today probably done tensorflow pytorch legacy caffe starting see emergence rest ai software ecosystem developing new software productive platform access technology access gpus whether cloud desk data center fast develop innovate suitable format neural network always seem take six day train matter smart fast keep measuring gpus someone coming next neural network going get smarter bigger cloud computing seems know week thing must anyway iteration performance matter plus productivity matter program really matter going start seeing diversification framework compound see competitive landscape evolving within training look five year rising tide b think including fpga asic along gpus world yes think bifurcation happening training world inferencing world training building designing developing neural network inferencing production deployment ai training space want highest performing system resource available data scientist hire one today probably spending 0.5 million 1 million salary recruiting person job keep person productive neural network getting bigger scale getting bigger want highest performance stuff inferencing typically want start believe seeing ai introduced hyperscale business processing every data element come cloud want run ai inferred lot diﬃcult understand lot benchmarking going thing gpus offer fastest ai training scale node single chip also offer lowest latency highest throughput inferencing well infer 1.1 millisecond full model batch one also upwards 6,000 7,000 inference per second throughput rate large dash scenario training side becoming gang gpus together build super gpus seeing technology called nvswitch gang multiple 16 gpus together work one invested interconnects called nv link link gpus together switch called nvswitch gang together really operate one single tensorflow training operating upwards 15,000 image per second training group obviously target rest world competition going fall think guess always room specialization one area investing iot edge doorbell thermostat shoe lace whatever scenario kind believe either going rely cloud truly intelligent ai service specialize specific use case need mean build ai chip recognize word alexa take get cost whole hockey puck 20 worth r effort time specialization q christopher james muse ian buck q christopher james muse q unidentified participant ian buckreduce cost ai chip alexa ai chip next nothing especially going sell million million think area think people sort thing actually also particularly engineering hard technology help market way sooner get ai sooner get ai cloud training want succeed technology one called dla neural network need matrix multiplier hardware made available community go play ai make product know ca share much future technology road map guess one core focus company single architecture take silicon come new offering roughly every year point start maybe morphing piece silicon and/or perhaps custom specific workload customer mean think ai starting affect market already seeing shortened graphic people cool stuff rendering ray tracing actually actually fill hole array tracing engine using ai predict missing pixel color based trained image think continue build one gpu best computer graphic best simulation best ai many thing long term road map thing getting intertwined graphic becoming simulating light ai becoming general computing tool could used computer graphic rendering looking cool benefit take entire horsepower money generated market funnel entire investment back one architecture great thing course benefit leader industry help guide industry make transition happen faster keeping aligned obviously know build take next step question audience inaudible guy comment inaudible well data ﬂow interesting first getting ph d. first version parallel programming thinking data ﬂow architecture keep stuff check think one challenge data ﬂow programming model constrained let say pipeline pipeline pipeline restricts q unidentified participant ian buckprogram model fairly constrained always question ca fuse layer together well end problem think neural network getting bigger faster roughly think 100,000x five year term networking size go way translation model translation model understand entire english language used web entire mandarin used web try translate model massively huge trying express data ﬂow architecture actually really hard seen seen program model make pivot easy instead people want express computation level inaudible like architecture let memory system solve problem term providing large amount l2 l3 cache enough hpm memory worry today training neural network hpm got headroom overall going take best possible memory interconnect technology help u scale inaudible yes great question question people programming python right expressing neural network python letting framework job mean need compiler anymore actually exact opposite happening happens data scientist right computer scientist know cache would fail job like software nvidia understand neural network understand workﬂow understand designing neural network really bother performance stuff happening everyone designing neural network compiler inside framework basically express problem understand see layer see size see shape batching ruler batch form activation function hard part take compile neural network fit optimally machine actually blocking register blocking pivot calculation look like look like back vector versus simd kind transformation happening happening domain level like way huge software team basically work compiler take neural network described recompile turned output around optimally execute architecture neural network getting diverse need actually think compiler problem pattern matching one actually headache silicon also headache compiler engineer build something called tensorrt make tensorrt actually outlier inferencing recompile gpu corner turn reblock computation run eﬃciently keep memory also reduce precision instead expressing neural network ﬂoating point automatically compile ﬂoating point even measure operation operate 4x faster 4x smaller compiler guy thrilled thing play q christopher james muse ian buck q christopher james museare beginning input super give sort room play get thing called precision reduction often sit data scientist call data scientist try figure actually going work headache compiler getting harder hire unfortunately think run time ian thank much thank appreciate