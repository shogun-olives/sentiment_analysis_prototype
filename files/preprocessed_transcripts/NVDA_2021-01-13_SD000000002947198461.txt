good afternoon , everyone . thank , joining u annual technology internet conference . 'm toshiya hari . cover semiconductor semiconductor capital equipment space goldman sachs . 'm honored excited u today ian buck , general manager vice president accelerated computing nvidia . 40 minute . list question ian . webcast , please feel free type question . 'll try get toward latter part session . , ian , 'd like get started . first , thank much carving time busy schedule . 'm sure 're pulled sort direction . really appreciate . question answer technology conference . suspect investor audience know heard speak past . level set audience , hoping could talk little bit , responsibility nvidia -- although 'm pretty sure 's thing typical day . 'm curious spend time internal responsibility , customer-facing responsibility thing . yes . sure . thank . . 's bother . wonderful break thing get talk little bit thing done 're going . - toshiya hari - ian buckmy name ian buck . 'm general manager accelerated computing nvidia . 's long way saying 'm responsible gpus go data center . le graphic gaming forward compute ai . focus csp market . day filled talking like amazon , microsoft facebook apple baidu tencent alibaba name , hyperscalers , obviously , , nvidia , course , special relationship , given work . -- 'm also responsible work hpc , traditionally background . joined nvidia 2004 started cuda 2006 , came built engineering side , mostly focused computing , hpc use case , still today , huge part business . obviously , grew , encompasses hpc ai today . time spent hyperscalers larger supercomputing project . surprisingly , conversation tend similar sometimes ... got . 's great intro . thank , much . wanted kick post introduction , asking sort look back reï¬‚ect 2020 potentially look forward 2021 . 2020 clearly challenging year many u global economy . time , many secular trend technology space expected occur next 3 , 5 , 10 year seems accelerated pulled . sit , ian , key highlight business 2020 ? top priority team 2021 ? yes . go answer question , want remind audience investor team reminds . presentation , conversation may include forward- looking statement . investor advised read full report filed sec information related risk uncertainty facing business . way , get question . certainly , think anyone could imagine kind year . real test lot company market . covid come switch oï¬ƒce environment , meeting customer ' safe space , traveling everyone home maintaining social distancing , business , inability travel , event , conference going virtual well engaging customer data center . -- drive lot ai innovation , come experimentation development ai . , course , , one world 's largest ai computer upgrade continue invest . term achievement year , certainly , execution wise , think everyone nvidia proud 're able . took covid seriously early . went home back february . -- despite despite culture , 're still able execute . launched ampere generation gpus , a100 gtc conference spring , home run . work pulling together launch , finalizing product , taking market , getting hyperscalers oems activated product , happened covid . result , result -- performance great , 20x performance previous generation product , faster anyone expected . meantime , upgraded data center ampere . competed competition like mlperf virtually -- covid delivering leadership performance training inference . challenge ai slowing . research community n't slow either . continue deliver faster , better , smarter neural network . basically , neural network accelerating , doubling basically capability size term number parameter every 2 three month . date back resnet-50 , gpt-3 , 's like 30,000x increase computational complexity neural network . 've racing meet demand innovating whole stack , course , hardware , a100 helped lot year . big trend year finally saw inï¬‚ection inference side business . got ampere gpus , growth t4 cloud inference workload , add ï¬‚ops gpus available inference cpu available inference , 've actually tipped scale . compute gpu inference cpu , great . thing driving recommender system , people figuring apply ai ad placement , content prioritization , research . one nlp , natural language processing , speech workload , able transcription , virtual chat bot , kind workload , order magnitude complex main use case past , focused computer vision . way 'd like explain computer vision baseline capability sort think , see understand 're seeing silicon dog cat even bug basic computer vision understanding . - toshiya hari - ian buckthe recognize image , good bad . understanding language , 's whole another level intelligence . understand said rate speed say , meant come answer . human . 're nowhere near superhuman level nlp yet . 're trying get . 's one thing openai demonstrated gpt-3 turning around useful service business . company really well covid . mean hard time sure . story . data center upgrade , maintaining protocol , even robot , supervisor walking around observing people , making sure wiring done right . 're able pull . result , got -- market rewarded customer appreciated . certainly , time people care cloud , deliver next-generation platform . ian , maybe top priority coming year ? certainly , 're seeing growth continuing rollout ampere ampere product . 'll see , mean 'll definitely see . emphasis vertical workload , conversational ai , software early still beta . go widely , also recommender system . 're also seeing applying technology video collaboration platform . 's maxim product . obviously -- invented last year . 're going come market activate . conversational huge market . 're 500 million support call , 200 million meeting day . 's huge area ai content opportunity add value . recommender system . challenge recommenders 's -- 's common input-output . we're looking -- looking one picture telling 's . 's everything customer sale data web traï¬ƒc web content star like review . 's much richer opportunity . , people figure different way apply technology . see inference definitely growing conversational ai recommenders 2 big driver natural language processing general . new neural network going stop . people going continue build bigger , impressive , capable ai , 'll need infrastructure order deliver get done . 's lot - toshiya hari - ian buckgoing happen year , certainly , ai front , 's stuff 'm pretty excited . got . definitely want come back thing talked term inference performance improvement a100 . go , wanted ask software . analyst semiconductor background like , tend spend little bit much time hardware side maybe little software side . 's pretty clear based 've accomplished nvidia accomplished , software critical component support growth business . hoping could take u back working cuda , guess , early 2000s . drove company overall create today critical platform support business ? explain u cuda evolved past 14 15 year . contribute competitive moat guy data center accelerated computing ? early , certainly , roadshow . asked lot people industry cared computing compute focused . needed way -- people gpgpu graphic card using graphic apis . couple thing came clear . first , n't want learn new language . want easy access take programmer developer give way program system . 's cuda based c extended fortran language make really easy developer grok [ ph ] gpu , express kind parallelism without learn whole new language whole new platform . think largely achieved . 's -- teach developer cuda day . long understand concept thread , -- decent c fortran programming , get hpc space . model extended others . one -- quickly evolved building platform 's -- ca n't program gpu . people expect certain level library capability get work done . software today developed entirely . 's combination different library technology needed make median application work certainly compute space . work quickly grown , 's quickly grown building entire platform sdks library enable , starting basic math library , single processing , linear algebra operation sparse algebra , dnn library , video codecs , dali input output processing . 80 sdks track different industry give way program gpu , 's one step , library , capability already optimized gpus backward forward compatible . use today , go volta , 're 100 , ampere , get 10x , right , like without -- customer platform get enjoy . thing think -- platform grown substantially since first day program kernel , program one piece code gpu , providing different -- must hundred library . mentioned 80 sdks make successful . thing recognized , big secret success , fact 're full stack platform . n't try like standardize define next-generation isa . fact , n't even release isas gpus . decided tackle problem higher level . meet programmer 're programming 're expressing problem different way want consume . keep innovation space deep could innovate broader software stack underneath well hardware change hardware time . result , huge number software developer . think actually software developer hardware developer nvidia , building investing algorithm , library write code optimize gpus , meet developer , 're algorithmic work . meantime , also give u ï¬‚exibility completely redesign architecture . break isa compatibility day long . fact , order move needle forward learn engage customer . think 's big part success look whole stack . even people engage acquisition industry stay focused certain one know going add value optimize whole stack chip library compiler runtime vertical stack . critical decision early . n't worry isa compatibility , meet , provide whole innovation space . 's really get 10 20x kind performance see number we're - toshiya hari - ian buckinnovating way . programmer need u . developed volta kepler fermi . -- ride wave , 's platform enjoyable many people . got . thank . ian , wanted shift gear little bit talk growth driver business . sort touched earlier response . hyperscale , obviously , important market . 's sort business turbocharged growth overall data center business . spoke thing like conversational ai , recommender system important driver business year obviously going forward . based conversation 're amazon google world , thinking growth ? sort killer application hyperscale business ? yes , hyperscalers tend tip spear serve market term renting inference -- sorry , infrastructure , well meeting customer . often development team engineering team go invest build first adopter kind use case like saw ai beginning . result , 're obviously important customer . learn lot engaging . partner help take technology market , whether conversational ai , language processing next model recommender system . 're -- learn lot engagement . serve well . enjoy -- developer enjoy platform . time , turn around turn service provide core infrastructure rest market rent engage . take longer rest market catch google n't obviously n't brain trust google amazon alibaba , 's happening . fact , vertical industry , 're running 50-50 , half business hyperscale , representing 50 % data center revenue , vertical industry represent another 50 % . 're catching learning technique . part they're sdks , library , application framework . n't build scratch , industry , ai prowess , consume library service rather developing . time , think data center edge use case much larger hyperscale world industry consume footprint learn adopt - toshiya hari - ian buckthis technology . 're obviously seeing applied everywhere . end , choice want consume , whether 's cloud , managed data center push edge based problem use case . job basically activate 3 let customer figure choose amongst based use case . 're certainly seeing early adoption vertical space , certainly , manufacturing , transportation , health care , retail , financial service , certainly . early adopter company like bmw ge , walmart , american express , example , figuring apply technology . certainly get involved engage . one fun part nvidia 're company -- 're ai company work every ai company . able learn engage facebook time amex able bridge technology capability recommender system may used social medium site looking fraud credit card transaction . different use case , underlying system recommender system . 's trying understand litany unstructured data right choice anomaly might system . got . sort next question , ian , traction 're seeing enterprise side . mentioned , business 50-50 roughly today , health care , financial service , manufacturing . listed couple vertical 're seeing traction . could shed light 're thinking enterprise market , medium long term relative hyperscale ? 's probably hard put exact number , think relative growth profile enterprise vis-ã -vis hyperscale ? think adoption cycle enterprise relative adoption cycle [ ph ] . adoption technology , 's couple -- 's 2 camp . think we've always -- presence hpc side . course , oil gas industry need supercomputer seismic processing . connect market well continue . likewise , simulation space , imagine . think ai adoption enterprise still fairly early , early day . expect grow significantly . challenge consume adopt 's right product consume adopt making little bit easier , ca n't give tensorflow hope train model . - toshiya hariin end , 're focused vertical sdks solution stack . 's one focus around jarvis , conversational ai platform , providing complete end-to-end asr , nlu , tt pipeline , pretrained data ï¬‚eet dgx system . enterprise customer get something transcription box . may last-mile training , 's -- even provide framework . tune -- 're generically trained model , understand phone conversation augment domain-specific information . 'm ordering prescription , teach prescription name recognize . 're already teaching someone already well understood . even know speak english know conversation . ai , start beginning , 're truly starting brand-new baby . know nothing . 's huge engineering test bring speed . see model like bert . offer fine-tuning capability , train certain level intelligence fine-tune specialization . stack n't really exist starting exist . 's focus driver stack provide conversational ai . similarly , merlin recommender system maxine ucaas , kind conversation collaboration platform , providing -- 's needed enterprise adopt vertical base-focused sdks need bought sold like product managed maintained , little different go-to-market , little different engagement might see hyperscaler , obviously technology-focused developer developer , 've done pretty well , . full confidence know . certainly different market today . lot quadro rendering business done way . lot early ai adoption 've , seen great success triton inference software we've building . 'm excited see come fruition year moving . got . ian , wanted ask inference . couple year ago , one common reaction investor : , nvidia dominates training market , n't plain inference 's mostly cpu based forth . , obviously , 've ton success t4 a100 . guess recently , noted aggregate nvidia gpu compute capacity available inference cloud exceeded cpu . what's sort secret sauce , 's big driver term 've done well inference date ? - ian buck start model complexity . -- obviously , training order magnitude complex inference . train model , inference , back propagation lot competition obviously requires started . many early ai model computer vision space others , cpu infrastructure certainly suitable . execute forward pas ai reasonable amount latency also people , 's existing software . simply call user framework kick inference capable . 's changed model complexity . model complexity , model , traditional use case new use case . cv , computer vision went nascar cnm [ ph ] , got harder , put bounding box around people thing object actually identify every pixel . , attempting real time high throughput became prohibitively expensive . nlp driver . bert model example . also dlrm , dlrm deep learning recommender model , -- basically , 's reference recommended model facebook , submitted mlperf . 's much harder execute real-time latency requirement might recommender system language system . 're conversation , ca n't take second inference . respond 100 millisecond . take network traï¬ƒc load , time slot actually inference quite small real-time interaction use case . recommender system even worse actually run recommender thousand product get click answer immediately . driving growth see t4 . record revenue t4 shipment q3 . -- get t4 , inference-focused gpu . 's priced differently . 's different product 's focused inference hyperscalers . see 's driving lot strength . part software . n't -- software problem n't gone away . delivering best performance problem n't chip lot ï¬‚ops algorithm optimization software stack execute right precision maintain accuracy continue provide high throughput . 've investing software called tensorrt , sort deep learning inference compiler . take model trained tensorflow pytorch whatever compiles reduce precision , fp16 date , run real-time . - toshiya hari - ian buckon top , found challenge deploying inference . 've made also easier kubernetes environment triton software , like turnkey inference engine . give -- throw -- fire triton across kubernetes home chart , need send data give inference back . lot customer trying optimize inference infrastructure triton . 's super helpful help people deploy . run cpu , run gpus , support different -- major ai framework even includes . 's huge uplift help business make easier people deploy inference . instead trying shoehorn existing application , call micro-service . , software huge part . training one job . inference entirely different latency , throughput , accuracy , quantization , graph compiler fusion matter lot , diversity . got work kubernetes infrastructure , prometheus monitoring system , stuff work order get stuff production . 's lot software . 've investing couple year thrilled see finally take . great use case . amex fraud detection one . walmart using inventory management , even microsoft oï¬ƒce . grammar correction right done cloud -- cloud azure , checking grammar gpu . yes . follow-up , ian , term think growth model complexity . feel like customer manage perfect thing like conversational ai recommender system , 's pretty darn complex . fair sort extrapolate current slope term rate model becoming complex future ? could even acceleration ? think ? male [ ph ] recommender system still open n't tapped curve slowing . gpt-3 openai approved . continue go right . 've seen chart model complexity . one shown end language . , neural network close human level neuron , naive parameter neuron basis . 's still clearly -- least one existence proof 've got another one 2 order magnitude go . - toshiya hariand way , training scale get really complicated get net -- whole thing learn converge . expect continue , application nlu different use case , specialization network . 's simple people want extract language varies compared like image , 's image recognition , box -- bounding box . much complicated . language , sentiment . search , want find data information structured data -- imagine take new york time , read new york time come fully structured table information could used search . cybersecurity , another example , like every network log able build extract structured data look intrusion detection . application space go get really broad nlu . exact story play recommender system . 's even complicated data data tends unstructured well . application use case widely different . 's make ai super exciting application space keep becoming broader , diverging , . result , variety different neural network platform need run get complicated . think 's one reason invest much different vertical use case get experience bring back core platform figure optimize . n't think -- network complexity going slow . people continue get human level language understanding intelligence . interestingly , think application use case applied use case continue expand . diversity model , cambrian explosion , big bang ai going get exciting people apply variety different use case . speech , , way , creating human -- reliable human speech . 've applied ai problem , done . many use case still -- turning good ai speech use case still developed . 's fascinating stuff . shifting gear little bit . wanted ask road map . mentioned earlier , rate innovation gpu accelerated computing staggering . think spoke 20x improvement a100 . based working today visibility internally road map , would characterize sustainability technology cadence ? outside 10 going 7-nanometer 7 going 5 , lever - ian buckhave pull , hardware side software side maintain cadence ? yes . huge part full stack optimization . going new node technology change parameter , 's obviously good baseline . go different new technology , eï¬ƒciency performance particular power level increase . also , run processor different power level change shift time . 's great . give new option transistor performance . huge product performance come though software algorithm . improved volta 's performance . day launched gtc , day launched a100 three year later different gtc 4x , came innovation algorithm , compiler , working community improve overall holistic platform , running v100 gpu server . 's -- -- result , try crank software optimization fast . publish new framework container every month , whether tensorflow pytorch , help improve accelerate training . look bottleneck training pipeline see make faster . make core ï¬‚ops faster matrix multiple layer , lot i/o pipeline start show . amdahl 's law ( expletive ) show lot place . front-end back-end burn . 've actually work optimize use case . invented library called dali , preprocessing image processing cropping angling preparing data trained gpu cpu could n't keep . applies audio data processing . nvtabular , library processing structuring lot data , used done cpu . gpu , put right next framework , data optimized move quickly . 's huge part make platform successful -- generation generation . n't wait new hardware release . 're constantly pumping technology . come together holistically look top bottom . , software , algorithm , domain-specific solution make thing lot faster . , course , cuda compiler run time , course , work operating system optimize low level optimization . - toshiya hari - ian buckthat , course , go gpu , improved redesigned throughout old isa , bring new one . designed core sm architecture see trend shift hpc ai . scale , 's -- look data center . n't constrain one gpu pcie card . broke mold turned gpu side , turned mezzanine product built hgx baseboard , go dgx platform , go -- hgx go hyperscalers oems . take step look interconnect . acquisition mellanox , look building data center scale , supercomputer , work one throughout -- solve ai challenge -- help define future ai . software stack data center scale optimization 's done generation generation . kind need think way . ai getting big one gpu one processor . 's -- run layer fast ? 's apply technology , develop next-generation ai workload science data science feeling constrained . want push limit . provide way training scale , like 've demonstrated , take advantage develop next- generation ai . got . mean , touched mellanox little bit . speak dpu opportunity see next couple year ? yes . think 's super exciting . acquisition mellanox , look computing network data center scale networking space . nvidia bluefield , example , taking networking building dpu programmable data center chip open another $ 10 billion tam nvidia . dpus doca , counterpart cuda platform , help re- architect modern data center -- optimize data center scale networking . area security network compute able make data center malleable , turn supercomputer cloud resource , capable insert programmable networking platform ensure security isolation right level oï¬ „ oad impact performance . - toshiya hari - ian buckso 's problem 's trying solve , 're early journey . certainly , worked -- worked mellanox little decade hpc space . culture compatible . engineering driven , technical . 's great see nvidia . certainly getting -- bring platform strength capability 've talked full stack market really help revolutionize . okay . arm , 's four month since announced acquisition . 's early feedback customer broader ecosystem ? remind u arm fit overall data center strategy . sure , sure . arm also exciting certainly 'm spending lot time right . lot interest arm , talent . strategy ai -- company standpoint , think 've made clear , create premier computing company age ai . combine lot nvidia 's ai leading computing platform arm 's vast ecosystem help really move forward together help position next wave computing age ai . 's happening data center , 's happening desktop , course , 's happening edge world iot . help expand arm 's ip licensing portfolio nvidia 's technology meet large market , including mobile pc . also -- given background data center server , help advance -- turbocharge arm 's cpu adoption [ ph ] pace data center . course , 's lot interest work amazon graviton . course , consumer side , see apple 's m1 , 's great time arm . we're certainly seeing everywhere . customer 's feedback , overall positive . deal would affect way customer getting access arm 's technology , like . 're fully committed arm 's existing licensing model , preserve arm 's customer neutrality regard . general , nvidia open company . work every major cpu provider , x86 , lot work ibm power , course , arm even acquisition announced . like said , 're ai company work every ai company . job activate technology place help get help ride accelerate tide ai . - toshiya hari - ian buck - toshiya hariwe high confidence deal close . long term , -- treat arm like first-class citizen acquisition , certainly already released software stack arm , 're excited see come market . ian , ca n't believe 're time . let go , wanted ask , realize probably n't spend much time finance community . maybe , . extent view , sort finance world missing prospect data center world broadly ? missing underestimating story ? well , first , 's hard comprehend growth ai . n't think none u , unless around original pc revolution , kind experienced something like mean model doubling every 2 three month mean , nvidia , general , different market . people figure first going really make wave impact enterprise , problem , customer . hard . also -- think 's hard put number put spec sheet say 've got great product . 've lived -- 've since ai -- since oscar dusky [ ph ] first work montreal , worked core overriding [ ph ] work . soon torch 7 , started turning gpus , 's really hard . complexity software stack intense value full stack innovation , think 's really important see different thing happening industry , understand software expect take market -- 're . 's -- huge part , 's hard quantify amount constant optimization work move ball forward software stack underlying hardware capability . said , 's full stack innovation sort business model , engineering approach enabled u , keep super fun that's moving quickly . n't underestimate cost energy take bring -- get stuff done . -- keep -- 's fun , get learn every different use case ai . would n't wish job . ian , 's great place end . ian , thank precious time . thank insight . also big thank investor joined u afternoon . - ian buck - toshiya hari - ian buck thank . good luck . meanwhile everyone , thank . bye .