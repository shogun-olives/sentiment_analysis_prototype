( technical diﬃculty ) also simona jankowski . 'm going pas simona read forward-looking statement . simona , . thanks , brett . reminder , presentation contains forward-looking statement , investor advised read report filed sec information related risk uncertainty facing business . back , brett . question answer thanks , simona . ian , maybe wanted set , maybe set scene market . guess 2020 breakout year strategically commercially nvidia , division specifically . mean launched a100 . finalize mellanox transaction launched dpu . 's obviously proposed acquisition arm . 's chinese entity list restriction deal , mean , surging sale . obviously crazy year . 's clear -- least 's clear investor -- 're giant kind innovation phase compute right . maybe break see front running division ? see course 2021 , 2022 ? think recognize 's still really early adoption curve accelerated compute . 's going define year crazy 2020 ? crazy 2020 certainly 'm sitting . nvidia launched whole new architecture , ampere gpu a100 . launch home . fact , jensen kitchen . -- think company slowed struggle execute , think thrive environment . 're already virtual global company , knew , 've launched kitchen virtually . a100 great success u . continues . fact , market today really give enjoy benefit ampere business . 's 20x improvement previous architecture . kind innovation -- kind improvement make generation generation . -- able achieve look whole stack perspective . 's chip performance chip . obviously , chip critically important , ampere added new technology like tensor float 32 whole new tensor core architecture . -- gaming visualization side , also added ray tracing -- new ray tracing capability , amazing . optimize software stack well . 're seeing right , course , adoption a100 . 's targeted , first foremost , course , ai cloud market broader data center . ability train world 's largest model done ampere a100 . also , course , seeing success hpc scientific computing . strategy build 1 gpu , 1 platform 's highly leveraged , point , different vertical capability market library sdks take advantage 1 gpu architecture underneath . see moving forward , first , ai continues obviously grow . 's software , writing software defining next-generation application going interact cloud use business insight thing . 's totally new technology . 's something world still learning use even first principal standpoint . see business . grew lot originally hyperscalers , google facebooks amazon alibabas world , people technology knowledge go invent build scratch . 're starting see broadening . cloud starting consume gpus rest world learning use technology , either nvidia 's direct software software partner ai stack 're working . finally , 're -- training side sure also increasingly enterprise . - brett simpson - ian buck - brett simpsonthe bigger company maybe need -- understand apply business , decision-making use ai technology thing like understanding data 're ingesting , understanding product adoption , understanding -- recommend give customer also changing interact customer , particularly covid , 're kind -- 's whole new world video chat . good . mean guess , since -- largely nontechnical audience . wanted spend bit time market strategic opportunity see next couple year . maybe , first , 've seen lot research breakthrough ai last 12 month . mean bert large , gpt-3 . model size going crazy algorithm , . mean , 're still -- still look like 're applied research domain lot breakthrough . think one colleague , bryan catanzaro , saying maybe 5-year view , 's possible company could spending $ 1 billion compute time train single language model . guess 's practical application 're going see breakthrough 're seeing model size ? yes . -- people still figuring limit ai , sure . think one area started , computer vision . idea picture basic question . think 're largely mature . well -- starting point ai 6 , seven year ago asked -- asking computer question . think 're pretty good . 're getting pretty good also identifying different part picture , putting box around , even identifying individual pixel 's consisted face . 's background , 's ai green screening . 're starting see consumerization technology . bryan talk -- huge model , 1 billion parameter hear , 's new area particularly natural language processing . 's area 're going beyond understanding computer vision , , think , bug cat dog every intelligent life force , intelligence , level computer vision . brain pretty small . language language understanding , however , much broader , bigger -- challenge , right ? need understand saying right , also mean , intent understand take action respond communicate back way 'm communicating . - ian buckyes . 's -- much , much intelligent problem . opportunity large , right ? interact human 're going interact computer . data interact business , actually , language understanding document . thing like chat bot recommender system sentiment analysis understanding dialogue making decision call doctor 's oﬃce help request financial adviser . 're understanding meaning intent . technology like virtual assistant chat bot want kind understanding improve user experience , end , make better customer . 's conversational ai big thrust right . call general conversational ai . 's -- market huge . 's 500 million support call year . 's 200 million meeting going . 's 200 million smart speaker world . -- obviously , new world covid , everything digital . 's going digital medium , 's area could ai agent call help transcribe , understand , summarize , capture action . see people talking thing . big model . area recommenders . think recommenders -- think , interact internet . search , really recommendation . go amazon 're browsing website buy something , they're recommending thing . visit news feed , 're deciding see n't see , obviously , implication . model present something 's accurate , something 're likely buy also moderate content time . , huge data problem amount data across -- think every user social medium , every news post every product . 's massive matrix . model tend large . certainly , data 're trying capture large getting even bigger . , 're seeing significant growth challenge ai also people buying infrastructure . go right -- obviously , 're highly motivated often go right bottom line economics . - brett simpson - ian buckone example , guess , conversational ai microsoft oﬃce . know audience know , turn grammar checking , microsoft actually using ai model based bert , famous ai model language understanding . 's finding grammatical error , highlighting blue . model got complicated 's trying understand language move gpu . today , run nvidia gpu . 're live oﬃce 365 , beta actually highly accurate grammar correction running sentence gpu running ai real-time inference . yes . yes . interesting . maybe switching gear little bit , ian . term adoption curve , technology . mean mentioned computer vision . 6- , 7-year ago thing , 've kind solved . 're moving next thing . guess go survey , talking cio , ai coming spending budget big item big item today . guess , technology still feel quite nascent outside maybe top 50 hyperscalers developing next-gen model recommenders laid . many organization think actually using accelerated compute today real scale ? yes . think adoption curve followed , like mentioned , people capability use . think adoption curve 's getting consumed , 's 2 part . 's training part , developing ai service model use case . 's deployment part , inference deploying ai live service infrastructure . adoption curve follow people . first , needed people understood data science , understood like machine learning ops ﬂow capability understand published ai community apply particular business . pretty small . fact , started hyperscaler . think fortune 500 , 5000 others , 's still relatively small . see traction actually going isv partner , start-up . start-up community actually quite rich area . find right partner understands particular technology working apply particular business use case . see huge majority use case outside big hyperscalers starting way . - brett simpson - ian buckand think community probably see start-up activity ai right , make lot sense . lot smart people great idea could applied many different possible business use case . point , develop service partner , probably data scientist company . need turn deploy . growth come -- 's different growth vector . one training developing model , , course , scale number people , number problem model set size . kind multiply 3 together kind get size training opportunity . side , inference deployment . data . service running , amount data coming opportunity ai optimize . scale amount data size business . opportunity -- want gpu front every one connection run operate execute ai latency required service , whether interactively news feed . click , got hundred thousand inference millisecond voice conversation maintain 20-millisecond inference latency keep number utterance , least speed talk . mean guess obviously going take time , 's lack data scientist really understand well . see lot guy prototyping today kicking tire cloud , trying figure they're going technology . see path sort path see corporates building industrial scale ai ? going sort cloud hyperscale play providing service library supporting view ? think lot start cloud . obviously , 's easy take first step cloud 're -- budgetary standpoint , 're paying hour . certainly , -- nvidia 's standpoint , make assure architecture available platform real everywhere . work major cloud provider activate make sure latest a100 gpus cloud , customer use they're inferencing t4 gpus . time , make sure major oems access technology . offer base gpus time , market consume , however want -- choose . remain open way . - brett simpson - ian buckthe adoption tends start usually data . data resides cloud , tends start cloud . need on-prem data center privacy security reason , people start , . usually kicking point thing get started . experiment cloud , get real stake , start data . scale , certainly , people look cloud bill , decide whether want -- on-prem cloud . many case , see also stratification . people n't want manage risk . want make sure work multiple different cloud provider on-prem use case , on-prem capability well manage risk want run different service . 's necessarily locked one particular cloud sort one particular on-prem hybrid . think people going necessarily naturally want , vary industry industry , sure . talking cloud , role think really play ? silicon perspective , one hand , 're buying gpus , guy like google aws . , developing chip software . see sort internal chip effort developing ? obviously resource nvidia reach . love get thought term internal silicon effort . well , sure . think -- first , 's great everyone 's coming conclusion need accelerated computing . mean ai use case great one compute turn software , turn business opportunity . work . one thing unique nvidia forefront lot technology full stack company -- remember , i'm releasing gpus everyone get access start using , 'm also releasing software stack top well . work tightly friend google tensorflow facebook pytorch many stack actually , ml ops stack well . also released , container , optimized version make freely available ngc container registry download , get latest certified , tested , validated ai software work , whether cloud on-prem . 're ai company 's working ai company , including hyperscalers take learning knowledge , engagement , whether recommender system , conversational one , we're - brett simpson - ian buckdoing stuff ai video chat like conversation well . informs u . help customer . make product better , library sdks better make better , incorporate back platform . corporation improving making framework better optimized vertical stack optimize . feedback get right back hardware team architecture , benchmark tune test . team also see improve architecture make new investment architecture , whether compute caching memory define next generation . someone stay middle , see quickly happens nvidia . result , 're releasing new container every month different workﬂows different framework well new architecture every year continuously innovate 're super done . area rapid innovation , great company . get train bandwagon , ride wave 're programming interface high enough level . nvidia come along next gpu next version software , see 20x saw ampere . story repeat . everyone investing . think make total sense . ai platform compute could write software . think stand , know , 're making platform available everywhere customer , benefit benefit . think mostly advance adoption ai inside broader enterprise , pretty exciting . yes . yes . , guess , cloud specifically , 've seen cloud compute , big concentration amongst big player . listen aws , talk -- 've got 10,000 customer machine learning today . become contemplated service market , 's dominated public cloud player ? , see large opportunity sell pod system corporates build enterprise channel ? yes . think couple thing . one 's -- 's -- definitely , see -- 's one way consume ai , sure . service going stand different . ai capability . different service stand serve capability , fine tune . one software program run . model widely different . use case different . 's -- off-line , streaming , ensemble-based . -- latency requirement wildly different . think 'll see wide variety different service capability , everyone compete naturally vertical capability market . term hybrid on-prem , , course , decision people want make term -- much want consume utilization , first foremost , data . superpod standpoint pod audience , ability actually put together multiple gpus system create ai infrastructure broad data science team . think ai gain adoption , people going want infrastructure internally . first , allows optimize infrastructure workload model size . model train thousand gpus . optimized running embedded use case maybe different size different scaling . scaling parameter something need -- get today on-prem 're starting see cloud , also offer lot diversity different architecture cloud . hyperscalers make decision make investment , obviously , 're hyperscalers . decided scale want deploy something . seeing option cloud , also exciting offer different place point customer choose . end , boil rent versus buy decision -- . come economics , different -- conversation , think , 've way cloud versus on-prem . ai different , except difference want necessarily configure machine , certainly training . term know want put together going way infiniband stack , going -- providing high-speed storage solution 's tightly coupled compute , usually important training scale . one reason built superpod , selene , made available customer capability obviously -- 're basically supercomputer , offer community . also supercomputer , , offer community get head start . cloud starting figure participate well . seeing infiniband happen csps cloud provider , exciting , different storage option . obviously , 's different - brett simpson - ian buckchallenge deploy stuff scale across multiple region making available rent , making economics work well . think 're going see lot diversification kind instance type capability different cloud people get access different way technology connected together . yes , yes . yes . interesting . maybe mentioned selene , ian . wanted touch little bit infrastructure investment nvidia making . look capex budget nvidia , 's going annualizing $ 1 billion today . know 're investing new campus , et cetera . nvidia see opportunity offer ai service enterprise ? -- mean see geforce business model , early stage . opportunity , wider strategy service business ? reason see u building selene building infrastructure , first , successful ai , practitioner . 's like -- understand technology intimately understand advance . like said , 's one chip one core . problem people want today , capability super exciting . need think like data center whole . ca n't think programming one chip . model big fit single gpu 're going -- case , single server . think , spread across entire rack row data center . certainly , train time 's reasonable , 2 week , n't really want go , keep data science team , also expensive , busy . need multi-node training scale , batch-based training . 'm thinking entire data center . ca n't paper . order successful ai , thinking problem scale . engineering organization , build , . make product better sure . also create product vertical market , 've chosen . self-driving car one . huge portion infrastructure 're seeing today used self- driving car initiative nvidia drive work 're self- driving car customer give turnkey solution partner nvidia deliver self-driving car capability . - brett simpsonand -- build whole pipeline data ingestion labeling training simulated environment run car simulation crash 100 time without ever hurting anyone seeing work n't work ever put car actually test real time . build infrastructure . result , also learned product make better . certainly also research team , specializing different capability learning -- advancing field forward . also teach u lot product . term service , work -- one market . one use case , right ? strategy make available ai platform every different start-up hyperscaler , oem enterprise , consume develop capability . remember , 're phase new form computing , people figuring deploy , use different use case . market , choose go vertical advance forward . 've done self-driving car . 've also done conversational ai , like mentioned . software stack called jarvis , come pretrained model help speech recognition language understanding , also text-to-speech capability . 've done recommender system . 've published software stack , baseline capability large recommender system scale . informed engagement hyperscalers , call stack merlin . also video collaboration stack , ucaas stack called maxine , used improving experience 're right zoom helping apply ai technology thing like noise cancellation , green screening , super resolution , et cetera . 'll choose , 're really help advance ai field forward . 's different -- usually n't go way turnkey solution . usually go active enablement , rest market take deploy technology see benefit . maybe ask , ian , -- guess look back v100 cycle data center division , bit lumpy . good time slower time . guess take time customer digest 're buying need next amount compute . think 's going -- - ian buck - brett simpson - ian buckthe behavior 're going see a100 ? think different type market time around ? 's getting faster every time , think 's market 's maturing . saw v100 -- remember , three year ago . wave ai , requires time people absorb understand technology see next ramp . think coming -- software matured , way go -- market technology , software matured 's going -- 's much faster u . certainly see digestion sense product transition . obviously , people want refresh large ﬂeet like hyperscaler . happen . 's experienced v100 a100 much -- much -- happening much faster . fact , grew data center business many company , think , struggled saw downturn . think 's rapid adoption ai observation 20x need go next platform , really pulling product forward making sure get market quickly possible , making available . think transition happening faster . 's always going transition . manage , certainly spent lot time focusing . prime pump . make sure everyone get platform ready , make technology ready early , people understand . hit market , everyone ready absorb . backwards compatibility big part , making sure framework ai software stack already ready go day 1. n't wait people test hardware try , reporting ahead simulation early version hardware get ready launch , stack ready go . think 've improved significantly since v100 a100 . yes . excellent . maybe competitive dynamic see ahead . mean 've -- dominant franchise particularly training , also , 's getting -- accelerated compute come inference , 're great . look 2 three year , sustainable think position , market share position accelerated compute look like ? lot start-ups . 've taken lot longer get market . look 2 three year , 's perspective market share ? lot change 2 , three year . mean think ai 2 , three year ago today , continues evolve grow . model thing 're talking widely different . used talk imagenet . used talk resnet . 's kind like table stake . ca n't conversational ai natural language processing , 's lot opportunity growth coming . -- 're well-established already place . -- think -- 's one part . think technology ai evolving really rapidly . 's 's important practitioner ai order keep trend understand model actually , 's art craft , learn lot system engineering , computer architecture , interconnect , storage system , whole data center . think look 2- 3-year time frame , 's -- really , 's happening , 're thinking data center computer 's really new data center designed . 're designed train network scale give data science team throughput keep tool develop natural language conversational agent going right use case . problem size 're trying solve huge . 's every product , every user every data point , every news feed . -- 're optimizing , nvidia shifted company that's thinking data center unit compute . includes gpus , system , networking , increasing cpu fit together broader software stack kubernetes workﬂow manage enclave data scientist different service developing thing turning around ﬂipping infrastructure applying inference . mentioned inference -- , 3 , four year ago , vast majority inference done cpu . today , compute gpu -- compute inference compute cpu hyperscalers , add ﬂops capability . came a100 . designed a100 , started seeing trend model getting bigger capability want get smarter . cpu could keep term executing model latency necessary nlp model conversational agent talked , particularly text-to-speech , recommenders newer model . - brett simpson - ian buckresult , workﬂow -- people started deploying gpus . saw t4 gpu , 're used hyperscalers today inference . a100 , made architecture excellent . 's great training gpu , also tensor core run operation necessary inference . reduced precision stuff either ( inaudible ) fp16 . also capability called mig multi-instance gpu . gpu actually , inside , split 7 separate gpus presented independently system people take gpu bought training turnaround serve inference use case . 's 2 3 faster previous gpus , one single slice . 're seeing adoption -- need good training inference . certainly workﬂow allows seamlessly go training inference really important . able obviously run new model area conversation recommender , 's super key . maybe switching gear little bit , ian . maybe get update arm situation ? mean 's update arm acquisition , would great . 'm also interested asset data center perspective ? mean see role -- nvidia see general purpose cpu arsenal long time ? develop server architecture based arm general purpose server architecture ? see arm opportunity data center ? well , certainly , data center new unit computing . look -- advance nvidia advance data center . certainly , 's focus , talk . think arm standpoint , creates premier computing company age ai . combine latest nvidia 's leading ai computing platform arm's cpu expertise help position arm nvidia arm 's customer entire ecosystem customer next wave computing , age ai . -- course , ai also powering internet thing , thousand item , bigger internet people point . make exciting . certainly expand arm 's ip licensing opportunity allows u offer nvidia's technology large end market , including mobile pc turbocharger arm server cpu road map help investing road map advancing arm - brett simpson - ian buck - brett simpson - ian buck - brett simpsonmove faster accelerate adoption data center , edge ai course iot . certainly expands nvidia 's computing platform reach -- today , 2 million 15 million developer . 's exciting . customer excited . think partner excited . opportunity great . ca n't succeed unless arm 's customer succeed . guess , see important step cpu capability data center in- house . think , particularly business scaling much , cpu becomes fundamental solution going forward ? think -- always needed fast cpu . fact , amdahl 's law still much law unlike law . -- make infinitely fast gpu . n't accelerate entire workﬂow , entire problem , may -- accelerate 80 % solution infinitely fast , 'm still 5x faster 're stuck 5x . 's think ai accelerated computing general data center scale . investing data center data center scale , cpu , dpu gpu , component parallel serial i/o networking , really get -- achieve 20x speed ups talked . think entire canvas , 's innovation canvas we're talking order achieve next-generation performance see ai continue advance continue allow breakthrough happen turn business opportunity world 's enterprise . excellent . interesting . well , think 're time , ian . say , really appreciate time . great , great discussion . could go lot longer many question . really appreciate coming event today chatting u . problem . time . thank . next speaker starting minute . samsung 's network evp , woojune kim . please , click zoom session . thanks much . , ian , thanks time . bye . thank . thanks , simona .