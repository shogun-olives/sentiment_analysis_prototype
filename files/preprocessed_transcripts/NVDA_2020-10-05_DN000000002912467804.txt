jensen huangthank . hi , everyone , thank joining u gtc financial analyst event . hope 're able view jensen 's gtc keynote address morning . 're excited opportunity spend time investment community unpacking announcement . go introduction today 's agenda , let remind presentation may make forward-looking statement based current expectation . subject number significant risk uncertainty actual result may differ materially . discussion factor could affect future financial result business , please refer recent form , 10-k 10-q , report may file form 8-k security exchange commission . statement made today , october 5 , 2020 , based information currently available u . except required law , assume obligation update statement . , let 's -- ready get started . six speaker today , cover highlight morning 's announcement mean business : nvidia founder ceo , jensen huang , kick u overview nvidia computing platform strategy . next 'll four speaker , cover important aspect data center market platform , 'll wrap cfo , colette kress , opening q & . expect entire program wrap two hour . , , let turn jensen . hi , everyone . special gtc , many new platform product 're working came together . strategic theme nvidia driving reverberate throughout gtc . ai powerful technology force time , software writing software , age ai , automation automation , age ai often open large untapped market . accelerated computing full stack challenge . start great chip , stack lot complicated . accelerated computing platform take chip cloud computing platform take server . new unit computing data center , whether cloud native application run across entire data center edge computing whole data center chip someday . iphone moment industrial company . ai service spend cloud edge . nvidia ai probably somewhere , say , actually 6 today . also want bring nvidia ai accelerated computing arm , world 's popular cpu , offer architecture arm 's vast ecosystem . simply , building computing company age ai . 're focused five major domain . application domain share similarity within use case , system platform , ecosystem end market . despite domain , nvidia rtx , nvidia hpc nvidia ai nvidia enterprise ai nvidia edge ai . let say word one . nvidia rtx inventing future graphic digital world . rtx massive endeavor , reinventing real-time graphic , requiring u fundamentally change every layer stack top bottom . rtx high risk , clearly home run . ampere second-generation rtx expected prepared great demand 30 series ramp fastest ever . still , demand exceeding expectation . also announced ( technical diï¬ƒculty ) , physically based simulation collaboration platform , platform creating digital world open beta . nvidia ai full throttle . ampere 's latest mlperf 20 benchmark , demonstrating growing lean . ampere fastest ever data center ramp . first generation required explaining whatsoever customer , oems cloud data center need nvidia cpu 's data center . ask take ampere market . today , announced new nvidia rtx a6000 nvidia a40 enterprise data center ampere-based gpus . pci express base complement already full production nvidia a100 . also announced nvidia jarvis , conversational ai , sdks open data . nvidia merlin recommender sdk open beta . two important ai model world today . also announced nvidia maxine sdk cloud ai video process . maxine help video conference service take advantage nvidia 's gpus nvidia ai cloud . live video one active , busy traï¬ƒc internet today . finally , announced stack popular 're working bring inclusively ngc , cloud registry , cloud marketplace , essentially like store within store . next wave ai enterprise . enterprise use ai automate company use ai bring automation product service company build . latter also called industrial iot edge ai , come several name . imagine john deere autonomous tractor connected john deere cloud service autonomous mercedes-benz connected cloud service , connected air conditioner , street sweeper , entire building connected ai service . iphone moment world 's industry . ai automate world 's largest industry . breakthrough ai made automation software possible . nvidia enterprise ai helping company build modern , secure nvidia accelerated data center offering software platform help major industry apply ai . manuvir talk nvidia egx enterprise , new nvidia bluefield data center infrastructure chip platform vision enterprise ai . nvidia edge ai helping company build modern , secure nvidia accelerated edge data center box software stack let customer operate network like ï¬‚eet software platform help major industry create operate ai service . today , announced fleet command , software-as-a-service offering help operate suite . another recent example , ai powered connected product service mercedes-benz partnership . development mercedes-benz full throttle . mercedes using entire stack infrastructure , av computer car driving application . justin talk nvidia egx edge wave partner joining u . nvidia hpc consist supercomputing center industrial hpc . industrial hpc demand accelerating large number domain-specific application . example , healthcare domain representing decade work created state- of-the-art suite accelerating tool help medical researcher discover lifesaving drug . announced nvidia clara discovery , kimberly talk great work 're discovery partnership . biggest gtc ever , 1,000 session , record number sponsor , record number startup participate . announced avsdk . sdks critical difference gpu chip accel -- nvidia accelerated computing platform gpu . sdks run nvidia 's 1 billion cuda gpus , one architecture , gigantic installed base developer . sdks covered range nvidia 's full stack computing platform , chip architecture like cuda gpu doca dpu , system system component rtx , dgx , hdx hyperscalers , egx enterprise edge , agx autonomous machine , system software apis window , android , qnx , linux , kubernetes , vmware pc cloud , enterprise ( technical diï¬ƒculty ) . acceleration library engine like cuda-x library , magnum io , cudnn , tensorrt , triton inference server , rtx stack , physic engine , course application application framework , omniverse , nvidia drive , jarvis , merlin , isaac , robotic stack , clara , computational healthcare life science deck . deck optimizing containerized ngc . nvidia sdks created service nearly 2.5 million developer , researcher , software company accelerated 1,800 application billion computer user , global computer maker , cloud service provider , solution partner , 6,500 startup inception . built gtc . built -- sdks serviced . gtc . paresh kharyato tell announcement gtc , 've got special speaker lined guy . let first introduce paresh kharya tell nvidia ai . paresh ? thank , jensen . jensen talked ai software writing software , ai already achieving result human written software . interesting thing , approach extremely scalable , larger , complex model , create capable ai , ai 's 's accurate applicable many different type task . chart left basically show number day take train model one petaï¬‚op supercomputer computer continues grow exponentially . 's doubling every couple month . think another way . moore 's law still true , could delivered every 10 year ai need every 10 month . larger model need larger larger supercomputer train expanding opportunity nvidia , capability advanced ai model potential transform industry immense . right , see recent example . nvidia 's natural language understanding ai took race reading comprehension challenge consists middle school high school level test . average human score 73 % . nvidia 's megatron-bert scored 91 % . addition reading comprehension , language model also used predict 3d structure protein , reading amino acid sequence . dramatic impact discovering drug . kimberly talk bit later . facebook ai research developed large ai model-based chatbot exhibit knowledge , personality empathy , call blenderbot . half user tested preferred chatting blenderbot human . another work , researcher caltech developed reinforcement learning drone ï¬‚ight control system . smoothly land drone payload different surface , critical problem solve making safe drone delivery . larger advanced model bring transformative capability deployed application , also require gpus inference economics work company . take instance , bert-based model used microsoft improve search engine bing . accuracy model resulted largest improvement microsoft search engine . however , impossible run cpu . gpus , microsoft hot 800 time higher throughput could run model real time . led switch thousand nvidia gpus running azure power search . ai need gpus training inference . ampere architecture delivered first time unified platform ai training ai inference . provided 20 time higher performance , unified computing architecture data analysis , preventing [ ph ] inference multi-instance gpu ability scale time single server . reason picked readily industry . a100 , jensen talked , fastest ramp data center gpu history . shortly jensen announced may , 50 different server model announced world 's leading server maker based a100 . leading hyperscalers announced plan deploy a100 cloud . 's already available google cloud , microsoft azure oracle cloud . course , mighty gpu architecture foundation nvidia ai platform . however , ai workload push limit every aspect data center , computing , storage , networking , software run . addressing challenge democratizing ai three pillar nvidia ai platform : data processing training , inference , ai application framework . first , data processing featuring engineering training , platform run scale one gpu multiple gpus multiple node across data center running framework , screening type model available cloud , company starting deep learning , nearly every company data processing exponentially growing scale . work rapid transforming data analytics landscape . accelerate spark , world 's leading data analytics platform used 16,000 enterprise 0.5 million data scientist . earlier today , jensen announced cloudera accelerated nvidia ai . cloudera 2,000 plus customer run 400,000 data center server , manuvir touch bit presentation . second , inference great computing challenge . requires lot software make work . break four step , complex . starting pre-dreamed state-of-the-art model key use case available ngc , cloud registry hub gpu accelerated software . provide easy ramp enterprise customer infuse ai application . use transfer learning tool kit refine model data set optimize domain . nvidia tensorrt , optimizing compiler , help optimize model run inference gpus . finally , triton inference server actually help run model , application send query constraint like response time need throughput need scale thousand million user triton take care plumbing run model . third pillar ai application framework . package stack provide end-to-end workï¬‚ows incorporating ai specific application domain different industry use case . help democratize complex ai development pipeline help enterprise jump-start adoption ai use case . application framework target challenging ai application large market , like self-driving car , robotics , drug discovery , conversational ai , recommendation system . scale inï¬‚uence cloud huge , starting point ai infused service . opportunity service inference massive . running ai inference nvidia performant cost effective continue see rapid shift inï¬‚uence running nvidia gpus . talked tensorrt bit earlier , optimizing compiler inï¬‚uence . latest version 2,000 optimization . tensorrt 's downloaded 1.3 million time used 16,000 enterprise . term gpu compute inference , 've gone -- practically negligible four year ago shipping 166 extra ops last 12 month . 6 time said last year . since aws launched first gpu accelerated cloud instance 10 year ago , every cloud offer nvidia gpu , aggregate throughput increasing 10 time every two year . chart right show growth aggregate nvidia gpu inference compute cloud . estimate aggregate gpu inference compute exceeds cloud cpu . trend , two three year , nvidia gpu represent 90 % total cloud inference compute . ai application service rely nvidia inference , passed tipping point . nvidia inference enabling transformative capability customer . microsoft -- earlier today jensen announced , adopting nvidia ai azure power smart experience microsoft oï¬ƒce , world 's popular productivity application . first feature include smart grammar correction , question answer , text prediction . nvidia gpus , microsoft able cut responsiveness le one-fifth second enables real-time grammar correction . gpus also provide high throughput , eï¬ƒciently scale service half trillion query expect service year . second , cyber crime cost global economy nearly $ 1 trillion , 1 % global economy . american express alone 8 billion transaction year , totaling $ 1 trillion 115 million credit card holders.using nvidia ai , american express us advanced ai ten million transaction everyday take two millisecond detect fraud instantly . ai fraud detection going help safe financial industry hundred billion dollar year nvidia ai make possible . finally , tencent platform content group numerous recommendation system support application ; video , news , music application et cetera . thousand model handle hundred billion query per day . nvidia gpu inference enables use advanced model production tencent . talked handful customer nvidia ai inference , today nvidia ai inference operating service company broad range industry automotive consumer internet cloud-based company robotics , medical , retail financial service , industrial customer . manuvir dasmany case , nvidia ai inference make possible deploy advanced ai production use case case save money customer . nvidia accelerated ai inference adoption reached tipping point . , would like hand next speaker , manuvir da . thank , paresh . good morning good afternoon , everyone . jensen mentioned beginning call , data center new unit computing . amount data available processed every application running data center growing dramatically . mean application longer fit within individual server must spread across data center . paresh talked work nvidia done many year accelerate particular class application running data center . talked three pillar ai training inference , well different framework . action , want talk next opportunity nvidia , next phase work accelerating data center , applies particular class application , every application workload running enterprise data center . particular , talking technology introduced every one ten million server deployed enterprise data center . consider happening enterprise data center last decade , infrastructure moved towards software defined model guided advancement happened public cloud . right hand side , see variety data center infrastructure function , traditionally performed hardware . example , firewall located edge data center complicated networking infrastructure , well operation performed manually army human manage infrastructure . last year , function moved software running every application circle . left hand side , picture showing stack running within every application server . box top represent actual application workload running virtual machine container bare metal environment . box represents infrastructure function deployed software running every application server ; software defined networking , software defined storage , software defined security , infrastructure management , typically deployed layer like hypervisor . great example vmware , used almost every enterprise customer virtualized environment . every one server connected data center network , communicating moving data one server another . accomplished network interface card nic . know , nvidia working mellanox well part family . mellanox worked connectx family mix many year , state-of-the-art term mix transfer data across data center equipped powerful acceleration engine make networking io operation proceed fast . challenge model ? see representation different infrastructure function running layer infrastructure . challenge amount data grows , east-west traï¬ƒc server data center growing dramatically . look today , already see 30 % resource cpu every server occupied infrastructure function , leaving le resource available actual application problem going grow , amount data growing exponentially therefore amount resource required different function also growing time le le room available cpu server run application . new solution needed , new piece hardware need sit alongside cpu every server order take increasing load . therefore introducing next concept computing refer data processing unit , dpu . role dpu take software function , oï¬ „ oad cpu put new kind chip call dpu . extension chip already nic . particular , along acceleration engine chip , introduced cpu form powerful arm core host infrastructure function . see picture right-hand side moving function new chip , dpu , resource host cpu available run application , whether running virtual machine container payment [ ph ] . 's important stress moving functionality dpu , situation burden growing amount data growing would apply picture right hand side well . however , dpu sitting within nic , already processing every packet data ï¬‚owing network therefore infrastructure function operate data much eï¬ƒcient dramatically accelerated perform nic rather cpu , leading effect obtained application move cpu gpu . oï¬ „ oading , dramatic acceleration lead massive reduction amount infrastructure needed run amount application workload leading tco benefit customer . jensen mentioned keynote morning , introduced bluefield ï¬‚agship dpu purpose . provides variety acceleration engine different functionality io storage , security . 's got 7 billion transistor . give one example power technology , consider different activity performed dpu perform host cpu , would require upwards 125 x86 core perform functionality , really practical reason believe computing move forward every server equipped one gpus make processing feasible . move forward journey gpus nvidia , introduced cuda platform , software abstraction allowed ecosystem 2.3 million developer proceed forward single api even advance technology inside gpus . exactly thing gpu . , jensen today announced doca , data center infrastructure chip architecture , abstraction interface developer access capability gpu . 's based open api , p fall packet processing , dpdk network , spdk storage . open apis developer ecosystem build variety software defined infrastructure run dpu opposed running host cpu . beginning journey . know well , nvidia belief strongly power ai . power ai brought bear data center infrastructure well . , embarking journey jensen announced take silicon dpu add tensor core silicon gpus well , infuse ai data center infrastructure . lead complete road map nvidia bluefield-2 starting point . chart show road map . bottom left , see bluefield-2 certain capability term network traï¬ƒc , well computational power . gpus based one architecture doca , see timeline advancement . y-axis referred computational capability . year bluefield-2 , bluefield-3 , followed bluefield-4 , two year bluefield 2. shown y-axis , bluefield-4 , combination silicon dpu , well state-of-the-art gpus 600 time computational capability bluefield-2 . significant advancement . waiting two year bring capability . get point integrate silicon , producing new form factor combine dpu gpu single form factor single card . referred bluefield-2x , see vertically bluefield-2 , follow bluefield-2 month , 85 time computational power bluefield-2 . significant advancement put ai infused data center infrastructure chip hand customer base much bluefield-4 available . mentioned earlier infrastructure function performed software today typically live within layer like hypervisor . nvidia vmware announced last day , major new partnership vmware bring enterprise customer base . know , majority enterprise customer today use vmware platform virtualized data center . announcing work together take vmware platform justin boitanoand move functionality onto nvidia bluefield dpu host cpu freed perform run application . time , also announced partnership vmware bring accelerated ai application vmware platform truly democratize ai make ai available seamless manner every enterprise customer . picture full stack collaboration . see top , talking traditional enterprise application already running vmware platform , well workload paresh talked accelerated nvidia gpu . workload done one infrastructure using vmware platform , turn run gpus , well dpus present every server provide form acceleration , application acceleration domain workload accelerated gpus , well dpu-based acceleration applies every server every workload . time , paresh talked data analytics next frontier workload accelerated also announced partnership cloudera . cloudera predominant platform used enterprise customer spark deployment . cloudera platform powered nvidia , also accelerated gpus , well model dpus . , 'll hand justin talk edge . great . thank , manuvir , good morning everybody . big bang ai originally happened cloud , ai really transform every industry wave new ai infrastructure announced today using nvidia egx edge ai platform . , want talk announcement put context . today , internet connects billion people giant cloud data center , future going trillion device connected million edge data center , going create internet thing , 's 1,000 time bigger today 's internet people , smart retail manufacturing service robot , self-driving car , smart street city , computing going extend cloud data center -- every corner world . ai sense , infer , act accordingly edge . amount data generated high resolution sensor simply much data moved back cloud . thing ca n't done cloud action need immediate . software powering new internet written human , computer learning data . new way computing called ai . edge ai driving tremendous acceleration -- driving tremendous acceleration demand computing , precisely time moore's law slowed , requires new approach computing legacy architecture ca n't keep . nvidia 's accelerated computing platform really platform power future every industry . today made several new announcement nvidia egx edge ai platform . egx -- nvidia egx designed make easy world 's enterprise quickly stand , state-of-the-art edge ai server . nvidia egx control factory robot , perform automatic checkout retail , orchestrate ï¬‚eet inventory moving robot , help nurse monitor patient . egx full stack solution consisting ai computer , system software , ai framework ï¬‚eet orchestration management software . security really top feature egx . every aspect security measure operating system , protecting data motion rest , securing application ai model signing encryption tamper proof infrastructure automate future industry . today announced early access nvidia fleet command . 's software-as-a-service deploying managing ai service edge . fleet command simplified setup management ensuring simple one- touch authentication connect new node . n't need linux admins ï¬‚oating around edge location . allows store associate warehouse manager without experience quickly set new system . important feature egx though rich ecosystem partner bringing ai every industry . egx server certified leading oems include nvidia bluefield-2 ampere gpus . ensures customer quickly find easily buy hardware 's optimized ai performance securely managed updated leading enterprise platform . fully accelerate run time egx service , 're working leading enterprise platform company including vmware , red hat , canonical , suse others test validate performance cuda-x delivered ai training inference platform . 're building industry focused ai optimized framework make easier developer bring new innovation every industry . every industry benefit egx . network partner , egx help company manufacturing , health care , retail , logistics transportation . oem partner , software partner , industry focus solution maker participate 's open platform . truly iphone moment world 's industry . nvidia egx make easy create deploy new edge ai service . , let share type customer 've working build refine egx edge ai platform . previously spoke 're working leading company like wal-mart , procter & gamble , bmw siemens bring range new -- -- bring ai range industry , drive higher business eï¬ƒciency -- let highlight 've announced today . kimberly powellkion group largest logistics automation supply chain solution provider globally operates 6,000 automated warehouse worldwide . matic [ ph ] , 're developing smart cabinet adaptive speed conveyor increase distribution eï¬ƒciency throughput . feel developing automated forklift . kion looking simplify management deployment ai application ï¬‚eets gpu accelerated system used optimizing warehouse eï¬ƒciency using nvidia fleet command . look retail industry , lose 1.5 % sale $ 60 billion per year shrinkage . ai instantly detect scan checkout . kroger one largest superchain market -- super chain -- supermarket chain u operate -- operates close 2,800 store . ever seen vision ai application , reducing customer error , providing faster customer checkout improve shopping experience . every healthcare provider world want reduce operating cost , improving patient care . northwestern medicine , whiteboard coordinator used operate network thousand sensor , camera microphone perception conversational ai help nurse monitor patient , reducing load nurse improving care . 's egx platform . 's full stack open platform , state-of-the-art computing , designed security ground . broad ecosystem partner help enterprise around world create ai service . range software vendor like vmware , red hat , canonical suse industry focused assay , including ibm accenture , well every major oem odm , dell , hp , cisco , lenovo , fujitsu many . 're working hundred isvs leveraging power ai framework build industry-focused ai every industry . every enterprise company understands power ai . longer need convinced , need broad partner ecosystem show become ai-driven enterprise , powered world 's widely adopted accelerator broad range ecosystem partner , 're working bring ai every industry nvidia egx edge ai platform . , let hand kimberly powell , run healthcare business . great . thank , justin . hope everyone well morning . healthcare industry extraordinary moment time . global pandemic created biggest threat humanity lifetime . race discover new therapy never critical today healthcare industry producing biomedical data couple month last several hundred year . perfect storm catalyze ai drug discovery . 're excited announce nvidia clara discovery , suite state-of-the-art tool tackle pressing future challenge drug discovery . end-to-end drug discovery process incredibly complex starting biology understand human disease get sick first place , chemistry combine molecule inhibit enhance biological behavior next patient uncovering biomarkers medical science associated disease response . pharma industry huge $ 1.5 trillion large , still much unsolved problem taking well 10 year , costing $ 2 billion still high failure rate 90 % . drug discovery draw every computer science domain accelerated computing , data science machine learning , deep learning natural language processing , clara discovery brings together decade worth work working industry 's popular gpu accelerated tool like schrodinger computational chemistry n't tool built nvidia clara parabricks genomics , clara imaging pathology radiology , biomegatron biobert natural language processing nvidia rapid gpu accelerated machine learning . suite tool powering next generation computational drug discovery accelerate discovery month minute using ai neutral data improve success rate discovering new lifesaving drug . uk epicenter healthcare research . cambridge home -- francis crick james watson discovered structure dna -- home world leader pharmaceutical industry rich university startup ecosystem focused healthcare . researcher scientist uk need say computing infrastructure , important time nvidia building uk's fastest supercomputer 're calling cambridge-1 . 's 400 petaï¬‚ops ai performance supercomputer based nvidia 's dgx superpod . become fastest supercomputer uk top 30 top 500 also top 3 green500 . cambridge-1 host collaboration already underway uk ai healthcare researcher academia , industry startup . first partner gsk , astrazeneca , king's college london , guy 's st thomas ' nh foundation trust , oxford nanopore technology , already using nvidia gpu computing . cambridge-1 let experiment large infrastructure resource 're building . cambridge-1 accelerate use ai vast wide healthcare ecosystem . also exciting announce today glaxosmithkline leading way pharmaceutical industry adopting artificial intelligence data driven drug discovery . 're partnering gsk one world 's first ai drug discovery lab . gsk pushing frontier drug discovery data driven drug discovery year using genomics improve target selection early drug discovery process recently established gsk 's london based ai hub . gsk nvidia together expand use biomedical data field digital pathology , radiology , genomics , natural language processing using clara discovery optimize computational discovery application . addition gsk 's investment colette kressdgx a100 system , gsk also able access nvidia 's new cambridge-1 supercomputer . conclude , perfect storm ai healthcare race time global pandemic , explosion biomedical data utility ai , accelerate healthcare research discovery month minute , 16x across many domain used drug discovery harness biggest ai breakthrough natural language processing tap invaluable biomedical literature clinical data , healthcare vocabulary domain specific , complex disease , protein drug name case point covid-19 . tipping point ai healthcare 're delighted building industry's computational platform partnering world leader healthcare . thank . okay . colette kress 'm going quick overview gtc fall 2020 . first , 've seen u talk much nvidia 's ai nvidia 's overall momentum term gaining across many different piece . one thing bound u altogether really cuda overall development platform . 20 million cuda downloads year , 6 million last year . seeing also expansion nvidia able power much overall enterprise . seen managerial discus term 're seeing collaboration vmware cloudera well introduction nvidia dpu data center chip architecture software well . also got hear nvidia 's edge ai internet trillion thing edge ï¬‚eet command reoccurring revenue service adding later . kimberly , 've heard focus term nvidia healthcare key part drug discovery key partnership important area uk , gsk . allowing u broaden overall ecosystem customer adoption every server , every storage oem , hundred isps , thousand enterprise , keep mind gtc , also exposed 2 million -- 2.3 million developer focused overall computing platform . 'm going take next opportunity discus important piece high level view seizes market opportunity nvidia concur [ ph ] . first , nvidia rtx target large growing market gaming professional visualization . trailing 12-month revenue two market close $ 8 billion , representing 18 % cagr last five year . computer graphic first holistically largest application nvidia 's gpus . graphic growth going forward fueled expanding universe gamers , trader professional , already number $ 1 billion around world . operator q - aaron rakersone day expect every human gamer connected others virtual world . rtx platform ampere architecture launched year giant step making future reality foundation growth graphic next decade . gaming historically largest revenue driver , last quarter first time , eclipsed data center platform , driven ai . last quarter also first include mellanox acquisition . let take moment update total addressable market opportunity data center , significantly expanded inclusion mellanox . see $ 100 billion tam 2024 across four main market within data center , including high performance computing , hyperscale cloud , enterprise edge . may recall , last year sized data center tam $ 50 billion 2023. let help understand driver expansion . first mellanox , addressing large data center networking market particular focus high performance hyperscale software-defined environment . add $ 20 billion tam . second , heard manuvir 's presentation , introducing new class processor data center called data processing unit dpu . dpu oï¬ „ oads substantial amount processing currently done cpu , well processing done data center infrastructure today , word , data center ( inaudible ) . new process out 10 billion estimated tam period . third , heard justin 's presentation , enabling emerging edge ai market egx computing platform . add approximately 10 billion tam . opportunity uniquely enabled combination nvidia compute mellanox networking , delighted mellanox team board . concludes prepared remark today 's presentation . turn back operator , open line q & . question answer ( operator instruction ) first question today come aaron rakers well fargo . line open . yeah . thank taking question presentation . want , colette , touch brieï¬‚y tam assumption 're making . guess , first , kind general kind gpu tam , give u kind framework 're thinking attach rate gpus data center ? - colette kress q - aaron rakers operator q - cj muse - jensen huangand kind similar question think time horizon , 10 billion opportunity data processing unit , 's underlying assumption kind industry move , mean every server incorporating form dpu ? thank . yeah . thanks , aaron , question . first , let start , 's great place look term overall server environment , use overall gpus acceleration , well ai many server . nothing changed term view future . similar , everybody would gamer , expect everything overall data center environment accelerated movement ai getting u . early day talk attachment . discussed already continued growth overall attachment , coming , , small base folk focused ai . expansion 've seen u today 's presentation term gtc overall really expanding different type workload , well different customer , whether enterprise , whether focused edge core quality workload within data center really stronger attachment go forward . summary , nothing changed . goal term getting server accelerated use ai still . thank . next question come cj muse evercore . line open . yeah , good afternoon . good morning . thank presentation today thank taking question . guess , could ask two . first , jensen , discussed number ai platform keynote morning . help u prioritize focused , think biggest revenue opportunity looking next one two year ? perhaps question kimberly . announced partnership gsk , working astrazeneca , got cambridge-1 . really curious think go-to-market strategy revenue model medical business ? thank . yeah , cj . ai started research , first five year work conversation related groundbreaking work done , superhuman image recognition , superhuman speech recognition , near human natural speech synthesis . ability process data scale human could predict recommendation conversational ai , recent breakthrough natural language understanding . first five year really focused groundbreaking work early work self- driving car , robotics , et cetera . first wave economic growth ai , economic impact ai cloud . would expect next couple year still -- unquestionably still cloud . vast majority , -- would expect next couple year , cloud grow significant percentage , often quite large base . 's multi-billion dollar business . said , passed tipping point service , application take advantage nvidia gpu inference , 's every single cloud 's large abundance . amount computation -- aggregated computation nvidia gpu inference exceeds cross -- surpassed cpu . 's growing factor 10 per couple year , couple year 90 % world 's total inference compute capacity would gpu accelerated -- nvidia gpu accelerated . , think -- 've seen type platform , reach tipping point , acceleration adoption actually go -- obvious reason , people feel really , really safe could take advantage , always count nvidia architecture every cloud , abundance every single cloud . , think next couple year see nvidia ai growing cloud service provider large number ever larger number . next wave enterprise . enterprise , 've described two way . enterprise helping automate company lot work manuvir talking . requires u re-architect data center , system software re- architected , reason enterprise software enterprise data center infrastructure different cloud . work partner , particularly vmware lot computer science around current stack . course data analytics application , we're going grow enterprise even finish vmware , many early adopter perfectly comfortable building multiple infrastructure , that's going get turbocharged incredibly work vmware next several quarter come market . meanwhile , 're preparing ecosystem speak . next wave edge autonomous . , -- enterprise company comfortable mastered processing large amount data , also collecting giant amount data data connected sensor webservices application product know thing world today , could anything , lawn mower , refrigerator , elevator , air conditioner , name . 're going connected either 5g wifi allows collect data , turn product essentially smartphone connected smart device . - kimberly powell q - cj muse operator q - vivek aryaiphone moment coming . 's wave . 're preparing one wave hope happen bam , bam , bam , bam , keep happening course next five year , surely . we're -- 're looking one largest computing opportunity ever . kimberly got next question . go ahead , kimberly . yeah . thank . thanks , jensen . cj , thanks question . bit healthcare 's go-to-market strategy , 's much like nvidia 's enterprise go-to- market strategy industry . think 're building clara , building domain specific computing platform healthcare , computational healthcare deliver call full stack silicon system software software , think , described clara discovery , aspect drug discovery still insatiable demand compute . -- looking exabyte genomic data near future trying use artificial intelligence extract association large population genomic data looking vast chemistry space 10 60 potential combination using combination search docking simulation , done silico today , still totally consume world 's fastest supercomputer work 're covid today . system covid complex 've ever simulated . still insatiable demand . move new budding area natural language processing , paresh talk , fact growing complexity , size train model every 10 month . 's different . mean model biomedical specific natural language model take ten thousand gpu hour train . incredible amount opportunity ahead u that's 're really inspired clara platform . hope catalyze quickly disseminate capability building cambridge-1 , enabling industry leading researcher longer term , time , plenty opportunity monetize across three ; system , silicon software . thank , . next question come vivek arya bank america security . line open . thanks presentation , thanks question . actually two well ; one colette first , one jensen . colette , hoping could give u sense supply situation ampere -- data center gaming side ? good lot demand , supply situation working ? , could talk specifically gaming side well ? - colette kress - jensen huangand jensen , question , arm fit data center vision ? heard today workload value going pre-processing dpu smart nic , realize contains embedded cpu , value going dpu various kind accelerator gpu , matter one way another , whether arm x86 , 's cpu architecture choice . , word , really critical owning arm think achieve similar level success optimizing dpu accelerator , 's value data center shifting anywhere ? vivek , thanks first question discus term supply . 're comfortable supply term supply outlook provided . turn overall data center look overall ampere architecture , keep mind a100 going forward complex product . mean , probably take multiple quarter really work supply need get market full capacity . also focused term ampere architecture overall -- gaming , 're initial stage ramping . take month u fully supply channel , right track term providing . sure , 'd love supply sooner 're ramping , 're also executing plan , feel comfortable supply mean outlook . achieve extraordinary success success 've talked guy without arm . however , arm really exciting thing , let highlight two . first one extending nvidia 's architecture accelerated computing arm ecosystem . might notice 've -- accelerated computing surely , passed tipping point everybody acknowledge way go forward , moore 's law ended , ended last week , n't revive week . order extend computing , bring accelerated computing device computing device , including arm . benefit owning arm could also offer nvidia accelerated computing soft ip form , hardened ip form soft ip form , nvidia ip company , 're chip company , nvidia ip company , 'm pretty sure tsmc make chip 'm pretty sure deliver , effectively email completion multi-billion dollar project nvidia soft ip company , 're ip company benefit arm team vast network ecosystem arm device , billion billion unit sold every year extend arm accelerated computing , ai computing -- renowned . second , going bring lot platform technology arm whole bunch new data center environment . could high performance computing , cloud q - vivek arya operator q - timothy arcuri - colette kressdata center , enterprise data center talking earlier gpus , edge data center , whole bunch new technology 're rolling . turn cpu core arm , world class , mean , absolutely energy eï¬ƒciency cpu core world . turn cpu core computing platform , 're going bring -- 're going deliver lot value arm , 're going create lot value arm beyond mobile device . market 'm talking really nascent create almost value around arm platform would great first . think two enormous opportunity extend nvidia 's accelerated computing , large ecosystem around world . , secondarily , 're going create lot value around data center server , computing platform nascent arm would love create value around . thank . next question come timothy arcuri ubs . line open . thanks lot . two well . guess first question colette . much $ 100 billion tam china ? first question . second question jensen , really 's expectation around share $ 100 billion tam . way sort handicap would reasonable share assumption within non-gaming tam ? guess , asked sort take non-gaming non-mellanox revenue year relative tam set forth year ago , seems like 're maybe mid-teens like 20 % tam . guess question , would disappointed say 20 % share tam 2024 ? guess , ask different way , really expect gain share within rising tam story really riding growth tam ? thanks . let first start question regarding tam regional breakout . n't ability time really look opportunity region , keep mind , area 're focused , opportunity take every single region . look addition added mellanox , gpu , edge look term type customer market also addressing . opportunity u focus hyperscales massive expansion term cloud . considerable portion overall tam whole . additionally , think overall enterprise opportunity . lot growth announced today term key area enterprise focus . high-performance computing big part u 10 , - jensen huang q - timothy arcuri - jensen huang12 year . , expansion term bringing acceleration ai also area . edge think device , even region opportunity grow . 've expanded every single one different area today term increase $ 100 billion mellanox , dpu , overall edge . yes , region , china u definitely benefit . address entire tam except x86 cpu . 's really simplest way think . almost computing platform serve , accelerated computing important part . going forward , believe thesis -- believe thesis , two important thesis . first one , application future infused ai . example , something like microsoft oï¬ƒce infused ai . would suggest ai would every computer , would suggest every computer accelerated . certain every computer accelerated fact , convinced 30 year ago every pc accelerated gpus . , certain . certain fact cpu alone job . complete certainty . believe thesis ai , believe ai every application , ai open new market create new application n't writable human know right . believe therefore accelerated computing going everywhere . platform 're , accelerated computing gpu networking frankly dominates vast majority electronics inside computing platform . second , believe world zero trust . believe protecting data center perimeter historic . 's like building big wall . make sense . future security trust -- zero trust 's securing every single transaction , every single node , every single application . therefore , need take used security appliance perimeter data center put server , every single one , every single network , 's reason networking chip going important security chip future , 's input output come . that's exactly want put , 's exactly gpu invented . security going force every single computer planet something like dpu . , believe every single server node accelerated dpu . every single server application accelerated gpu . , therefore , vast majority world 's tam minus x86 cpu opportunity . thank , jensen . thanks . yeah . thank . operator q - stacy rasgon - colette kress - jensen huang - colette kress - jensen huang q - stacy rasgon - jensen huangyour next question come stacy rasgon bernstein research . line open . hi guy . thanks taking question . two well . first , go back chart showing gpu inï¬‚uence workload cloud versus exceeding cpu . , guess , given trend , cloud revenue today split inference training ? -- like , trajectory growth relative two , relative ? second question , tell u little revenue model vmware partnership work . working incentivize quarter gpu use enterprise direct revenue share ? something . thank . let give -- ( multiple speaker ) . yeah . n't give shot ? okay . reason inference -- well , first , know inference -- hello . hello . yes . yeah , 've got reverb . 's okay . first thing , course , stacy , know inference acceleration business growing , quickly -- reason 've already talked . turbo charged even time ampere , ampere first universal gpu . used essentially three gpus data center . one would heavy duty training system build large model -- ai model . second cloud training platform , based pci express . like new gpu -- announced today , nvidia a40 going go cloud easy deploy . 's easy put pci express - colette kress - jensen huangservers , 's based pci express . a100 based sxm2 , different type networking different type system architecture , fact , different . , second cloud-based -- cloud-based training second gpu . third inference gpu . well , ampere combined one architecture , , could literally use ampere , a100 sxm base training , well cloud training , well inference , one single architecture . -- like -- would like pci express version , cloud data center able facilitate lot pci express server , a40 gpu allows -- a100 a40 gpu depending size allows training inference . architecture 's universal . training , inï¬‚uence , computer graphic . thing -- know well , one architecture . , 's reason inference performance going continue grow historic rate , really , really high , number unit fact 're increasing throughput factor 20 generationally . ability put lot unified aggregated gpus cloud inference based . -- strategy really good strategy . know stacy , people want , want make sure use cloud evolve software forward type technology develop software capability , could video decoding , could whatever , x86 arm case accelerated ai . whatever capability use cloud available every cloud , ï¬‚exibility , -- established . number two abundance capacity 's tipping point aggregated ai inference throughput big deal . think point rate 're growing , 's forgone conclusion 's going vast majority computing cloud . colette , second question ? second question vmware ( multiple speaker ) ( technical diï¬ƒculty ) . yes . yeah , vmware , three way benefit 'll leave important one last . first way benefit , course , vmware running -- vmware , know , data center operating system . represent 70 % world 's data center . operating system really computationally complex day reason software defined data center , networking stack , storage stack , security stack , virtualization stack , 's running vmware . first thing 're going 're going oï¬ „ oad accelerate isolate beta playing application play ï¬‚owed alone creates really fantastic opportunity dpu . cheaper , purely faster unquestionably secure vmware running x86 q - stacy rasgon - jensen huang operator q - john pitzerplus dpu instead x86 without dpu . first creating opportunity gpus . second , every one vmware stack go virtualization stack gpus hypervisor -- vmware hypervisor essentially nvidia hypervisor virtualizing gpus . virtualization gpus really complex open cuda , open graphic rtx , open cudnn , open capability buried underneath hypervisor otherwise . second thing , open virtualization stack , call gpu data center . okay ? third really biggest one , ability enterprise able accommodate three domain computing scale virtualized micro service . three harmoniously basically transparently data center using vmware . ability enterprise easily adapt really accelerated ai n't think , like . vmware never fully transparently integrated nvidia gpus accelerator aside cpu . transition big , big deal open great opportunity vmware world ai , open great opportunity u able -- transparently , seamlessly , easily integrate nvidia ai world 's data center . three way . got . thank , guy . yeah , thanks lot , stacy . next question come john pitzer credit suisse . line open . yeah . good morning , guy . thanks presentation . two question . jensen , presentation believe paresh 's presentation , talked software writing software sort iphone moment , 'm wondering could help u elaborate little bit . analogy 're sort io 'll collecting recurring revenue stream sort ai apps way apple ? , expect hear mercedes like deal coming pipeline think monetizing software part $ 100 billion incremental tam colette talked morning beyond ? secondly colette , talked kind ampere extremely strong guy clearly guided october . also guided gross margin little bit pressure ramp new product . 'm - jensen huang q - john pitzer - jensen huangcurious , strength 're seeing demand outstripping supply 're supply issue well , think gross margin comment ? thanks . $ 100 billion tam include many thing almost software thing 've talked guy . n't even include mentioned stacy virtual compute . n't include geforce , n't include drive , n't include fleet command , n't include software stack enterprise . 'll plenty opportunity talk guy future . today , want stay , focused , keep nice conservative plenty talk . nvidia full stack accelerated computing company know opportunity 're open computing platform . work network partner way would like . -- would like hold stack reason good , 're good . , 'd like develop part use hour . work figure part would like use part would like use . people would like build use lot open source tool library , like cuda-x rapid open source stack build data analytics service . 're open computing platform work across multiple layer technology system , sdks application framework . want able work entire world 's industry democratize ai bring accelerated computing many place . -- we've captured far tam hardware stuff , hardware stuff pretty good know . mercedes deal , run number , 's hard envision kind software recurring revenue stream , large hardware revenue stream , think potential service software recurring revenue relative $ 100 billion tam ? yeah , 's great way think , . reason -- n't mean guy go make change model , okay . listen strategy , listen strategy think implication think 're going building public piece talked gtc guy know 're going . question case autonomous vehicle , business model created mercedes really quite extraordinary , 's potentially best one . reason , first 's incredibly hard able create computing platform integrates safety concerned , safety conscious company industry accommodation heritage existing technology able integrate , infuse - colette kressinto harmoniously great challenge . 's beginning . took u 10 year learn . 're inside car 're computing platform , create application sit top . unlike -- unlike smartphone , 're going able create application cloud download work every single android phone , 's going like reason safety . application safety concerned first one application opportunity belong car company . one reason extraordinary thing . daimler figure way make car software defined turn application platform , 'll grow application platform 2.5 million car year , 'll grow instantaneously . course decade , could imagine economic opportunity 're going create . business model share . 're lot hard work course well becomes one 's significant opportunity . u , would like -- 're open platform company would like car company opportunity . reason simple . number company world could create end end self-driving car stack world-class , deliver real street , , integrates existing car industry , . , think great opportunity 're going continue scale . 're going see example like . see example like . always free community version , 's one policy . community version free , developer version could free , always free version . company , want make sure 're hook want make sure kind enterprise agreement enterprise business model allows get front open source allows get front developer others get software hand towards software debug . let see touch based second question regarding overall ampere demand impact term gross margin . far , gaming demand rtx 30 series chart . expected really great holiday season . knew overall platform bring best generation generation performance ever . 've got great release fall game coming . work home even bringing gaming entertainment social arena . racing catch demand , ramp going well . yield good . intact . think gross margin remind term gross margin outlook q3 . outlook q3 usual quarter mix driver overall gross margin . expect strong sequential increase q - john pitzer - jensen huang operator q - mark lipacis - jensen huangfor gaming . gaming piece business strong , took slight sequential dip term guidance gross margin . everything seems place , intact , change term gross margin term 're seeing . helpful . thanks guy . thank . next question come mark lipacis jefferies . line open . hi . thanks presentation today . question , think one jensen , provide integrated data center scale architecture , 'm trying make sure understand far across data center value chain deep value chain nvidia -- feel nvidia go order deliver . think pretty clear , nvidia chip company platform company , maybe could compare feel need deliver across value chain today today 's data center value chain . nvidia effectively becoming equivalent company selling processor data center today , company selling server software , networking company software , o application side , far software stack 're going ? could provide maybe analogue today 's data center versus data center scale architecture 're delivering future ? maybe would helpful level set . thank . sure . first -- first -- three question 'll hit right away , i'll explain . one , 're like company exist today , ai problem opportunity , challenge opportunity unlike software 's ever written , otherwise could thing 're right , number one . number two , integrated data center , 're . number three , innovate much need -- much need little -- innovate much need little guiding principle nvidia little . 're trying everything , trying thing , 're thing world relies u , 're thing n't , world . absolutely case n't today , world n't . absolutely case gelsinger worked vmware partnership u , two u n't , n't get done . get done . , go thing world n't . answered three question quickly . let give back little bit explain . one , way ai written , way ai software , 's computer learning data , 's learning data collect asked , coach , inï¬‚uence type neural network architecture type data presented , way wanted learn , coach , 're like coach , 're like teacher , go , know run day week , junk [ ph ] amount data writes software . 's done writing software , 've made -- ca n't read . unreadable . 's like neural -- 's like brain dump somebody 's brain 's readable requires new type computer run . , way software written , methodology written , infrastructure pressure creates pod [ ph ] , ( technical diï¬ƒculty ) -- talking , four speaker fantastic today , really appreciate work . could hear phrase , tip iceberg challenge computing 're solving . , software different , way 's written different , pool [ ph ] different , pressure infrastructure different coordinate different . time history see albus 1 [ ph ] data center , enterprise data center advance hybrid cloud enterprise data center manage three computing environment . 's never happened . one computing environment bare metal ( inaudible ) computing like supercomputer . number two , 's virtualized multi-tenant . virtualized , easily manageable , easily scalable , easily secured , multi-tenant . , third , continuized micro service . core far edge , 'll never visit . drop server , connect network , hopefully never go back warehouse never go back store room ever . manage one thin glass , far away . three type computing domain never happened one company . 've got go make happen 's never done ai 's never done gpus . , go create necessary gpu . done creating -- 're done creating , important . 're done creating , open like sdk , open like sdks , system sdks , adp [ ph ] , egx , agx , 're sdk , hardware component oems integrate . put top entire software sdk , put library top application developer create tool like application framework basically ai skill pre-train . stuff put cloud . q - mark lipacis - jensen huang operator q - matt ramsay - jensen huangall stuff put cloud , 's certified , 's optimized , run data center , run cloud . , result , connect network partner software developer , system maker , solution maker , cloud service provider want partner world . run ai , run nvidia 's already computing , run nvidia clara , run nvidia rapid , run nvidia isaac , jarvis , mervin , sdks created . hope 's helpful . know look different . however , accelerated computing need look different , moore 's law finished . number two , ai different , 's written human , written machine . world changed , 's new type company need created . helpful . thank . right . thanks lot . next question come matt ramsay cowen . line open . yes . thank much . good afternoon good morning . jensen , couple question . first one , noticed bluefield dpu roadmap eventually guy integrate sort full ai engine dpu . wondered could talk little bit acceleration side ai opportunity low-hanging fruit might available -- particularly security domain ? second question , ai acceleration , dpu acceleration , integrated stack , mean whether buy arm n't buy arm , seems like could make cpu maybe could talk little bit pro con going one piece tam 're addressing today ? thanks . yeah . excellent question . number one , 'll give example , intrusion detection . intrusion detection distributed perimeter , data center protected every single transaction every single node , every single application , protected door . reason , n't forget , intruder largely inside building already . future , also public cloud . entire data center opened world , can't allowed east-west intrusion . moment intruder go inside data center , go sideways , east-west , data center imagine damage could . security incredible . every single node become super firewall . firewall technology today , intrusion detection technology today based ai . 've got put ai processing right network , number one -- number two . network shaping , network traï¬ƒc shaping , 's ai problem , 's optimization problem done simple set equation 's heuristic problem , 's dynamic problem . 's one computer science problem go , well , depends ; 's solution ? well , depends . , well , depends requires intelligence want put intelligence right network . computer science described past network computing , two example in-network computing . okay . , big deal . 're super excited one reason -- one reason . go back early day talked acquisition mellanox , talked normal computing , talked network become fabric lot computational , lot ai , first step . several thing ca n't . many thing arm , many thing arm , arm , build cpu . however , never another cpu built like arm ever 's computer science problem anymore . started computer science problem 30 year ago , energy-eï¬ƒcient architecture 's designed like . visionary reason energy eï¬ƒcient world hit wall end moore 's law , 've got runway . runway arm x86 , 's , mean 's bottom line . architecture energy eï¬ƒcient , therefore got runway . however , moore 's law end well . need bring accelerated computing arm . arm number one genius architecture , 's also genius business model reason wanted arm popular cpu world , want used kind thing everything everything , car phone television name . required business model allow license ip soft form , soft ï¬‚exible form fit people 's chip , many computer future full -- whole data center one chip , whole computer one chip , phone one chip , tv one chip . thing two chip . one chip . second thing business model created third thing , ultimately valuable thing today , vast ecosystem . execution machine arm know build soft ip , ip smartphones , embedded system , microcontrollers data center increasingly pc , number cpu core , engine behind creates soft ip , productizing delivering customer , helping integrated chip , 's phenomenal , 's phenomenal . , result , created ecosystem thousand chip company , ship 22 billion operator q - harlan sur - kimberly powellchips last year , nvidia shipped 0.1 billion . difference nvidia arm 22 billion . put perspective , reach ecosystem , 's value u . ca n't building another cpu , n't matter another cpu , n't care . n't think ecosystem ever rich one , 's 30 year build took enormous character enormous vision built . team built phenomenal . love cambridge , work cambridge , 's great computer science team , love work 've done , ultimately asset 're buying , combination ecosystem 've built simply wo n't get replicated . next question come harlan sur jpmorgan . line open . good morning , thank taking question . one powerful dynamic team creating leveraging entire portfolio target vertical market question kimberly vertical market focus like healthcare , drug discovery opportunity talked primarily focused high performance computing platform like egx moving across portfolio team leveraging edge inferencing portfolio like egx jetson product family , within healthcare franchise involved team hoping define next generation hardware system platform ? yeah . thanks , harlan , thanks question . drug discovery , 're right , dgx system 's full stack architecture , literally cross every computer science domain . yes , 's heavy upcoming artificial intelligence , course take advantage accelerated computing . 's also going instrumental data science machine learning data analytics move gigantic data set genomic data set even compound screening , generate huge output analysis need analytics really call necessary information . literally leverage every corner nvidia 's extreme powerful world-class computing architecture , whether 'd accelerated computing , data science , machine learning , deep learning natural language processing . area justin touched brieï¬‚y , decade working edge device frankly , revolutionizing medical instrument care u see inside body extract dna build 3 billion letter make u . instrument one edge platform future like phone car , want software defined . -- sensor technology created edge medical instrument incredibly powerful continue get amazing insight new information sensor technology applying artificial intelligence , ca n't remind old way deploying instrument would sell couple million dollar q - harlan sur operator q - raji gillct scanner would refresh every 10 , sometimes 15 year . ca n't carry way anymore . edge computing absolutely going vital going software defined future medical instrument . imagine new instrument -- leverage everything 've built jetson platform , also leverage we're building egx platform able remotely manage provision securely operate edge node need updated new ai application time extremely vital . example justin gave northwestern hospital , actually plenty sensor already exist healthcare environment , microphone , camera coupled artificial intelligence conversational ai , brand new service enter healthcare hospital environment , like would expect , like home , talk smart speaker , 're unlocking enabling environment health care system today using deepstream -- 's used smart city , jarvis , used lot conversational ai platform . leverage technology create domain specific application framework -- literally overnight allow application developer develop new application deployed leverage fleet command system egx deploy ten thousand installation environment 're going wireless [ ph ] edge . whether 's new instrument , augmenting existing instrument compute , coupling amazing sensor -- live health care environment ai able manage securely deploy application egx . future incredibly bright , see smart hospital application popping literally woodwork course imagine respond great demand dynamic putting healthcare system . cool . thanks , kimberly . next question come raji gill needham & company . line open . yes , thank , thanks excellent presentation . thinking new cloud class data center product , 's dpu , think kind pricing dynamic term revenue opportunity relative class chip 're selling . trying understand kind integrated go-to-market share ? - jensen huang q - raji gill - jensen huang operator q - ambrish srivastava - jensen huang yeah , two pillar could -- could look towards . one course baseline , smart nic go , 's hundred dollar . modest cpu oï¬ „ oad provide application performance server get boost . 're effectively going add dpu server , expectation time 'll double performance server , kind put value . somewhat two spacing [ ph ] work go . thank . yeah . thanks lot . next question come ambrish srivastava bmo . line open . hi . thank much . jensen , question inferencing . one gaming well , maybe colette could answer . inferencing , shared pretty revealing piece data term crossing cpu . gave projection 90 % market share . intel incumbent , , could please help u understand kind term much training could translate nvidia inferencing give confidence get 90 % share ? also , assuming competition market ? know jensen , know competition lately ? gaming side , colette , know past event , guy kind giving u component cagr term unit asp . wondering could help u well ? also said gaming -- sorry , 'm asking multipart question , said fastest ramp ever . could give little bit detail helpful . thank . yeah . yeah , -- n't actually share , compute -- aggregate compute cloud . example , pc right , pc , decent gpu [ ph ] , aggregate -- computational throughput pc 99 % gpu . fact , aggregate dpu versus gpu compute inside data center , inside supercomputer high performance computer 99 % gpu reason 's job . primary job data acceleration , primary job compute . - colette kressand 's say cpu useful , 's job . job manage application , manage operating system , manage -- orchestrate processing application , figuring get priority . thing really important , moving thing around , managing thing . really important . single threaded performance , single threaded application code operating process , single threaded part code becomes critical path , otherwise known amdahl 's law . , 's . vast majority cloud going forward accelerated . fact , program conclusion point , 's corollary -- moore 's law ended , therefore look another approach accelerate application , moore 's law ended , yet hand , emergence new type application called ai require much computation exactly time cpu performance going double every couple year , ca n't wait . , world look code re-factor take advantage acceleration . happened perfectly good time , reason -- cloud compute . cloud computing , world re- factor application disaggregate . disaggregated -- whenever disaggregate containerized certain module , certain micro service , might well re-tolerate must -- 're infusing ai anyway . think conï¬‚uence end moore 's law beginning ai emergence new type data center data center scale computing , call , working favor . colette ? yeah , let see answer question regarding split gaming asp growth unit growth . important overall growth , five-year period time contributed . one key thing note term inï¬‚uencing unit asp growth onset laptop , notebook , gaming . high-end gaming notebook market really grown quite well great asp force well . continue uplift overall asp new gamers coming board tend take rtx , tend take higher performing overall gpu start . still provide slew different overall price point attract every single gamer , see asp probably period reaching double-digits growth , still great opportunity go forward . also announced right overall ampere architecture gaming growing quite well . launch probably best launch history . opportunity little bit different overall terrain . terrain opportunity u address ray tracing first time , really start market essentially chicken egg type market . hardware availability began beginning overall software . q - ambrish srivastava operator - jensen huang operatorwe also take little bit pause term launch really address whole scope gpus longer period time . 're excited term performance improvement overall ampere , well great price point . far , launch ramp growing quite well , really pleased term thing going . okay . thank detail . thank . bring u end today 's question-and-answer session . turn call back jensen closing remark . amazing time computer industry world . age ai begun , nvidia full throttle capability world . breakthrough ai bring automation world 's largest industry . new type software requires new type computer write software , validate software , deploy software . ai understandably complex chip , system , software , algorithm application . ai requires reinventing every layer computing stack . nvidia full throttle building full stack computing domain computing environment . cloud , pc , enterprise , autonomous machine edge . nvidia full throttle building computing company age ai . thanks joining u gtc . thank everyone . bring u conclusion today 's conference call . may disconnect .