thank cj , pleasure . excellent . audience , chat box ask question i'll best integrate question fireside chat . , paresh , busy , new product cycle , figured would start , new a100 offering . ampere appears transformative architecture technology . walk u mean customer term ability harness power ai ? yeah . cj , look , two mega trend ai . first trend exponential growing complexity ai model . launch a100 , spoke , talked since launch volta , model complexity grown 3,000 time train largest model . fact , trend continues . month announced ampere , open ai introduced model called gpt3 . 's 175 billion parameter model , 's 10 time compute intensity train model . , continues , trajectory continues , 30 time compute intensity train largest model , since launched volta . requires large scale computer , c.j . muse paresh kharyabecause otherwise could take year train massive model . that's first trend . second trend , ai model accurate , pervasive ai-powered application everywhere , conversational ai recommender system , service million user . service million user , interaction user requires tiny amount acceleration , requires many small-scale accelerated computer . , two seemingly divergent need , a100 first time , provided single solution divergent need time . first , provides massive performance boost , 20 time higher performance compared volta . second , provides 50 time higher scalability . , single server used one big gpu , working large scale training problem interconnected network even larger scale training problem . secondly , capability called multi-instance gpu , server partitioned 50 different smaller scale gpus , running different inference application . , first time , a100 unifies data center acceleration training inference 's customer loving a100 architecture 've really seen rapid uptake . okay . 's brings next question , , share u reception far guess 'd love hear whether 's scale-up , scale-out driver think adoption hyperscale versus enterprise versus super-compute , excites segment perhaps -- something else ? sure . yeah . tremendous uptake . a100 came cloud faster nvidia gpu history . 's already available google cloud , microsoft azure , 's coming soon every hyperscale cloud provider . 50 different a100 several model , announced leading server manufacturer within week launch . help vertical industry ramp-up next coming quarter , value proposition really strong . , hyperscale multi- instance gpu , a100 enable 's great economics , discussed , 50 time higher scalability , well unified training inference platform . provision instance different capability infrastructure , 's cloud provider hyperscalers excited bring a100 cloud . enterprise , enables unification acceleration data center , optimize single architecture , optimizing utility utilization , investment accelerate data center , accelerate full range application , whether 's data analytics , artificial intelligence , ai inﬂuencing , virtual graphic , accelerated infrastructure investment . c.j . muse paresh kharya c.j . musefinally , supercomputing , mentioned introduced next-generation nvlink , combined mellanox infiniband technology , along software stack , call magnum io , scale application massively , something supercomputing really enjoys , multi-gpu , multi-node really large scale application , backed single architecture 've come rely upon nvidia , 've several design win supercomputing reason . u , example , supercomputer called perlmutter nersc europe juelich supercomputing , max planck institute . several design win a100 . congratulation . hoping pivot system level approach , think something perhaps still under-appreciated nvidia , 'm thinking , le every day pass . obviously acceleration computing start gpu , continues system design , system software algorithm optimized application . speak importance platform approach nvidia ? yeah , platform approach critical . made great gpus , tensor core third generation unrivaled term performance . nvlink provides really massive speed-up multi-gpu environment , 's 2 million nvidia developer rapidly growing . 's testament platform approach . , provide fully end-to-end platform developer , cuda , single programing model sits top gpus cuda- x , layer domain-specific library provide map 's needed different domain application , whether 's ai training , inferencing , running larger scale job , 's layer cuda-x , million line code evolved 15 year , 's really important ai framework sit top , supreme work like tensorflow pytorch . reason 're able perform well gpus layer cuda-x , contains acceleration library make framework work well . , stopping . also created application framework really important enterprise deploy create application , whether 's conversational ai application framework called jarvis recommendation application framework called merlin . software stack delivered ngc , hub gpu-optimized software . net effect , full platform approach , able sustain virtuous cycle adoption , developer , find easy develop platform , implies creating application deployed endpoint , deployed endpoint , attracts even developer platform . full platform approach , able sustain virtuous cycle adoption 's vital industry . paresh kharya c.j . muse paresh kharyai guess playing devil 's advocate , talking folk industry clearly , think one two year ago , notion , support one two ai framework , 's enough cuda-x n't necessary . , speak , disagree notion ? yeah . , reason framework like tensorflow pytorch work well platform , cuda cuda-x . framework sit top cuda cuda-x , automatically benefit capability built hardware . example , launched third-generation tensor core gpus ampere architecture , introduced new precision called tf32 . zero code change required framework , framework use library like cudnn , automatically benefit tf32 , new precision introduced come developer . cuda cuda-x really important accelerating framework . reason , frankly , customer confidently invest platform , 've seen commitment library single cuda programing stack , know every generation gpu , they'll automatically benefit architecture , sometimes without changing single line code , 's really benefit get , platform layer industry framework sitting top thing like cuda cuda-x . great helpful explanation . 'm curious think platform approach , seeing difference term required hyperscalers versus enterprise customer , know 're early enterprise ramp a100 , would curious 're seeing sort difference ? yeah . platform approach , great advantage , able meet customer . meaning , one hand create end-to-end solution like dgx enterprise . time , open platform agx gut behind dgx hyperscalers deploy create infrastructure . well oem server make partner work u layer . , 's hardware front . look software stack , hyperscalers , approach deeply integrate software stack , framework promoting . example , let 's take tensorrt , 's library optimizing trained model inference , 's deeply integrated tensorflow . similarly , 's deeply integrated microsoft onnx runtime . , hyperscalers , approach deeply integrate software stack . side , hyperscalers also contribute software stack . last week example , microsoft announced deepspeed . used extreme scale training model thousand gpus , model c.j . muse paresh kharya c.j . musereached trillion parameter , really important contribution microsoft , benefit , 's open source project , benefit every nvidia customer . , 's strategy hyperscalers . enterprise , hand , n't always in-house ai software capability . , approach continue provide higher level stack value prop , ngc critical part . ngc , provide pre-trained model , enterprise n't start scratch , training model . take pre-trained model state-of-the-art , whether 's conversational ai recommenders , apply proprietary data customize need , using 's called transfer learning . also provide application framework targeted enterprise , end-to- end workﬂows , like describing whether 's isaac robotics clara healthcare . , hyperscalers led adoption ai accelerated computing , enterprise adoption curve , many 's existing imperative , frankly . 've seen tremendous growth vertical industry , data center business derives close half revenue enterprise . 's helpful . 've made splash announcement , guess week back , potential arm acquisition , curious think full stack solution , end-to- end , asset fit go-to-market strategy excited potentially cpu data center portfolio ? yeah . pointed , first , creates premier computing company age ai , combining ai computing platform , arm vast cpu ecosystem . secondly , expands arm ip licensing portfolio nvidia technology several large end-markets like mobile pc thirdly , turbo charge arm server cpu roadmap pace , accelerate data center edge ai iot opportunity u together . finally , expands reach computing platform 2 million developer today 15 million developer arm . look endpoint perspective , sell 100 million chip per year , arm architecture based chip sell 22 billion per year . , ultimately , benefit virtuous cycle , endpoint application attract developer , developer result even application deployed endpoint , 's exciting possibility . 's great , appreciate . hoping pivot different business vertical . think something 's special nvidia 're clearly taking customized approach vertical . guess , speak business currently fastest adopt accelerated computing ai benefiting platform ? paresh kharya c.j . muse paresh kharya yeah . 're seeing adoption across retail , industrial , automotive , healthcare , video analytics , discussing , close half data center business driven vertical industry use case value prop tremendous . look retail , example , walmart deploys nvidia ai optimizing supply chain . problem immense , customer like walmart , 100,000 different product going thousand store , u look much stock minimize stock-outs optimize shelf space utilization . weekly basis , predicting demand half billion item-by-store combination combination impacted number factor . , massive sort data analytics ai training problem , using nvidia platform , 're able increase data analytics 100 time result faster delivery store . similarly , look manufacturing side , talked working bmw , bmw produce 10,000 car everyday , challenge , challenge customization . offer 40 different car model , 100 different option per car . , logistics problem humongous . 10 million part coming everyday hundred supplier , deploy factory produce 10,000 build-to-order car everyday . order keep production line humming operating smoothly , part need arrive time , sequence , , selected isaac robotics platform enhance automation automotive factory . , really amazing possibility enterprise able transform business model , operation ai . guess , sticking vertical really digging bit deeper data analytics data science side , past , 've spoken coordination cpu server , creating bottleneck exponential data growth . walk u dynamic supporting spark 3.0 solve ? yeah . , model trained , data need prepared , process 's called etl industry , stand extract , transform load , meaning , data coming various source preparing data , readying , used train model . computationally intensive process . fact , 70 % 80 % data scientist ' time today spent preparing data , even training , preparing data . , data analytics big computing challenge spark popular data analytics framework distributed computing , distributed data analytics . 16,000 enterprise 0.5 million data scientist use -- use spark data analytics , primarily running cpu server . c.j . muse paresh kharya c.j . muse paresh kharyanow spark 3.0 , bringing gpu acceleration vital part end-to- end ai development pipeline , speedup tremendous . databricks , example , offering gpu-accelerated spark platform , google offering data cloud dataproc , way benefit two-folds . first , faster performance . , data analytics much faster , 're able , customer , customer able iterate faster able train model faster . talked walmart example earlier , predicting -- let 's say 're predicting supply chain weekly basis , , able optimize model analyze faster , bring prediction day . optimize supply chain even . secondly , infrastructure , analyze data , well train , reduce infrastructure cost . infrastructure data analysis training . adobe example , talked , using spark 3.0 , able achieve seven time higher performance time 90 % saving cost . , spark 3.0 gpu acceleration really transformative . 's important part overall ai data analytics workﬂow able accelerate customer . think economic benefit nvidia , selling gpus e-tail process tam expansion ai workload ? 's really great question . way look , cj , data analytics done much faster , lot iteration . instead training job run weekly basis , example , daily basis , case even real time . impact really expansionary able training automation , expands overall opportunity , time , help customer optimize supply chain optimize business operation , able invest even infrastructure order combined data analytics training . guess last question spark 3.0 , fit nvidia's overarching goal making data center , computing unit ? yeah . data center fast becoming unit computing 's meant , developer today writing application limited confines single server . modern application deployed today , micro service based , run everywhere data center . fact , case , running hybrid cloud well . on-premise , cloud edge longer siloed . hybrid application taking c.j . muse paresh kharyaadvantage needed . , spark particular , great example distributing data analytics processing similarly kubernetes used manage cluster , data center scale . , data center need software defined , able accelerate spark , able accelerate important framework used distributed processing data center . , accelerates transition towards modern data center future , optimized full data center scale . 've also talked modern data center requires three pillar , cpu , gpu dpu . cpu running sequential task hosting operating system , gpu accelerating modern application , whether 's data analytics machine learning ai dpu processing data transit securing communication . helpful . enterprise side guess maybe focusing bit virtualization side , enterprise computer still vast majority computing market . talk 're make enterprise computing look like hyperscalers run cloud ? yeah . enterprise know , enterprise run 75 % application on- premise . however , impacted really profound way cloud computing finding inﬂection point , three sort major change , , driving modern -- enterprise infrastructure modernization . first , ai data driven application , enterprise moving experimental ai application future every enterprise application ai-infused constantly improved data driven insight . secondly , monolithic application giving way micro service based modern application . finally , talked notion on-premise , cloud edge longer siloed . hybrid application seeming -- seamlessly taking advantage , needed application . way addressing , server hardware side , dgx superpod , basically data center product , enterprise stand , world-class ai first data center matter week . secondly , mainstream edge computing , egx , helping enterprise processing closer source data . software side , -- platform side , working leading partner industry . one hand , 're working kubernetes ecosystem , make gpus first class citizen , working downstream partner like red hat open shift make gpu acceleration natively supported . also partner like vmware mainstream enterprise computing . last year , announced virtual compute server , enables vmware vsphere used management layer ai , data analytics workload gpu accelerated . finally , make software stack available , containerized stack c.j . muse paresh kharyaenterprise deployment , help transition modern infrastructure enterprise . , ( inaudible ) , five minute left . , figured 'd kind conclude maybe larger picture question . , think evolution ai interesting application seen last three six month ? yeah . , ai still nascent . see 's still nascent , continues advance exponentially , compute complexity 30,000 time last four year , example , 's opening new market , giant model trained wonderful use case possible . roadmap , driving roadmap open possibility developer , term interesting application , conversational ai example , highly accurate . 's really changing way interact application machine . one company closer investment community example kensho , 's & p global company . speech recognition product asr product called scribe , transcribes earnings call , customizes model financial jargon . , 10 thousand earning call , management presentation , acquisition call year transcribed really high accuracy help improve coverage call . similarly , interesting use case recommendation system , example , alibaba , largest e-commerce company , massive volume , mind-boggling . single ' day event example , $ 38 billion sale . 's two time black friday thanksgiving online shopping combined , able deploy advanced recommendation system powered nvidia gpus , six time complex model able deploy recommendation , improved click-through rate 10 % . , phenomenal value . healthcare side , example , looking cold ﬂu season upon u , still pandemic , work nih create ai take chest ct scan help identify classify cause pneumonia . pneumonia caused bacterial infection , fungal , viral , want able detect whether pneumonia caused covid-19 cause , working nih , able create model detects 90 % accuracy , -- pneumonia due covid-19 made model available ngc anyone deploy . use case immense still nascent phase , drive roadmap , open new possibility developer 's possible . we're c.j . muse paresh kharya c.j . muse paresh kharya c.j . musevery excited . get 30 , 50 second left last question want go , think under-appreciated either ai nvidia ? sure . would say three thing . first , pace adoption scale gpu usage everyday application , really under-appreciated . one quick example , microsoft recently talked bert , model came year half ago , power search bing , search engine , 's made possible gpus , thousand gpus used serve search result . research adoption , pace mind-boggling . second , ai used consumer internet hyperscale space , enterprise adopting ai rapidly . talked several example . half revenue come enterprise segment . finally , importance full stack under-appreciated . start great chip , need full software platform , make work happen nvidia , continue innovate architecture , software platform enables developer access hardware capability seamlessly , go one architecture , ngc simplifies development deployment customer base . well , paresh fantastic , unfortunately 've run time . thank . really appreciate wish best great health still crazy pandemic time . thank , cj . thank .