get started . first , n't know , name chris mcnally . cover global automotive supplier london . really , behalf entire global auto team , c.j . semi team . really evercore , want say thank welcome think going special event . quickly , evolution last couple year sort small autonomous bus tour 've , c.j . , silicon valley . arndt helped organize bunch southern germany countless trip israel . 'll keep really brief . amazing lineup next two day almost 20 company really leader autonomous ai soon shared mobility space . say , leader really soon leader , broad spectrum new startup . , hope great conference . kick c.j . great . thanks , chris . n't know , c.j . muse , covering semiconductor space well semi equipment . perspective , private public company , servicing , primarily ai autonomous . we've got nvidia , intel , xilinx public side handful emerging asic company , , think , quite interesting . ian buckto kick start , nvidia . honored ian buck , vice president accelerated computing , kick thing . think 'll present roughly 10 , 15 minute . 'll little fireside chat . , 'll open q & audience . guess , , 'll -- 'll bring ian stage . thank . well thank giving opportunity talk . name ian buck . 'm general manager vice president accelerated computing nvidia . background actually -- engineer , started nvidia . 've 15 year . hired start programming project called cuda built cuda engineering . five year ago , jensen invited actually run data center business . life -- day job working hpc ai , whether 'd supercomputing lab like oak ridge national lab others . course , ai player , google , amazon , facebooks , alibabas , et cetera . 've done -- slide serve context nvidia maybe kick discussion q & taking question . usual , safe harbor conversation ( inaudible ) . right . ( inaudible ) advance slide thing working . bring back , please , f5 . ( inaudible ) closed presentation . 's middle desktop . maybe semiconductor guy could invest logitech improve product . would appreciate . hate thing . go . next slide , please . nvidia ai computing company . really , acceleration . accelerator , mean companion cpu . first market accelerated , course , known , obviously computer game graphic . started way founding mission company . really first workload accelerated . think computer graphic . computer graphic video game typically every pixel screen video game batman , might 1,000 , 10,000 , even 100,000 line program 's determining color 1 pixel batman 's face . 's taking consideration different light source room , surface property skin , environmental effect , lighting effect lens effect graphic artist , game developer basically writes . write program c -- compile run gpu . gpus turn around run program every pixel screen . 's 1 million pixel , 10,000 line program 60th second , throw result away . camera moved . nature 2 decade point computer graphic . -- basically , evolution still graphic , become massively parallel computing problem , running long program massive set data , designing incredible speed throughput , simulating life , . majority -- vast majority processor dedicated specialized core , call tensor core , accelerating kind -- kind computation . 's massively parallel problem , 've got 1,000,000,000 pixel screen , put lot lot core . -- latest volta gpus , 5,000 core . 're different cpu . cpu core tend optimized running single program really fast , one thread execution run outlook web browser operating system . gpu lab , 's accelerated computing lab . typically want run thousand ten thousand , really hundred thousand thread running parallel throw many core problem . first market computer graphic gaming , evolved programmable stimulating light . expanded actually accelerated -- accelerating simulation high-performance computing . world's fastest supercomputer u.s. , world 's fastest supercomputer europe . built , world 's fastest supercomputer japan accelerated nvidia gpus . 're kind simulation . example would air-conditioning room . want simulate air ﬂow room . we'll divide room tiny little group belt 'll simulate group belt parallel . use group belt -- time various kind equation simulate air ﬂow room identify vent , quality . thing air ﬂow -- air ring combustion engine . similar math kind problem . course , today , ai -- found -- actually n't find ai , ai found u 's ( third ) slide 'll talking next . next slide , please . let 's go back , please . first market really discovered nvidia general purpose specialized computing graphic actually high- performance computing community . people building supercomputer look plan 5 , 10 year . first notice trend end moore 's law . basically , moore 's law transistor law , giving transistor process technology improves . transistor put toward product . also turned marketing law . transistor meant performance . decade , 's industry worked . 've got transistor . company like intel fantastic , turning transistor faster technology , adding thing like predictive execution , effective execution , branch predictor . enormous cache keep memory closer processor . result , industry could rely getting 2x performance roughly two year . , course , started tail . around 2010 , even transistor , started running idea . passed . cpu today starting add core try deliver performance . basically , they're trying go parallel . gpu end , 're different . started actually parallel . started different kind use case . never tried run outlook -- run outlook system , solve problem massively parallel . result , architecture 's designed throughput , necessarily latency . result , able keep continuing taking transistor available u directly applying core . also tend holistic way optimize . n't release instruction drive processor . ca n't download . ca n't write assembly , unlike ( inaudible ) . actually expose high-level software interface , call cuda . everything built top optimized . give u much wider palette innovate improve performance . actually change instruction set every major architecture generation . actually optimize compile whole system software , programming language . , course , go higher software like linear outlook , mass library . way ai framework like tensorflow pytorch others . 's basically giving u 10x 10 year kind speedup often see talked . next slide . 've transitioned era ai really feel like many -- technology transition 've experienced last 30 , 40-plus year . first , course , pc revolution advent wintel , mobile revolution advent android platform , cloud revolution like amazon container . today ai , 's yet another new kind computing technology 's going pervasive . think 's important talk ai computing technology . 's necessarily market . see ai showing every one market touch . 's cloud service like okay google . 're seeing affecting inﬂuencing high-performance simulation community 're . people using ai better weather simulation , better -- processing data data set . anywhere enormous amount data make prediction improve service , process , scientific discovery 's ai deployed . capability really data-driven computing technology 's effectively replacing traditional software , traditional software write describe perhaps stop sign look like . 'll describe stop sign look like see hexagon , 's red , 's got letter s-t-o-p. 'll write code . ai , 'll basically give lot data , lot picture stop sign learn see -- -- -- recognize stop sign image , basically write software . story play every one industry long data drive . next slide . history -- well , could go long time history ai explain -- . think , ai found gpus early advent cuda . we've decided make available gpus , data center one -- even consumer-level gpus . anyone go fry 's best buy gamer also download cuda tool kit writing program see could benefit computing . back 2012 , guy named alex krizhevsky graduate student canada . working thing called neural network , deep neural network . still ai winter . -- happened geforce gtx graphic card also gamer dorm room pc realized math convolutional neural network studying geoffrey hinton kind math talking hpc time . imported ai code gpu , called cuda-convnet . beginning alexnet . alex krizhevsky , 's named . went -- submitted network computer vision contest called imagenet , predominant competition computer vision researcher . given million image predict 's inside image . computer vision researcher competing . getting 70 % accurate . alex came nobody computer vision industry went -- 83 % . stuck 72 % , 73 % . within overnight , became # 1 researcher computer vision without ever studying participating computer vision contest . catalyst moment . geoff -- alex , geoff henson , work , course , google . alex krizhevsky 're seeing facebook whole industry going . basically , ai got gpus alex trained , could take training took literally entire semester train neural network brought month . -- making -- 's terrible way get ph . .. could train month , today , train alexnet matter , think , 15 minute something like . accelerate whole industry become practical . 're seeing ai hit every one nvidia 's market certainly anywhere computing ai used tool improve prediction , improve speech speech recognition , 're seeing speech synthesis . one reason okay google alexa sound good 're using ai generate speech , figure inﬂections right -- say certain tense word . 're seeing ad recommender system . given web page , -- likely click link , , course , diﬃcult advertising . we're seeing video inﬂection space ( city ) . typically run 40 hd stream single gpu , running neural network every frame look suspicious behavior , catalog vehicle , lot content filtering , detecting hate speech . thing modern-use ai today . , 's sort creative super resolution , magical enhanced button , take fuzzy image make crisp neural network trained image detect incomplete data make high resolution high quality data . truly amazing stuff . next slide , please . fast forward 2012 today . nvidia , core , technology company . try make product technology available every channel . today 's modern gpus -- volta gpu . kind look -- n't like son 's daughter 's gaming card anymore . 's going data center google amazon , supercomputer around world , basically build fastest , largest possible thing smc allow prioritized module run fast thirst computing ai extreme . put perspective , typically need around 10 million image train neural network 90-plus accurate prediction rate , -- path modern neural network , like resnet-50 , gigaﬂop . 's enormous amount computing necessary train along data . make available gpus like volta oems . also make bespoked system highlight ai system lead market . enable oem partner build server technology well . help -- make technology available every cloud . ramp volta dgx amazon , microsoft , google alibaba . innovating software side n't stop hardware . work numerical library level , programming level . team working tensorflow team , pytorch team , caffe2 , ( palo palo ) china framework help training software , course , important software well running neural network production . , 'll even make available consumer level , developer level , next alex guy . fastest possible consumer-grade pc gpu ai research develop next workﬂow make available . next slide , please . let go -- 's sort market . talk market later . keep going . n't want drag long . next slide , please . couple fun one . ohio state neural network -- health care . health care , think , literally $ 1 trillion market . everyone need health care . they're using ai ai-assisted radiology . huge amount time energy money wasted throwaway scan , mri n't come clean mri may missed early detection cancer . guy actually training neural network . enormous amount medical imaging data available u world . everything archived electronic medical record . take data train neural network tell radiologist , `` hi . look , potential spot '' like ( inaudible ) therapy . 's replace doctor . think 's -- one want rely entirely computer diagnosis . aid doctor identifying spot really early . transportation . kansa city , wo n't think kansa city bastion innovation ai . actually deploying neural network detect pothole form . take traﬃc light data , weather data , -- street data pump neural network . predict within -- think , 're getting 90 % accurate pothole going form intersection . actually send truck ahead time target crack road pothole form actually think eliminate pothole kansa city using ai . wish san jose live . last one preventative maintenance . ge good work actually taking data 're getting gas turbine -- predicting , ahead time , machine going start fail preventative maintenance early rather later take off-line , potentially interrupt service . 'll cost hell lot . 're roughly saving $ 50 million year per plant preventative maintenance , ai- driven . ton story go . 'll spare detail . see ai general purpose computing tool taking data making good prediction applying sort opportunity . ai we've developed need data scientist researcher ingest data , understand build service . need lot compute . think 's last slide . oh . know guy want talk car later . thought 'd frame little bit . self-driving vehicle example vertical industry . nvidia n't invest many vertical industry . one investing . actually building self-driving car platform . believe bulk computing , leverage cloud , 's much eﬃcient way , running ai . hockey puck kitchen , connect cloud ai , get horsepower cloud keep hockey puck $ 20 device . 's -- think hockey puck 's always connected cloud . ca n't rely self-driving . bring ai supercomputer car . typically run around 12 different neural network self-driving car . one actually drive around . get car hand touching close wheel , leave building , come around san tomas , merge onto 101 , drive around , fine . , basically take data center gpus . highest end , level 5 system , actually 2 gpus redundancy , 2 tegra socs running neural network parallel task prediction , lane detection , collision avoidance . actually multiple camera looking driver looking driver distracted . also , 's different use case . area 's incredibly complicated problem , lot challenge . getting production-worthy level 5 car challenging . lot simulation well . 're taking gpus use data center , graphic capability simulating thing . might able drive 1 million mile road test drive real car . billion mile simulation . big part q - christopher james muse - ian buck q - christopher james musedata center business actually trying show automotive company , buying rack data center gpus server simulation self-driving experience teach ai simulation ever hit road . think 's last slide . want thank 're happy start conversation take question . question answer 've got whole laundry list question . think 'll 20 minute time . start high level , dave patterson google talked renaissance computer architecture end gpu , tpu positing hypothesis 're inﬂect ai . 've built business that's almost $ 3 billion run rate , 's view kind ai cycle ? yes . certainly , agree dave sense accelerating . ai tool becoming new way write software , new way computation , obviously , market affecting huge health care , car , economy . kind architecture need order accelerate ai different traditionally cpu . fact , latest volta gpu redesigned architectural ( inaudible ) . call tensor core , designed -- specifically designed tensor operation , , -- 's -- 's basic building block framework like tensorflow , 's called tensor . pytorch challenging . part 's happening ai diversification . 's one neural network rule . started convolutional neural network image processing . rnns , lstms , gans . there's tqms . 's sort -- 's parsed lstms . one neural network different structure , sort mathematical operation need . -- 's 's invented last two year . mean , people swarm field , 's going explode . track 200 different neural network performance tuning alone expanding . think , reason mentioned programming really important . place platform people program develop neural network evolve tend usurp replace real-time critically important . -- ai field evolving , we're cranking new architecture , well , almost annually . fast industry moving people want . ( inaudible ) . innovate many different level go top bottom , time , forefront 's evolving quickly . - ian buck q - christopher james muse - ian bucki think one major area focus competitive positioning . kind , guess , start cuda talk ﬂexibility , programmability , nature . think give competitive advantage versus sort emerging asics evolving well cpu ? yes . started cuda , 2004 launched '06 , wanted give developer something program . gpu around . term used . basically ph . d. computer graphic order use gpu . invented new programming model , based c later fortran allow anyone c c++ background program gpu easily . function around gpu called function , instead running , like would cpu , say many time run parallel . really simple . anyone understood c c++ , course , python java fortran could understand programming gpu . -- second thing made available everywhere . every gpu we've shipped 2006 support cuda , massively pervasive available parallel computing architecture processor available world get country . engaging developer base allowing thing like alex krizhevsky , guy invented alexnet , keep u aloft find opportunity . diﬃcult decision make time . clearly paid u long term . ai evolving develop program move framework forward ai framework . also inferencing software , production software , take advantage technology , 's paramount . people n't want learn new programming language . want use language already know innovate top . world migrates 3 4 ai framework . 'm sure case . went world , would obviate need program cuda ? guess , share view think ai framework evolve time ? shrink migrate handful ? think 'll proliferate ? -- proliferate . beginning , think , bunch ai framework , large , trying thing . saw . , course , company bought merged 's consolidation overlapped capability . 're starting see little bit diversification framework starting happen . ( colby ) may heard colby . 's # 1 framework use speech 's specializing speech processing speech everything . 's -- health care , 's one called candle . 're specializing genomics understanding cancer . whole purpose ai used cancer , understanding agct correlate agct dna sequence doctor 's electronic medical record database . 's specialized kind processing , think , need different kind framework generic tensorflow . always tensorflow always pytorch 2 company keep thing aﬂoat . we're seeing ai space workﬂows eventually software q - christopher james muse - ian buckitself . think , vast majority ai today probably done tensorflow pytorch legacy caffe , 're starting see emergence rest ai software ecosystem developing new software . 's , , productive platform , access technology , access gpus , whether cloud desk data center fast develop innovate suitable format . neural network always seem take six day train . matter smart fast keep measuring gpus , someone coming next neural network 's going get smarter bigger cloud computing . seems 6-day -- n't know 's week thing , must . anyway , iteration , performance matter plus productivity matter , program really matter 're going start seeing diversification framework compound . see competitive landscape evolving within training ? look five year , , rising tide ? b , think including fpga asic along gpus world ? yes . think 's bifurcation happening . training world inferencing world . training building , designing developing neural network inferencing production deployment ai . training space , want highest performing system , resource available data scientist hire one today , 're probably spending $ 0.5 million $ 1 million salary recruiting person . job keep person productive neural network getting bigger . scale , 's getting bigger . want highest performance stuff . inferencing , typically -- want start -- believe 're seeing ai introduced hyperscale business processing every data element come cloud , want run ai inferred . 's lot -- 's diﬃcult understand . 's lot benchmarking going thing . gpus offer fastest ai training , scale , node single chip . also offer lowest latency highest throughput inferencing well . resnet-50 , infer 1.1 millisecond full resnet-50 model batch one . also upwards 6,000 7,000 inference per second throughput rate large ( dash ) scenario . training side , 's becoming gang gpus together build super gpus . 're seeing technology called nvswitch gang multiple 16 gpus together work one . 've -- 've invested high-speed interconnects called nv link link gpus together high-speed switch called nvswitch gang together really operate one single tensorflow training , operating upwards 15,000 image per second training group , obviously target . rest world competition going fall ? think , guess , 's always room specialization . one area 're investing iot edge , doorbell , thermostat , shoe lace , whatever . scenario , kind believe either going rely cloud truly intelligent ai service specialize specific use case . n't need -- mean , build ai chip recognize word alexa . take -- get cost whole hockey puck $ 20 . 's worth r & effort time specialization q - christopher james muse - ian buck q - christopher james muse q - unidentified participant - ian buckreduce cost ai chip , alexa ai chip next nothing , especially 're going sell million million . think 's area think people sort thing . 've actually -- 's also particularly engineering hard . 've open-sourced technology help market . way , sooner get ai , sooner get ai cloud , training want succeed . 've open-sourced technology . one called dla , neural network need matrix multiplier . 've open-sourced hardware made available community go play ai make product . know ca n't share much future technology road map . guess , one core focus company single architecture . take silicon come new offering roughly every year , point start maybe morphing ai-specific piece silicon and/or perhaps custom specific workload customer ? mean , think , ai starting affect market . 're already seeing shortened graphic . people cool stuff ai-driven rendering ray tracing . actually demo-ed actually fill hole array tracing engine -- using ai predict missing pixel 's color based trained real-life image . think -- -- 'll continue build one gpu best computer graphic , best simulation best ai , many thing -- long term road map thing getting intertwined . graphic becoming simulating light . ai becoming general computing tool could used computer graphic rendering , looking cool . -- benefit take entire horsepower -- money generated market funnel entire investment back one architecture . 's great thing . course , benefit leader industry help guide industry make transition happen faster keeping aligned obviously know build take next step . question audience ? ( inaudible ) guy comment ( inaudible ) well data ﬂow interesting . first getting ph . d. , first version parallel programming 're thinking data ﬂow architecture keep stuff check . think n't -- one challenge data ﬂow programming model , constrained , let 's say , -- pipeline , pipeline , pipeline , restricts q - unidentified participant - ian buckprogram model fairly constrained . 's always question can't fuse layer together . well end -- problem , think , neural network getting bigger faster . roughly -- think , 100,000x five year term networking size go way translation model . translation model understand entire english language used web entire mandarin used web try translate . model massively huge . trying express data ﬂow architecture actually really hard . n't seen -- seen program model make -- pivot easy . instead , people want express computation level ( inaudible ) like architecture let memory system solve problem term providing large amount l2 , l3 cache enough hpm memory worry . today , training neural network compute-bound hpm . 've got headroom . overall , going take best possible memory interconnect technology help u scale . ( inaudible ) yes , great question . question people programming python , right . 're expressing neural network python letting framework job n't mean n't need compiler anymore ? 's actually exact opposite 's 's happening . happens data scientist , right . 're computer scientist . n't know cache . would fail job like software nvidia . understand neural network , understand workﬂow , understand -- 're designing neural network . n't really bother performance stuff . what's happening everyone designing neural network compiler inside framework . basically -- express problem understand . see layer , see size , see shape . 's batching , 's ruler , 's batch form , 's activation function . hard part take compile neural network fit optimally machine . actually blocking , register blocking pivot calculation , look like , look like . 's back vector versus simd kind transformation happening . happening domain level like way . huge software team basically work compiler , take neural network described recompile 've turned output around optimally execute architecture . neural network getting diverse , need actually think compiler problem , pattern matching one . 's actually headache silicon also headache compiler engineer build -- something called tensorrt make tensorrt actually ( outlier ) inferencing . recompile gpu . corner turn reblock computation run eﬃciently keep memory , also reduce precision . instead expressing neural network 32-bit ﬂoating point , 'll automatically compile 16-bit ﬂoating point even 8-bit measure operation , operate 4x faster 4x smaller . -- compiler guy thrilled . thing play . q - christopher james muse - ian buck q - christopher james museare beginning input super high-level , give sort room play . get thing called precision reduction . often sit data scientist -- call data scientist try figure actually going work . 's headache compiler -- 're getting harder hire . unfortunately , think , 've run time , ian , thank much . thank . appreciate .