alright . think 're ready get going . 'm joe moore morgan stanley . happy u today , colette kress , cfo nvidia . think colette wanted make opening hedge comment go straight . absolutely . okay , statement read . reminder , presentation contains forward-looking statement , investor advised read report filed sec information related risk uncertainty facing business . question answer great . thank . well , feel like go couple hour , given much stuff going guy . maybe could start , 've talking forum various form large language model four year . feel like 2023 important year becoming mainstream , becoming every hyperscaler kind talking capability table stake going forward . wonder could talk ? made comment earnings call last 60 day enthusiasm built , see transforming demand product road . could talk conversation like right ? q - joseph moore - colette m. kressyeah . really good way start , talking ended earnings release great statement 've made . let kind step- back bit talk entered calendar year , expect , moving probably important understand , believe ai important part computing , important part accelerated computing really 're . 've entered stage actually believe ai inﬂection point . stemming inﬂection point , focus term large language model , recommend data engine natural language processing , 've done , incurred point time generative ai , particularly chatgpt , folk understand simple case , benefit . benefit use case consumer enterprise thinking develop ai within universe well , monetization capability sheer eﬃciency improvement . 're important stage , 're important stage ai , work done year bringing high end platform . thinking something h100 a100 computing platform data center whole , term improving eﬃciencies use acceleration . key use case would ai we're seeing everyday . interest 've seen holiday , we're talking large enterprise . ceo large enterprise , 've originally focused , need concentrate ai , leadership team . , ceo , understand possible , whether could something easy chatbot , whether simulation factory , whether could even use case continue develop overtime . start-ups interested well , large language model built 'll likely see lot large language model start inﬂuence case . thing u.s. , thing worldwide well . whether foundational model whether specific industry . therefore fuel csps interest . csps service agreement many company , need set-up -- compute start work , want start large language model generative ai . thing continue fuel demand see . think demand creation , 's pretty clear one-hand , -- watched cnbc day , ceo ceo come say important development u . need figure use better . manifest ? people -- people already developing type model ? looking much higher level complexity , looking scaling got , driving new people develop model ground-up ? generating interest model guy talking ? general , take excitement enthusiasm , quickly turn capex nvidia opportunity ... q - joseph moore - colette m. kressyeah . 's really good question term process start . interesting place referred exactly see , different type , focus full stock focused model , using ecosystem get enterprise get customer , seeing every stage ai . n't started . want focus ai , need help term building want design architecture . two , already working existing model , need optimization . term optimization level cuda , and/or working framework . even 're situation maybe exactly helping model . starting one model optimizing existing model eﬃciencies , help way , focused hardware , focused software . 're really -- type ai , help . end-of-the day , , many different opportunity procure . okay , procure directly csps , compare procure one partner well . opportunity absorb ai full platform many different way . great . maybe help u understand overlap kind declining budget environment hyperscalers ? 've alluded , saw last quarter everyone 's kind thinking scaling back budget . see protecting growing graphic within budget over-time ? given importance workload think , transition budget cut focus kind focus growth guy generating ? think economic time , 's time folk focus budget focus 're spending . however , 're still working eﬃciencies 're using money 're using capital . focus accelerated computing , matter look always going improvement eﬃciency use money . amount money save term moving accelerated , eﬃcient computing 're spending le cost . le cost versus existing cpu type infrastructure version legacy type computing . tend front center priority , even time working across enterprise eﬃcient , going focus eﬃciency . work therefore helping design different piece . although area within q4 , needed push thing , nothing lost , thing taking little bit time whatever different reason may term setting csps type data center . important part , world understood moore 's law u anymore , drive eﬃciency , overall need sustainability well . focusing accelerated computing going priority . accelerated computing , also demonstrating ai also another added bonus focusing . q - joseph moore - colette m. kress q - joseph moore - colette m. kress great . guess another part going capability hopper product 're ramping , obviously designed type model mind , talked 6x , transformer performance time launched . important hopper transition quickly see transitioning ampere ? yes . hopper architecture design phase many year . we've working internally , keep mind , work key generative ai partner . open ai , created chatgpt , u working u many year . continue working many different partner , help u design brought market . unusualness h100 , includes transformer engine -- transforming engine , really modeled towards large language model . yes , 've talking year year , 're seeing important use case . 'll continue path inﬂuence , hardware specific , software , transformer engine infrastructure standpoint included . 've also made huge inroad term term software . hardware alone probably 5x 6x improvement last generation , software even inferencing standpoint 're dealing , maybe close 30x improvement . hopper important piece , allows eﬃciency . believe ramp h100 focusing key workload really look use hopper . however , still also ship a100 also second-best , market still may great opportunity existing cluster may adding , 's already qualified , probably see h100 a100 year . one surprising element least around quarter h100 bigger a100 . leave rest year ? talked accelerating growth data center , sort thinking would get big value uptick h100 ramping year . seems like mix might little bit static . think term drive visibility rest year ? yeah . q4 represented probably first significant quarter h100 . started production tail-end q3 , q4 . 're still ramping perspective . 've discussed , important h100 a100 see moving forward . expect growth head q1 . quarter 're right sequential standpoint , expect strong growth also expect little bit year-over-year growth . focus accelerating growth rate rest year important piece h100 , also a100 product well . q - joseph moore - colette m. kress q - joseph moore - colette m. kress okay . great . guess , accelerating growth , define 're sort talking year-on-year growth quarter growing little bit faster , concern challenging july . -- talk , steep ramp year ? seeing today ? seems like maybe little bit visibility back-half year first-half ? yes , growth 're expecting data center , yes , year-over-year perspective , expect acceleration leave q1 . type growth , think , probably look size tam 's front u , opportunity many different offering availability . 's really hard say , fast growth rate going , know inﬂection point key focus area u . great . thank . inference side , mentioned inference performance hopper 30 time . 's really interesting microsoft google kind bickering lowest cost per query like esoteric question inference cost suddenly like one important cost . size big inference business today ? talk role inference think specifically two large language model road ? yeah . everyone focus eﬃciencies inside data center , 're looking thing costing . time focus cost , focus seeing term utilization across everything term data center . let 's kind step-back putting market , platform allows , training inferencing overall platform . ? , , time procurement time trying optimize training side inferencing , heard synergy across could probably benefit . time could spending working large language model , training , next week could mark , term inferencing side . improvement training side inferencing side term improving productivity . 's also important able capture power improperly utilized accelerated computing well . time may improve training better h100 , also improved overall inferencing well . improved whole system -- see people moving training inferencing platform . complexity seeing inferencing really stem large language model using accelerated computing inferencing well . software , utilization power , overall accelerated computing , 'll probably see training inferencing cost come time . q - joseph moore - colette m. kress q - joseph moore - colette m. kress q - joseph moore - colette m. kress 's hard classify , -- guess , 's part ? correct . ca n't determine point time much done training inferencing individual box . believe training important part today . 've made great inroad meaningful amount inferencing well great -- bigger opportunity see going forward . okay . great . thank . maybe could shift little bit new initiative talked call , dgx cloud . kind explain u scope nvidia 's ambition term kind cloud service capability offered within bigger cloud service provider ? yeah . dgx cloud , new offering 're going bring market really focused ai service , essentially browser . work enterprise , 're really trying help enterprise set-up computing , matter want . whether want csps cloud , whether want hybrid environment , whether want , on-premise . get djx cloud opportunity instance cloud nvidia help full stack software , full stack service , access model , access engineering help , pay csp instance . provide opportunity , choose csp want host , pay piece . also still opportunity enterprise work csps , also purchase full stack csps well . selling csps , work directly enterprise host help see csp instance equally . allows ﬂexibility speed quickly possible , working continue work working u term designing model designing infrastructure . term nvidia providing -- nvidia created model around large language model , thing like . 's scope ? would -- put competition cloud customer instance ? model -- creating model , whether 'd large language model anything footprint start work actually help full design ? today term helping optimize model eﬃciencies 'll continue . csps also may host model , still opportunity working many q - joseph moore - colette m. kress q - joseph moore - colette m. kress q - joseph moore - colette m. kressthose customer model well . 's difference , work year csps continued grow significantly optimizing infrastructure term standing . 're optimizing infrastructure acceleration model 're . great . thank . leave data center , question inspur come lot investor , added entity list chinese server company last week . talk much impact could nvidia ? yeah . inspur partner u , indicated partner , helping u stand computing end end customer . work forward probably working partner , stand-up compute within asia-pac region even part world . , important focus focusing law making sure follow export control closely . case , look term partner help u . 's busy year lawyer , guess , . ( inaudible ) okay . great . maybe could talk little bit software business model guy . revenue generating capability talk scale overtime ? yeah . software business important part enterprise work . enterprise staffed engineer many csps even largest company world able . established full stack software , n't start -- n't start end cuda . cuda , dnn , 's different library , 's system software , everything really get close application . we've established full stack software license enterprise , start instantaneously already x86 type computing . capability , need ai , work need inﬂuence , incorporate application use . industry application , stock actually help put together . still case , access software , also access service continue improve software overtime . q - joseph moore - colette m. kress q - joseph moorenow , software business right hundred million look still growth opportunity go forward . 've got three different area focus software , nvidia aie , enterprise stock give full stack ai solution , use enterprise . also use omniverse also sell separately . omniverse great path 3d internet focusing term simulating factory , manufacturing work . thirdly , see going forward , automotive derived platform . 've heard mercedes last week , talked use drive software sharing software u . three key area , lot software opportunity also work term software service overall ai surface also addition . great . wanted ask gaming 'll see question audience . sense gaming sell-through , 're $ 7 billion run-rate sell business . think one point talked kind $ 10 billion run-rate last -- second-half last year . , china weaker , also new product cycle . general , thinking seems pretty clear shipping end-demand , sense much ? yeah . finished q4 , feel really good going q1 inventory correction needed behind u essentially normalized channel , 'll probably hit u within q1 . channel normalized , give u opportunity continue selling newest architecture ada . last quarter , able launch ada able see excitement gamers term new architecture , 4090 , 4080 , 4070 ti , three really well period . watch overall sell-through , watch sell-through look demand articulated , probably $ 2.5 billion quarter , give take seasonality specific quarter . h2 usually larger demand h1 . feel 're on-track really get position actually sell-in closer start getting closer sell-through sell-in grow , gaming perspective , 's track . sure . little bit volatility china covid , solid demand gaming still absolutely exists worldwide . think business , mean , look back 10 year see disruptive inﬂuence cryptocurrency six 10 year causing kind shortage ( inaudible ) cycle . n't going forward , much steady growth type business n't volatility ? always going continue somewhat choppy trend , mean , growth , obviously , choppier growth trend ? - colette m. kress q - joseph moore q - unidentified participant - colette m. kress probably consistent many year focus gamers wanting best infrastructure gaming experience , well innovation come , whether 'd programmable shading 10 year ago today term ray tracing . important piece fueled gaming , gaming transformed 10 year . transformed entertainment industry , gamer pc home , bigger , 's social platform well . think continue see , growth believe part , key part crypto behind u . , u win heart many different gamers . ability multiple platform also reach gamers , term desktop , 've seen transformation laptop , notebook really take place drive type gaming would desktop device , really max-q technology , putting top-end gpus inside laptop inﬂuence ray tracing enabled well . ray tracing really helped game developer really add realistic capability , 's infused ai help game developer , build best type real game going forward . 350 game dl going forward . we're going continue add more-and-more innovation . yes , think opportunity u going forward . great . let pause see question audience . keep calling . sir , mic somewhere . thank . report last week amazon web service n't enough compute capacity demand launch new ai product . curious data center chip side , worried running shortage ? able serve demand hyperscale customer ? maybe address ? thank . yeah . 's -- every csp go capacity challenge different part data center . 's one piece . focused building eﬃcient capacity , run problem along way . know challenge may ready accept even gpu , thing saw end q4 . sure enough , know spend time getting understanding able accept start building . 're still ramping process h100 . demand strong . could time , week , quarter careful term whether 're going able make strong demand . 'll stay focused . yes , demand right certainly important part u right 've got good process supply , let 's see work . q - joseph moore - colette m. kress q - joseph moore - colette m. kress hear type anecdote , first thinking 's probably hopper challenge may seems like a100 , inventory ? correct . ramped h100 , probably going key area focus . yes , existing architecture also sell . question -- question audience ? , mentioned mercedes thing , know 've talking year , anyone n't , 've gone back look mercedes analyst day slide . mean , nvidia unlike every slide like 's really impressive . degree 've inﬂuencer program , 've essentially endorsed economics guy talking , economic split $ 1 billion plus mid decade multi-billion kind end decade . talk relationship ? guy think automotive opportunity , much thing like ? 're full system development , really good economics opposed selling card chip , know also lot win well . think biggest economic upside nvidia over-time opportunity develops ? mercedes work 're phenomenal . think understood lighthouse leading company automotive , importance av safety transformation automotive industry software important part car going forward . working together many year part ﬂeet , come market calendar 2025 important piece . continue think type business model work many industry well . time 're working mercedes inside car , know , 're also looking key lighthouse helping manufacturing ﬂoor . 're talking different business model focus omniverse . generate eﬃciencies factory ﬂoor . opportunity always thinking industry , industry 's top player helping end end , great business model u . 'll take different sort . case may sell somebody infrastructure . may case may sell full software may change term different component different part data center infrastructure . important term building ecosystem , building platform approach , nothing would turn away , help , get ai accelerated computing . q - joseph moore - colette m. kress great . lot opportunity front . thank much time today . great . thank .