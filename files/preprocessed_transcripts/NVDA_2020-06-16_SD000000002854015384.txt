okay . think 're live . welcome everybody , second day nasdaq conference virtually london . would like -- 'm delighted honored host nvidia 's cfo , colette kress , fireside chat . series question 'm going ask colette . also 's opportunity ask question interface hit email , 'll try get also . question answer , 'll jump right . would like ask colette , would care make -- start introductory comment ? sure . thanks much hosting u . love opportunity get great wide audience europe well u.s. 's certainly busy several month across world , including nvidia . taken time announce new architecture data center period time . able announce architecture , move full production contribute q1 result . keep mind , finished q1 fiscal year '21 , announced earnings several week ago . q2 continuing ramp overall ampere architecture . data center business accelerating quite well overall ampere well use accelerated computing , also opportunity business line , including gaming , -- quite well challenging time . - mark lipacis - colette kresswe started beginning year focusing impact may overall covid-19 impacting much overall world . able manage supply demand challenge q1 result provided guidance q2 incorporating . 're seeing right strong desire incorporate form accelerated computing many different overall industry . gaming also great area seen advancement number gamers playing , trying game -- home overall lockdown seen . overall innovation 've done different form factor really help overall gaming business whole . happy answer set question . see , nvidia able quite well period time 're . okay . great . thanks introduction , colette . think would like kind level set , review what's transpired bring nvidia today . think go back , think six year ago 2013 , annual revenue nvidia bouncing around $ 3.5 billion $ 4 billion previous five year . pc chipsets accounted 1/2 business . data center accounted 3 % . gross margin mid-50s . ebit margin kind struggled get 20 % . six year ago . contrast , year , street 's modeling revenue $ 10 billion higher , $ 14 billion . gross margin ten point higher mid- 60 . operating margin 15 point higher mid-30s . critical element driven transformation nvidia ? yes . great set fact term number overall growth 've seen last decade . step back actually recall many time , six , seven year ago , discussed company talking initial transformation chip company , associated overall pc shipment largest overall correlation overall revenue . several year discussing , yes , may interaction general pc , specific term market chosen market saw term growing . pc company pc chip company . 've seen u today transform , term gaming overall gaming platform , also seen term many platform used overall computing . whether server whether think role cloud computing everyday business today . 've moved period time , really getting grasp world would change computing necessity overall acceleration . n't going market would able built chip alone . focused focused 10.5 year ago also overall software important piece . software begin creating ability develop ride top overall gpu stitching together many component see term in-use platform . created cuda . cuda available across every single one overall gpus integral term work 've done expand market 've . 've taken overall unified architecture company , focused specifically area knew acceleration would important able expand . quite fortunate right time right place using acceleration expand overall ai . ai many year built area focus many scientist researcher looking ai would transform world . use acceleration use deep learning build much see today ai perfect match company . continue focus building superior chip , innovating overall design overall chip , also specific layer software support many industry . also , last several year , realized also opportunity accelerate beyond overall gpu gpu platform . 've seen last year , focus acquisition mellanox well several piece overall computing platform look acceleration possibility speed work overall complete . think careful choice , careful choice overall market chosen also full look computing , consider u - mark lipacis - colette kressplatform play system company actually look chip company . okay . 's great explanation transformation happened driver . -- kind lead next question ecosystem . privilege taking jensen roadshow five year ago . one meeting , asked competition , said , ai gpu , thought zen thing say time made think importance ecosystem . work , found pc era , wintel ecosystem captured 80 % value , generating pc supply chain . smartphone market , apple capturing 80 % value smartphone supply chain . question , think 's fair say -- compare nvidia 's ecosystem like wintel ecosystem pc era apple 's ecosystem smartphone era ? fair comparison ? 's various similarity thing saw back era . entering , maybe entered market since overall internet boom , ca n't full realization thing occurred time . little bit different , though , . different 's also underlying factor inﬂuencing see term next wave overall computing . think overall nvidia , matched sense microsoft intel time specific platform overall software . , case fast-moving industry . overall era ai continuing transform every single month . even last three year term 're seeing term type workload type solution built , 's different . see 's hard solidify static platform take different change , , therefore , put nvidia quite good position . nvidia 's ability agnostic different type computing solution , different cpu , different software stack , different middleware , different component may inside data center , allows u overall user ﬂexibility era ai changing . - mark lipacisso nothing term specific solution ai . solution , though , broad-based overall ai allows day one thinking ai day 300 continue used solution allows expand overall workload . 're able continue work major framework support ai . 're allowed work almost every single provider planet . every single hyperscale , large small across world , also focusing use gpus . think a100 platform announced , 's yet another evolution understanding people taking accelerated computing overall data center . a100 built system architecture . one , come eight gpus together underlying baseboard allows plugged existing rapid system easy manner improve overall qualification , allowing swap entire piece data center see modernization data center different piece whole . mean may stack overall storage , stack gpus well central area cpu . form factor a100 , allowing easy ability put incentive data center . additionally , a100 also ability elastic term type use want use accelerated computing . know ai -- know high- performance computing important area workload . many overall enterprise focused , term data analytics , focused field data science . usual platform allows scale scale capability useful hyperscales , hyperscales cloud instance , well enterprise . mean , point , choose leverage gpu inferencing . virtualize single gpu platform seven unique instance inferencing 're able stitch together eight gpus together complete one large training data set well . ability enterprise time purchase continue split use overall a100 across business unit , across different workload see period time overall a100 continue revise different new market area . another era work thinking future accelerated computing continues evolve . probably different since early match seen back last 20 year term decade . new world term computing . - colette kresswhat -- would consider critical element ecosystem 're providing customer ? percentage r & spent thing chip design ? overall ecosystem , think different business connection ecosystem , every single one business ecosystem need address . n't mean thinking end customer use overall application allows use overall compute underneath application put together key participant . starting already overall gaming . chose five ten year ago focus ecosystem , focus knowing gamer coming board look overall gpu card actually coming market wanted play game . ecosystem game built type game focused overall energy focus term connection partnership . even brought overall real-time ray tracing gaming , two year ago , first entrant well pleased term ecosystem adoption thought bringing real-time ray tracing overall game . needed starter . meaning , overall ecosystem would able manage bringing ray tracing market alone . needed partnership underlying compute , underlying hardware stitch overall together . two year passed . every single game engine , every single game developer organization focused incorporate ray tracing overall future game . put u , , top bar innovation , really bringing overall gamers like see game . realistic , different type game built ray tracing really expands market type entertainment work . 's one industry . think ecosystem even importantly focus data center focus type application use accelerated computing . work began high-performance computing . high- performance computing really high computational , diﬃcult data set could , back ten year ago , take significant amount time complete . important work , whether oil gas , whether many medical field well term work done . 've seen understanding use overall gpus inferring overall answer -- overall ai . ability allow ai expand farther research and/or lab work , everyday use term hyperscales well enterprise , u focusing ecosystem top application could overall accelerated . n't build application . work together middleware creating ease framework attach ecosystem application - mark lipacis - colette kressuser n't think put together . work essential place . differentiated u many overall player market really coming market underlying chip . focus large workload , carefully thinking . sure enough , way 're going deployed used whether software stitched together . company , although may think set hardware engineer focused designing chip , working fab provider term manufacturing , 's actually part overall engineering . software engineer actually overall hardware engineer . work together creating base system-level software , system-level software allow someone use one gpus work also work take place stitch overall application , rewrite sometimes application work overall gpu . data center side , think 's view coding data center acceleration platform , particularly ai , done higher level , call deep learning framework like tensorflow kera , could abstract developer nvidia 's ecosystem effectively would n't make easy port software developed deep learning framework another platform one present . saying investor present concern ? kind insulate happening ? yes . data center field overall ai , overall open source framework built essential term speeding ability create overall application specific overall industry . hyperscales focused overall framework . 's interesting significant amount work framework term compiling overall code , data together allow framework work eﬃciently effectively top gpus . essential underpinning overall framework . 're right , 's common developer understand overall stitching together , actually encourage . thought focus core competency term working application data solve overall problem able leverage gpu take workload workload great . - mark lipacisbut 's necessarily easy lift switch piece , see overall framework well framework cuda cuda-x , middleware 's together , thing updated , often . overall current discussion term happening framework . interesting articulated top framework today . three year ago , different set . continue make sure aligned current overall framework well current form use . three year ago , would talking image detection image categorization , would important use certain overall framework . 're looking right , hot overall workload , focus conversational ai focus recommendator engine . different overall framework , different model built overall process natural language understanding . combination two together represent 50 % type load workload done . anybody 's looking take something built six month ago put different type platform chip actually yesterday year thing moving ever fast new form ai building larger , bigger data set . amount work changed overall framework well underlying cuda software every single day changing . 're really looking people past going keep speed 're seeing term adoption ai . 's helpful . think another -- another kind debate come investor , competitive standpoint investor think could disrupt -- nvidia could disruptive , question general purpose versus application-specific computing . one past analyst day , jensen made case past computing era era 're dominated general purpose computing platform , became de facto standard opposed application-specific one . nvidia 's gpu accelerating computing platform , best positioned dominate programmable qualified kind general- purpose computing platform idea . side argument -- seems legitimate compute cycle consolidating seven -- like seven large cloud service provider , let 's say . csps massive economy scale like end user computing industry past . consolidate centralize specific workload benefit application-specific computing model building custom processor merchant application-specific processor . - colette kressso question , think ? general purpose computing model dominated past ? apply today ? yes . really interesting question . 's super interesting look history , history happened , also look nvidia excelled overall period . general purpose computing , think 's important perspective say ability u lead adoption lead inherit number researcher number developer platform general purpose nature , right ? reached point 1.8 million overall developer overall platform . done congregated toward overall nvidia gpu platform universal use . yes . 's lot different hyperscales . 's lot different type platform . know program equally across overall software set allows ability . general purpose , 's important demonstrate overall developer researcher continue expand workload want go . led u application-specific developer choose application use overall platform rather way around . developer base extremely important link together many application knew well understanding overall importance accelerated computing era moore 's law going fall become obsolete . use developer , overall thinking work need done creative application , allows u leverage model invest spend time . even think world right lot hyperscales , 's great hyperscales -- think would ability build custom overall infrastructure . reality 's always core competency know full house overall engineer understand base chip design , overall aspect building thermal , different us case improve performance gpu . turned u create universal capability use gpu . may specific workload may use custom chip . - mark lipacis - colette kressbut serving universe developer , universal platform also universal development platform , essential breadth type workload 're seeing would n't capable anybody show application specific . would invest tremendously in- house non-open application-specific era . 's . kept thing open possible , agnostic possible support growth ai high-performance computing many workload 'll see future . field work indicates nvidia account 85 % acceleration instance market top cloud service provider . time , amazon developing chip , inferentia , 's market -- data suggests 's around 1 % instance available 2 % . google tpu , 1 % instance available . -- -- mind , kind biggest risk potential solution consume acceleration cycle market ? solution customer ? -- data , get 's public market , instance available , competitive intelligence telling internal workload ? think -- biggest customer , think share equal external workload instance ? yes . evolving era type work -- type workload done overall hyperscales . 've big part growth overall ai overall hyperscales . first set customer . many find opportunity try ability create custom workload seen . 're correct , 's , small share . one main reason , work 've done custom custom asic . focused term -- design process design something specific workload 're seeing . speed market bringing overall custom asic may good , maybe reasonable amount time . keep mind trend overall asic come , 's ability go back revise overall chip revise change term overall workload . need relatively confident term type workload able used . even think overall a100 , many year making developing architecture probably quite big surprise overall - mark lipacisindustry . ? a100 , three year , 20x improvement performance versus last generation v100 . core competency working top performance , top performance speed feed , top performance many different workload . 've talked ability , overall tensor core really think ﬂoating point precision necessary inferencing dial depending type workload . would continue gravitate people using overall gpus large percentage workload 're versus using overall custom asic . believe also ability whether enterprise overall cloud user use gpus cloud instance , also importance edge . instance talked aws google focused captive space versus overall gpu serve large market believe exist edge important . everything hyperscales , everything term cloud incident . platform scalable edge different type workload exist important piece , , people continued choose overall nvidia well nvidia gpus case . time time , 'll see custom asic . oftentimes 're captive . they're probably focused specific overall workload . overall speed adoption ai growth focus people gravitate platform scale growth 're seeing market . yes . want kind pick point ampere think , think solution evolved platform time , 's involved , initial product , maybe , let 's say , five six year ago , seem well suited training . came product -- seem focused inferencing . ampere solution seems -- seems optimized , given scalability . standpoint , seems like solution fit completely idea offering general purpose acceleration platform training inferencing . two question ampere , right way think , -- , fit general purpose computing model ? end day , pick time -- three , five year , ten year , -- chip ampere-like inferencing -- offer best-in-class inferencing performance best-in-class training performance ? training-specific solution go away inferencing-specific solution go away , end single acceleration platform one - colette kresssolution ? yes . really , really important understanding entered overall inferencing market . let 's go back term couple year ago . discussed size , opportunity front u data center . size front u incorporated training , high-performance computing , two area quite leadership position , also discussion importance overall inferencing . lot people discus say , wait minute , ? people move overall gpu ? people use cpu inferencing . 're going need different form factor . 're going need smaller . 're going need focus term wattage otherwise , know , cpu fine . took piece important understanding inferencing would change changed last couple year . thought term working many customer type inferencing 're historically really based type compute . said , well , compute . therefore , create inferencing support . mean rather overall simplistic type inferencing mass amount data binary type response necessary . saw output training . output training ai would create phenomenal overall data set new information coming would need go overall inferencing model , standard overall compute chip would likely slow respond back overall need overall inferencing workload 's . see right conversational ai -- example , phenomenal ai workload . 's ai workload taking one challenging part overall understanding data , understanding natural language . understanding natural language , said , deciphering term piece meaning also able respond language well conversational manner . take training . also , therefore , take inferencing side . speed performance important . ability speak multiple language overall workload , 're looking couple hundred millisecond type response . entrance inferencing extension saw term training . built inferencing solidly double-digit percent overall data center business couple year . growing doubling year-over-year last quarter . ability bring something like a100 market allows u , , overall customer - mark lipacis - colette kresschoosing purchase workload want allow continuation building training model move overall inferencing . go forward , 's going hard u determine specifically model much overall inferencing workload 're selling , ability overall a100 meet multiple need end customer , whether hyperscale enterprise enterprise edge well . mean everything moving forward would a100 type platform ? believe overall acceleration meet many different type application server going forward . someday , way future , almost everything accelerated . period time , may still different form factor outside a100 . keep mind , a100 , platform . also sell full system . full system dgxs . ? ? ability score competency focus infrastructure get end-to-end configuration allows plug-and-play , focus application focus work overall core competency . similarly , -- may opposite , may say , provide specific overall gpu specific workload term overall volume . 'll see market play term , think 'll full host different platform solution everything look like a100 . okay . 's clear . want shift gear little bit 's going -- macro front china . recent trade tension u.s. china impacted nvidia 's business ? big china consumption market ? 's risk u.s. government determines nvidia gpus enabling something 's deemed politically unacceptable block shipment nvidia product china ? yes . let first start china whole customer nvidia . china important customer u whole . significant overall gaming business rest overall business . overall gaming business , pc platform , pc platform integral part china household many overall workload across overall nation . mean , , kind stem back universal nature , people leveraged overall pc much work overall - mark lipacis - colette kressconsumer user also important piece term overall business . early start high end type gaming using overall pc platform . pc platform become important probably built upon platform people use overall writing overall game . keep mind , statement say , 's universal platform going area world . underlying gpu inside pc and/or laptop . geared specific overall workload , lead u see term data center . data center , also worked overall hyperscales many tier 2 internet provider -- consumer internet provider china . nature u.s. u.s. hyperscales much larger overall capex budget see china . important part . important part , , universal platform also term data center use acceleration . tension u.s. china continue go back forth , industry understanding specific overall nvidia . 're similar memory supplier and/or type part term consuming overall computing would overall affected . stand watch say 's nothing overall gpus specific regarding u.s. china . compute whole . watch carefully . part , watch overall industry leader well focus . far , use really universal compute overall nation . able continue sell overall china exception specific overall entity u.s. government concerned , make sure following u.s. law regarding selling overall entity list . think -- 's helpful -- think related question china . tsmc critical supplier nvidia . political situation developed nvidia blocked using tsmc , 's nvidia 's wafer foundry contingency plan ? yes . several year ago , probably five year ago , path creating multiple foundry multiple foundry manufacturer important u . important u enterprise risk standpoint . enterprise risk say , oftentimes many different part world , global condition change , whether weather condition , geopolitical thing change and/or basic oversupply demand many change . - mark lipacis - colette kressour thought creating another foundry important part . keep mind , n't overnight decision something could put place quickly . year , dual overall fab support model . use tsmc . also use samsung . many case , take architecture , work term development architecture fabs . could choose split architecture across fabs singly one overall fab provider . clear , tsmc great partner . u since beginning time . truly appreciate partnership . partnership focused machine ability spit chip . really understanding process work . 're pleased also built samsung . similar different partnership different process relates overall samsung . look forward , like ability overall two fabs . also continue support something may pulling tsmc u.s.-based overall fab well . 'd supportive , 're excited see next term . model today -- high end , high end type chip complexity chip , 're extremely pleased two fab provider . excellent . 're coming end time , 'm hoping sneak one question . investor speak really focus data center . data center market historically lumpy one . 2018 , kind shift -- shift trend line . data center business declined dramatically first half '19 . -- talked good visibility july quarter . -- talk like october quarter ? give u framework ? like -- -- next quarter visibility , start kick ? risk 're shifting trend line -- kind reset due natural lumpiness market ? yes . past -- 've probably talked quite bit last five year . people wanted know reach seasonality data center , reach seasonality ? assure growth , see , continue quarter quarter ? 's nothing guarantee quarter-to-quarter sequential overall growth . 've done pretty phenomenal job , almost consistently growth . 're correct . period overall digestion , digestion industry . even digestion , important era people wanted know , well , going get back growth ? era time u focus engineer continuing expand partnership customer base incorporate work knew enterprise 're working growth saw term add . sit right end q1 , hyperscales , originally , three four year ago , probably majority , lion 's share overall data center business , le overall 50 % overall business data center . 's interesting side enterprise , research high- performance computing , supercomputing 50 % business . work term building breadth depth type workload using acceleration customer , hopefully able see something smoother . right , keep mind still stack project project . business model 're building inventory and/or customer inventory . specific project . great period time seen project per customer . 's one project , sometimes overlapping time frame term deployment . customer well u would like improve overall planning . planning data center hard know ineﬃciencies . know ineﬃciencies term working , working clearly work road map deploy data center best-of-breed . we're ramping a100 right . couple month , 's got long trajectory year term 's deployed . even quarter launch a100 , reached record level v100 record level t4 , even though market couple year . period time , see u selling a100 . also see u continue selling v100 selling overall specific inferencing product t4 . look , continue try work visibility . visibility q2 solid , similar visibility 've term q1 . 'll turn corner get closer q3 talk visibility . think 's important step back look say , a100 going u . know 're done everything coming overall architecture . - mark lipacis - colette kress - mark lipacisso 's great thing see . think 're pleased -- performance company started today 's call . covid-19 , overall decision area focus knowing ai accelerated computing still top priority customer unique time industry world whole , think , put u great place move second half . time , 're going wait get second half discus overall outlook . okay ? 's fair helpful . ran . think last word . colette , thank much joining fireside chat . extremely informative -- 'd imagine everybody else . everybody else line , thanks dialing . nice day . thanks , mark . appreciate . take care . bye-bye .